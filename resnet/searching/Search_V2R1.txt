Using GPU No: 2,3
net_cache :  ../training/models/checkpoint.pth.tar
Loading checkpoint ../training/models/checkpoint.pth.tar ..........
Loaded checkpoint ../training/models/checkpoint.pth.tar epoch = 31
population_num = 50 select_num = 50 mutation_num = 25 crossover_num = 25 max_iters = 20
Starting from 0

Testing Model 1
[17, 22, 19, 20, 16, 12, 21, 18, 23, 23, 20, 20, 17, 20, 22, 14, 23, 16, 22, 13]
FLOPs = 1973.21M
Top-1 Accuracy = 54.73 | Top-5 Accuracy = 78.41 | Loss = 2.0303
Testing Model 1 took 2 mins and 16 secs

Testing Model 2
[18, 23, 22, 19, 13, 15, 22, 22, 23, 15, 12, 23, 17, 21, 18, 23, 16, 15, 22, 23]
FLOPs = 2033.50M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.67 | Loss = 2.0151
Testing Model 2 took 2 mins and 1 secs

Testing Model 3
[15, 23, 22, 23, 16, 14, 13, 23, 19, 19, 14, 17, 22, 14, 22, 18, 19, 15, 23, 15]
FLOPs = 1957.65M
Top-1 Accuracy = 54.84 | Top-5 Accuracy = 78.54 | Loss = 2.0271
Testing Model 3 took 2 mins and 0 secs

Testing Model 4
[21, 22, 22, 18, 22, 18, 23, 19, 20, 23, 14, 17, 15, 17, 19, 17, 13, 22, 17, 19]
FLOPs = 1959.83M
Top-1 Accuracy = 55.04 | Top-5 Accuracy = 78.73 | Loss = 2.0190
Testing Model 4 took 2 mins and 3 secs

Testing Model 5
[23, 23, 18, 20, 21, 17, 22, 16, 18, 12, 20, 21, 17, 21, 23, 15, 22, 19, 18, 16]
FLOPs = 1976.67M
Top-1 Accuracy = 54.95 | Top-5 Accuracy = 78.64 | Loss = 2.0204
Testing Model 5 took 2 mins and 0 secs

Testing Model 6
[20, 22, 18, 21, 22, 20, 15, 13, 21, 23, 21, 23, 22, 17, 19, 18, 23, 13, 21, 17]
FLOPs = 2030.04M
Top-1 Accuracy = 54.95 | Top-5 Accuracy = 78.63 | Loss = 2.0190
Testing Model 6 took 2 mins and 0 secs

Testing Model 7
[12, 17, 22, 22, 19, 20, 16, 14, 20, 16, 19, 23, 16, 23, 17, 23, 17, 22, 18, 21]
FLOPs = 2006.36M
Top-1 Accuracy = 54.96 | Top-5 Accuracy = 78.66 | Loss = 2.0190
Testing Model 7 took 1 mins and 58 secs

Testing Model 8
[18, 15, 23, 22, 18, 21, 23, 18, 18, 17, 23, 18, 14, 19, 18, 23, 14, 23, 13, 16]
FLOPs = 1958.96M
Top-1 Accuracy = 54.65 | Top-5 Accuracy = 78.46 | Loss = 2.0290
Testing Model 8 took 1 mins and 59 secs

Testing Model 9
[14, 21, 21, 18, 20, 23, 16, 20, 20, 21, 12, 23, 23, 19, 23, 21, 23, 15, 15, 21]
FLOPs = 2035.24M
Top-1 Accuracy = 54.94 | Top-5 Accuracy = 78.54 | Loss = 2.0256
Testing Model 9 took 1 mins and 59 secs

Testing Model 10
[23, 22, 20, 18, 19, 12, 17, 23, 19, 21, 17, 16, 18, 22, 22, 22, 19, 21, 15, 16]
FLOPs = 1966.58M
Top-1 Accuracy = 54.83 | Top-5 Accuracy = 78.50 | Loss = 2.0269
Testing Model 10 took 1 mins and 59 secs

Testing Model 11
[15, 22, 21, 22, 13, 19, 22, 22, 13, 18, 20, 13, 13, 12, 23, 18, 21, 22, 22, 23]
FLOPs = 2007.26M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.67 | Loss = 2.0143
Testing Model 11 took 2 mins and 1 secs

Testing Model 12
[23, 23, 18, 21, 17, 15, 20, 18, 23, 23, 20, 21, 21, 15, 12, 16, 17, 17, 20, 22]
FLOPs = 1996.41M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.70 | Loss = 2.0163
Testing Model 12 took 2 mins and 2 secs

Testing Model 13
[23, 14, 21, 23, 15, 18, 17, 20, 23, 18, 22, 13, 14, 21, 17, 22, 23, 15, 22, 18]
FLOPs = 1983.29M
Top-1 Accuracy = 55.01 | Top-5 Accuracy = 78.52 | Loss = 2.0187
Testing Model 13 took 1 mins and 58 secs

Testing Model 14
[20, 20, 22, 22, 12, 23, 23, 21, 20, 19, 16, 18, 22, 13, 23, 16, 12, 13, 18, 21]
FLOPs = 1981.31M
Top-1 Accuracy = 54.88 | Top-5 Accuracy = 78.63 | Loss = 2.0244
Testing Model 14 took 2 mins and 1 secs

Testing Model 15
[18, 17, 22, 22, 19, 21, 13, 19, 19, 19, 12, 12, 22, 23, 21, 21, 21, 15, 23, 17]
FLOPs = 1971.05M
Top-1 Accuracy = 54.88 | Top-5 Accuracy = 78.51 | Loss = 2.0215
Testing Model 15 took 2 mins and 3 secs

Testing Model 16
[19, 23, 20, 18, 20, 12, 23, 15, 12, 16, 23, 22, 18, 18, 13, 23, 23, 21, 20, 18]
FLOPs = 1955.02M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.77 | Loss = 2.0173
Testing Model 16 took 1 mins and 59 secs

Testing Model 17
[12, 22, 21, 23, 18, 20, 13, 15, 20, 23, 22, 21, 23, 12, 16, 14, 20, 20, 22, 20]
FLOPs = 2027.76M
Top-1 Accuracy = 54.98 | Top-5 Accuracy = 78.66 | Loss = 2.0186
Testing Model 17 took 2 mins and 1 secs

Testing Model 18
[19, 20, 21, 16, 22, 18, 19, 23, 19, 23, 21, 19, 19, 12, 20, 16, 22, 17, 22, 19]
FLOPs = 1987.36M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.72 | Loss = 2.0167
Testing Model 18 took 1 mins and 59 secs

Testing Model 19
[15, 23, 23, 22, 22, 18, 23, 17, 23, 18, 16, 15, 21, 17, 20, 12, 18, 20, 15, 19]
FLOPs = 2010.20M
Top-1 Accuracy = 54.97 | Top-5 Accuracy = 78.56 | Loss = 2.0241
Testing Model 19 took 2 mins and 4 secs

Testing Model 20
[20, 23, 19, 21, 22, 15, 22, 17, 15, 22, 18, 22, 12, 17, 22, 22, 13, 14, 23, 21]
FLOPs = 1998.11M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.78 | Loss = 2.0144
Testing Model 20 took 2 mins and 2 secs

Testing Model 21
[17, 23, 15, 22, 23, 23, 18, 21, 19, 19, 17, 21, 23, 18, 16, 13, 20, 12, 21, 22]
FLOPs = 1998.38M
Top-1 Accuracy = 54.82 | Top-5 Accuracy = 78.64 | Loss = 2.0239
Testing Model 21 took 2 mins and 1 secs

Testing Model 22
[14, 14, 16, 22, 21, 22, 20, 19, 18, 22, 16, 21, 22, 21, 19, 15, 20, 21, 22, 18]
FLOPs = 1980.51M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.61 | Loss = 2.0197
Testing Model 22 took 2 mins and 1 secs

Testing Model 23
[15, 20, 17, 19, 21, 20, 17, 21, 22, 13, 16, 20, 23, 23, 14, 20, 21, 18, 18, 22]
FLOPs = 1960.33M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.74 | Loss = 2.0187
Testing Model 23 took 1 mins and 58 secs

Testing Model 24
[18, 23, 21, 20, 17, 17, 19, 23, 12, 20, 21, 12, 20, 21, 22, 22, 19, 12, 20, 17]
FLOPs = 1965.64M
Top-1 Accuracy = 54.85 | Top-5 Accuracy = 78.45 | Loss = 2.0258
Testing Model 24 took 2 mins and 0 secs

Testing Model 25
[20, 22, 21, 22, 20, 20, 13, 22, 16, 12, 19, 20, 22, 12, 16, 22, 15, 17, 20, 20]
FLOPs = 1959.01M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.74 | Loss = 2.0142
Testing Model 25 took 2 mins and 7 secs

Testing Model 26
[21, 23, 23, 22, 15, 21, 16, 22, 17, 13, 15, 21, 17, 22, 19, 13, 17, 23, 19, 14]
FLOPs = 2001.56M
Top-1 Accuracy = 54.74 | Top-5 Accuracy = 78.52 | Loss = 2.0269
Testing Model 26 took 2 mins and 2 secs

Testing Model 27
[14, 19, 21, 15, 20, 15, 22, 23, 23, 20, 16, 22, 17, 18, 19, 20, 22, 19, 22, 22]
FLOPs = 2004.17M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.73 | Loss = 2.0157
Testing Model 27 took 2 mins and 1 secs

Testing Model 28
[13, 23, 19, 22, 21, 19, 14, 14, 19, 19, 21, 19, 20, 17, 21, 23, 16, 23, 13, 19]
FLOPs = 1975.49M
Top-1 Accuracy = 54.72 | Top-5 Accuracy = 78.56 | Loss = 2.0258
Testing Model 28 took 1 mins and 59 secs

Testing Model 29
[18, 21, 20, 15, 21, 20, 13, 23, 14, 17, 23, 23, 23, 14, 23, 13, 23, 21, 21, 16]
FLOPs = 1957.24M
Top-1 Accuracy = 55.02 | Top-5 Accuracy = 78.63 | Loss = 2.0238
Testing Model 29 took 1 mins and 59 secs

Testing Model 30
[18, 17, 22, 23, 20, 20, 18, 16, 21, 21, 21, 19, 16, 18, 13, 19, 21, 19, 20, 22]
FLOPs = 2036.84M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.73 | Loss = 2.0137
Testing Model 30 took 2 mins and 0 secs

Testing Model 31
[19, 22, 17, 20, 22, 23, 19, 22, 22, 14, 21, 15, 14, 22, 19, 15, 19, 20, 18, 20]
FLOPs = 1983.97M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.67 | Loss = 2.0157
Testing Model 31 took 1 mins and 58 secs

Testing Model 32
[20, 23, 23, 15, 21, 17, 23, 23, 18, 23, 23, 19, 20, 17, 17, 22, 21, 12, 13, 14]
FLOPs = 1974.25M
Top-1 Accuracy = 54.31 | Top-5 Accuracy = 78.23 | Loss = 2.0459
Testing Model 32 took 2 mins and 3 secs

Testing Model 33
[21, 13, 20, 21, 22, 17, 17, 23, 23, 20, 15, 13, 17, 20, 22, 21, 23, 14, 21, 19]
FLOPs = 1970.30M
Top-1 Accuracy = 54.99 | Top-5 Accuracy = 78.61 | Loss = 2.0170
Testing Model 33 took 1 mins and 58 secs

Testing Model 34
[15, 18, 20, 23, 22, 19, 21, 18, 15, 22, 19, 23, 15, 19, 19, 20, 23, 23, 16, 14]
FLOPs = 2040.78M
Top-1 Accuracy = 54.85 | Top-5 Accuracy = 78.54 | Loss = 2.0271
Testing Model 34 took 1 mins and 59 secs

Testing Model 35
[17, 22, 23, 18, 15, 18, 20, 16, 22, 16, 18, 15, 23, 19, 15, 22, 21, 19, 20, 19]
FLOPs = 1963.81M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.72 | Loss = 2.0162
Testing Model 35 took 2 mins and 0 secs

Testing Model 36
[21, 23, 21, 18, 17, 12, 18, 20, 21, 16, 23, 17, 14, 23, 21, 20, 22, 20, 20, 14]
FLOPs = 1977.65M
Top-1 Accuracy = 54.81 | Top-5 Accuracy = 78.59 | Loss = 2.0256
Testing Model 36 took 2 mins and 1 secs

Testing Model 37
[15, 22, 23, 19, 19, 22, 16, 15, 23, 22, 15, 22, 20, 21, 14, 21, 14, 19, 21, 17]
FLOPs = 2006.10M
Top-1 Accuracy = 54.99 | Top-5 Accuracy = 78.56 | Loss = 2.0216
Testing Model 37 took 2 mins and 13 secs

Testing Model 38
[21, 23, 23, 18, 19, 23, 22, 21, 14, 21, 18, 19, 14, 18, 22, 23, 18, 17, 17, 16]
FLOPs = 2024.32M
Top-1 Accuracy = 54.96 | Top-5 Accuracy = 78.63 | Loss = 2.0231
Testing Model 38 took 2 mins and 7 secs

Testing Model 39
[21, 23, 22, 21, 19, 14, 19, 22, 19, 21, 14, 20, 15, 13, 12, 15, 18, 22, 22, 22]
FLOPs = 1990.95M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.73 | Loss = 2.0128
Testing Model 39 took 2 mins and 23 secs

Testing Model 40
[17, 18, 14, 22, 21, 17, 18, 21, 15, 15, 20, 19, 19, 22, 22, 23, 15, 20, 22, 20]
FLOPs = 1966.58M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.80 | Loss = 2.0136
Testing Model 40 took 2 mins and 1 secs

Testing Model 41
[18, 16, 21, 17, 20, 18, 20, 17, 18, 22, 20, 19, 17, 23, 21, 23, 23, 14, 22, 18]
FLOPs = 1967.93M
Top-1 Accuracy = 54.93 | Top-5 Accuracy = 78.61 | Loss = 2.0189
Testing Model 41 took 2 mins and 13 secs

Testing Model 42
[19, 20, 23, 20, 23, 17, 17, 15, 18, 23, 19, 13, 14, 21, 22, 23, 23, 14, 12, 20]
FLOPs = 1956.90M
Top-1 Accuracy = 54.72 | Top-5 Accuracy = 78.34 | Loss = 2.0319
Testing Model 42 took 2 mins and 3 secs

Testing Model 43
[19, 15, 20, 23, 20, 17, 12, 21, 17, 19, 20, 23, 22, 22, 20, 13, 23, 21, 13, 20]
FLOPs = 2011.92M
Top-1 Accuracy = 54.93 | Top-5 Accuracy = 78.62 | Loss = 2.0215
Testing Model 43 took 2 mins and 1 secs

Testing Model 44
[16, 16, 22, 21, 16, 13, 14, 17, 20, 23, 22, 19, 19, 12, 23, 14, 23, 23, 18, 23]
FLOPs = 1987.54M
Top-1 Accuracy = 55.04 | Top-5 Accuracy = 78.71 | Loss = 2.0158
Testing Model 44 took 2 mins and 14 secs

Testing Model 45
[19, 21, 22, 22, 13, 15, 23, 23, 12, 17, 18, 19, 22, 12, 18, 22, 21, 23, 15, 17]
FLOPs = 2000.68M
Top-1 Accuracy = 54.90 | Top-5 Accuracy = 78.58 | Loss = 2.0222
Testing Model 45 took 2 mins and 3 secs

Testing Model 46
[22, 20, 23, 14, 23, 17, 22, 13, 23, 19, 22, 19, 21, 16, 22, 17, 19, 22, 14, 22]
FLOPs = 1985.67M
Top-1 Accuracy = 54.99 | Top-5 Accuracy = 78.74 | Loss = 2.0218
Testing Model 46 took 2 mins and 4 secs

Testing Model 47
[22, 22, 23, 20, 14, 16, 14, 21, 17, 15, 21, 21, 15, 23, 19, 23, 16, 23, 13, 23]
FLOPs = 2031.72M
Top-1 Accuracy = 54.94 | Top-5 Accuracy = 78.66 | Loss = 2.0190
Testing Model 47 took 2 mins and 21 secs

Testing Model 48
[18, 20, 19, 17, 13, 22, 21, 20, 17, 22, 18, 20, 14, 18, 19, 18, 22, 23, 23, 20]
FLOPs = 1982.31M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.79 | Loss = 2.0136
Testing Model 48 took 2 mins and 12 secs

Testing Model 49
[23, 21, 23, 22, 18, 17, 22, 12, 23, 20, 14, 22, 23, 22, 21, 13, 19, 17, 17, 14]
FLOPs = 2035.08M
Top-1 Accuracy = 54.72 | Top-5 Accuracy = 78.46 | Loss = 2.0314
Testing Model 49 took 2 mins and 18 secs

Testing Model 50
[17, 21, 18, 23, 14, 13, 19, 16, 21, 16, 20, 12, 23, 22, 21, 19, 20, 16, 21, 23]
FLOPs = 1976.02M
Top-1 Accuracy = 55.02 | Top-5 Accuracy = 78.61 | Loss = 2.0190
Testing Model 50 took 2 mins and 16 secs

> Select
Iteration 0 : Showing Top 50 results
1. [20. 22. 21. 22. 20. 20. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.377861022949219
2. [19. 23. 20. 18. 20. 12. 23. 15. 12. 16. 23. 22. 18. 18. 13. 23. 23. 21.
 20. 18.] 
Reward = 15.3290376663208
3. [15. 20. 17. 19. 21. 20. 17. 21. 22. 13. 16. 20. 23. 23. 14. 20. 21. 18.
 18. 22.] 
Reward = 15.253179550170898
4. [17. 22. 23. 18. 15. 18. 20. 16. 22. 16. 18. 15. 23. 19. 15. 22. 21. 19.
 20. 19.] 
Reward = 15.243968963623047
5. [17. 18. 14. 22. 21. 17. 18. 21. 15. 15. 20. 19. 19. 22. 22. 23. 15. 20.
 22. 20.] 
Reward = 15.222638130187988
6. [21. 22. 22. 18. 22. 18. 23. 19. 20. 23. 14. 17. 15. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.195782661437988
7. [18. 20. 19. 17. 13. 22. 21. 20. 17. 22. 18. 20. 14. 18. 19. 18. 22. 23.
 23. 20.] 
Reward = 15.190483093261719
8. [18. 21. 20. 15. 21. 20. 13. 23. 14. 17. 23. 23. 23. 14. 23. 13. 23. 21.
 21. 16.] 
Reward = 15.187790870666504
9. [14. 14. 16. 22. 21. 22. 20. 19. 18. 22. 16. 21. 22. 21. 19. 15. 20. 21.
 22. 18.] 
Reward = 15.181986808776855
10. [19. 20. 21. 16. 22. 18. 19. 23. 19. 23. 21. 19. 19. 12. 20. 16. 22. 17.
 22. 19.] 
Reward = 15.063105583190918
11. [21. 23. 22. 21. 19. 14. 19. 22. 19. 21. 14. 20. 15. 13. 12. 15. 18. 22.
 22. 22.] 
Reward = 15.048895835876465
12. [19. 22. 17. 20. 22. 23. 19. 22. 22. 14. 21. 15. 14. 22. 19. 15. 19. 20.
 18. 20.] 
Reward = 15.001506805419922
13. [21. 13. 20. 21. 22. 17. 17. 23. 23. 20. 15. 13. 17. 20. 22. 21. 23. 14.
 21. 19.] 
Reward = 14.99339771270752
14. [17. 21. 18. 23. 14. 13. 19. 16. 21. 16. 20. 12. 23. 22. 21. 19. 20. 16.
 21. 23.] 
Reward = 14.987858772277832
15. [23. 23. 18. 21. 17. 15. 20. 18. 23. 23. 20. 21. 21. 15. 12. 16. 17. 17.
 20. 22.] 
Reward = 14.956939697265625
16. [20. 23. 19. 21. 22. 15. 22. 17. 15. 22. 18. 22. 12. 17. 22. 22. 13. 14.
 23. 21.] 
Reward = 14.916147232055664
17. [14. 19. 21. 15. 20. 15. 22. 23. 23. 20. 16. 22. 17. 18. 19. 20. 22. 19.
 22. 22.] 
Reward = 14.914803504943848
18. [18. 16. 21. 17. 20. 18. 20. 17. 18. 22. 20. 19. 17. 23. 21. 23. 23. 14.
 22. 18.] 
Reward = 14.903217315673828
19. [16. 16. 22. 21. 16. 13. 14. 17. 20. 23. 22. 19. 19. 12. 23. 14. 23. 23.
 18. 23.] 
Reward = 14.902915954589844
20. [23. 14. 21. 23. 15. 18. 17. 20. 23. 18. 22. 13. 14. 21. 17. 22. 23. 15.
 22. 18.] 
Reward = 14.889446258544922
21. [15. 22. 21. 22. 13. 19. 22. 22. 13. 18. 20. 13. 13. 12. 23. 18. 21. 22.
 22. 23.] 
Reward = 14.851967811584473
22. [23. 23. 18. 20. 21. 17. 22. 16. 18. 12. 20. 21. 17. 21. 23. 15. 22. 19.
 18. 16.] 
Reward = 14.843557357788086
23. [22. 20. 23. 14. 23. 17. 22. 13. 23. 19. 22. 19. 21. 16. 22. 17. 19. 22.
 14. 22.] 
Reward = 14.834461212158203
24. [15. 23. 22. 23. 16. 14. 13. 23. 19. 19. 14. 17. 22. 14. 22. 18. 19. 15.
 23. 15.] 
Reward = 14.831095695495605
25. [18. 17. 22. 22. 19. 21. 13. 19. 19. 19. 12. 12. 22. 23. 21. 21. 21. 15.
 23. 17.] 
Reward = 14.769139289855957
26. [18. 23. 21. 20. 17. 17. 19. 23. 12. 20. 21. 12. 20. 21. 22. 22. 19. 12.
 20. 17.] 
Reward = 14.768134117126465
27. [23. 22. 20. 18. 19. 12. 17. 23. 19. 21. 17. 16. 18. 22. 22. 22. 19. 21.
 15. 16.] 
Reward = 14.728584289550781
28. [20. 20. 22. 22. 12. 23. 23. 21. 20. 19. 16. 18. 22. 13. 23. 16. 12. 13.
 18. 21.] 
Reward = 14.660720825195312
29. [15. 22. 23. 19. 19. 22. 16. 15. 23. 22. 15. 22. 20. 21. 14. 21. 14. 19.
 21. 17.] 
Reward = 14.613758087158203
30. [19. 20. 23. 20. 23. 17. 17. 15. 18. 23. 19. 13. 14. 21. 22. 23. 23. 14.
 12. 20.] 
Reward = 14.611713409423828
31. [21. 23. 21. 18. 17. 12. 18. 20. 21. 16. 23. 17. 14. 23. 21. 20. 22. 20.
 20. 14.] 
Reward = 14.579030990600586
32. [12. 17. 22. 22. 19. 20. 16. 14. 20. 16. 19. 23. 16. 23. 17. 23. 17. 22.
 18. 21.] 
Reward = 14.562528610229492
33. [15. 23. 23. 22. 22. 18. 23. 17. 23. 18. 16. 15. 21. 17. 20. 12. 18. 20.
 15. 19.] 
Reward = 14.538524627685547
34. [19. 21. 22. 22. 13. 15. 23. 23. 12. 17. 18. 19. 22. 12. 18. 22. 21. 23.
 15. 17.] 
Reward = 14.516227722167969
35. [18. 23. 22. 19. 13. 15. 22. 22. 23. 15. 12. 23. 17. 21. 18. 23. 16. 15.
 22. 23.] 
Reward = 14.49194622039795
36. [18. 17. 22. 23. 20. 20. 18. 16. 21. 21. 21. 19. 16. 18. 13. 19. 21. 19.
 20. 22.] 
Reward = 14.487797737121582
37. [17. 22. 19. 20. 16. 12. 21. 18. 23. 23. 20. 20. 17. 20. 22. 14. 23. 16.
 22. 13.] 
Reward = 14.480584144592285
38. [18. 15. 23. 22. 18. 21. 23. 18. 18. 17. 23. 18. 14. 19. 18. 23. 14. 23.
 13. 16.] 
Reward = 14.477689743041992
39. [19. 15. 20. 23. 20. 17. 12. 21. 17. 19. 20. 23. 22. 22. 20. 13. 23. 21.
 13. 20.] 
Reward = 14.458112716674805
40. [13. 23. 19. 22. 21. 19. 14. 14. 19. 19. 21. 19. 20. 17. 21. 23. 16. 23.
 13. 19.] 
Reward = 14.424908638000488
41. [17. 23. 15. 22. 23. 23. 18. 21. 19. 19. 17. 21. 23. 18. 16. 13. 20. 12.
 21. 22.] 
Reward = 14.392367362976074
42. [12. 22. 21. 23. 18. 20. 13. 15. 20. 23. 22. 21. 23. 12. 16. 14. 20. 20.
 22. 20.] 
Reward = 14.379427909851074
43. [21. 23. 23. 18. 19. 23. 22. 21. 14. 21. 18. 19. 14. 18. 22. 23. 18. 17.
 17. 16.] 
Reward = 14.377300262451172
44. [20. 22. 18. 21. 22. 20. 15. 13. 21. 23. 21. 23. 22. 17. 19. 18. 23. 13.
 21. 17.] 
Reward = 14.305190086364746
45. [22. 22. 23. 20. 14. 16. 14. 21. 17. 15. 21. 21. 15. 23. 19. 23. 16. 23.
 13. 23.] 
Reward = 14.273801803588867
46. [14. 21. 21. 18. 20. 23. 16. 20. 20. 21. 12. 23. 23. 19. 23. 21. 23. 15.
 15. 21.] 
Reward = 14.242241859436035
47. [21. 23. 23. 22. 15. 21. 16. 22. 17. 13. 15. 21. 17. 22. 19. 13. 17. 23.
 19. 14.] 
Reward = 14.212459564208984
48. [15. 18. 20. 23. 22. 19. 21. 18. 15. 22. 19. 23. 15. 19. 19. 20. 23. 23.
 16. 14.] 
Reward = 14.025251388549805
49. [23. 21. 23. 22. 18. 17. 22. 12. 23. 20. 14. 22. 23. 22. 21. 13. 19. 17.
 17. 14.] 
Reward = 13.837839126586914
50. [20. 23. 23. 15. 21. 17. 23. 23. 18. 23. 23. 19. 20. 17. 17. 22. 21. 12.
 13. 14.] 
Reward = 13.723282814025879
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 0 took 1 hour 43 mins 45 secs



Testing Model 51
[20, 22, 21, 22, 20, 20, 13, 21, 16, 12, 19, 20, 22, 12, 16, 22, 15, 17, 20, 20]
FLOPs = 1950.01M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.69 | Loss = 2.0129
Testing Model 51 took 2 mins and 16 secs

Testing Model 52
[19, 20, 21, 16, 22, 18, 19, 23, 19, 23, 21, 7, 19, 12, 20, 16, 22, 17, 22, 27]
FLOPs = 1976.99M
Top-1 Accuracy = 54.86 | Top-5 Accuracy = 78.52 | Loss = 2.0241
Testing Model 52 took 2 mins and 12 secs

Testing Model 53
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 21, 22, 21, 19, 15, 20, 21, 21, 21]
FLOPs = 1967.31M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.67 | Loss = 2.0181
Testing Model 53 took 2 mins and 14 secs

Testing Model 54
[19, 23, 20, 18, 20, 16, 23, 19, 12, 16, 23, 22, 18, 18, 13, 23, 23, 21, 20, 18]
FLOPs = 2010.39M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.73 | Loss = 2.0167
Testing Model 54 took 2 mins and 22 secs

Testing Model 55
[21, 22, 22, 18, 22, 18, 23, 19, 20, 23, 14, 17, 17, 17, 19, 17, 13, 22, 15, 19]
FLOPs = 1957.97M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.70 | Loss = 2.0194
Testing Model 55 took 2 mins and 5 secs

Testing Model 56
[18, 20, 19, 17, 13, 22, 21, 20, 17, 11, 18, 20, 14, 18, 19, 29, 22, 23, 23, 20]
FLOPs = 1997.03M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.75 | Loss = 2.0134
Testing Model 56 took 2 mins and 17 secs

Testing Model 57
[20, 22, 21, 23, 20, 20, 13, 22, 16, 12, 19, 20, 22, 12, 25, 22, 15, 17, 20, 20]
FLOPs = 2042.84M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.76 | Loss = 2.0138
Testing Model 57 took 2 mins and 0 secs

Testing Model 58
[17, 22, 14, 18, 15, 18, 20, 16, 22, 16, 29, 15, 23, 19, 15, 22, 21, 23, 20, 19]
FLOPs = 1960.80M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.70 | Loss = 2.0154
Testing Model 58 took 2 mins and 19 secs

Testing Model 59
[5, 18, 14, 22, 21, 17, 18, 21, 15, 15, 20, 19, 26, 22, 27, 23, 15, 20, 22, 20]
FLOPs = 2002.28M
Top-1 Accuracy = 54.67 | Top-5 Accuracy = 78.35 | Loss = 2.0418
Testing Model 59 took 2 mins and 11 secs

Testing Model 60
[20, 22, 21, 22, 20, 21, 13, 22, 23, 12, 19, 20, 22, 12, 16, 22, 15, 17, 20, 20]
FLOPs = 2015.76M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.69 | Loss = 2.0143
Testing Model 60 took 2 mins and 13 secs

Testing Model 61
[17, 27, 14, 22, 21, 17, 18, 21, 15, 15, 21, 19, 19, 22, 22, 7, 15, 20, 22, 20]
FLOPs = 1963.43M
Top-1 Accuracy = 54.98 | Top-5 Accuracy = 78.61 | Loss = 2.0245
Testing Model 61 took 2 mins and 3 secs

Testing Model 62
[20, 22, 21, 22, 20, 22, 13, 22, 16, 12, 19, 20, 22, 12, 16, 22, 15, 17, 20, 20]
FLOPs = 1974.31M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.71 | Loss = 2.0143
Testing Model 62 took 2 mins and 16 secs

Testing Model 63
[18, 21, 20, 15, 21, 20, 13, 28, 17, 17, 23, 23, 23, 14, 23, 13, 23, 21, 21, 16]
FLOPs = 2022.40M
Top-1 Accuracy = 54.94 | Top-5 Accuracy = 78.62 | Loss = 2.0223
Testing Model 63 took 2 mins and 14 secs

Testing Model 64
[17, 18, 14, 22, 21, 17, 18, 21, 15, 15, 20, 19, 25, 22, 22, 23, 15, 20, 22, 20]
FLOPs = 2012.13M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.79 | Loss = 2.0120
Testing Model 64 took 2 mins and 11 secs

Testing Model 65
[3, 20, 19, 21, 13, 22, 21, 20, 17, 22, 18, 20, 14, 18, 19, 18, 22, 23, 23, 20]
FLOPs = 1985.46M
Top-1 Accuracy = 54.12 | Top-5 Accuracy = 77.96 | Loss = 2.0702
Testing Model 65 took 1 mins and 59 secs

Testing Model 66
[21, 22, 22, 18, 22, 18, 23, 19, 10, 23, 14, 17, 23, 17, 19, 17, 13, 22, 17, 19]
FLOPs = 1952.36M
Top-1 Accuracy = 55.03 | Top-5 Accuracy = 78.74 | Loss = 2.0192
Testing Model 66 took 2 mins and 12 secs

Testing Model 67
[19, 20, 21, 16, 22, 18, 19, 23, 15, 23, 21, 19, 19, 12, 20, 16, 22, 17, 22, 19]
FLOPs = 1962.13M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.72 | Loss = 2.0149
Testing Model 67 took 2 mins and 13 secs

Testing Model 68
[20, 22, 21, 22, 20, 8, 23, 22, 29, 12, 19, 20, 10, 12, 16, 22, 15, 17, 20, 20]
FLOPs = 1978.42M
Top-1 Accuracy = 54.98 | Top-5 Accuracy = 78.67 | Loss = 2.0169
Testing Model 68 took 2 mins and 11 secs

Testing Model 69
[18, 20, 19, 17, 13, 22, 21, 20, 17, 23, 18, 20, 14, 18, 19, 18, 22, 23, 23, 18]
FLOPs = 1974.47M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.69 | Loss = 2.0165
Testing Model 69 took 1 mins and 58 secs

Testing Model 70
[18, 18, 20, 15, 21, 20, 13, 23, 14, 17, 23, 23, 23, 14, 23, 27, 21, 21, 21, 16]
FLOPs = 2002.56M
Top-1 Accuracy = 55.00 | Top-5 Accuracy = 78.64 | Loss = 2.0196
Testing Model 70 took 1 mins and 58 secs

Testing Model 71
[18, 20, 19, 17, 13, 22, 6, 17, 17, 22, 18, 20, 25, 18, 19, 18, 22, 30, 23, 20]
FLOPs = 2015.84M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.78 | Loss = 2.0142
Testing Model 71 took 2 mins and 4 secs

Testing Model 72
[19, 20, 21, 16, 22, 18, 19, 23, 19, 23, 21, 19, 19, 12, 20, 16, 22, 13, 22, 19]
FLOPs = 1958.53M
Top-1 Accuracy = 54.88 | Top-5 Accuracy = 78.66 | Loss = 2.0189
Testing Model 72 took 2 mins and 13 secs

Testing Model 73
[17, 29, 23, 18, 15, 18, 20, 16, 22, 16, 18, 15, 23, 19, 15, 22, 8, 19, 20, 19]
FLOPs = 1962.44M
Top-1 Accuracy = 54.94 | Top-5 Accuracy = 78.57 | Loss = 2.0244
Testing Model 73 took 2 mins and 1 secs

Testing Model 74
[17, 22, 23, 18, 15, 18, 20, 16, 22, 16, 18, 20, 23, 19, 15, 22, 24, 19, 20, 19]
FLOPs = 2025.14M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.69 | Loss = 2.0156
Testing Model 74 took 2 mins and 9 secs

Testing Model 75
[25, 22, 23, 18, 15, 18, 20, 16, 22, 16, 18, 15, 23, 19, 15, 22, 21, 19, 20, 19]
FLOPs = 2003.04M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.67 | Loss = 2.0142
Testing Model 75 took 2 mins and 13 secs

Testing Model 76
[17, 22, 23, 15, 21, 18, 20, 16, 22, 17, 23, 15, 23, 19, 23, 22, 21, 19, 20, 16]
FLOPs = 2013.17M
Top-1 Accuracy = 54.96 | Top-5 Accuracy = 78.49 | Loss = 2.0228
Testing Model 76 took 2 mins and 2 secs

Testing Model 77
[19, 20, 21, 22, 20, 20, 19, 23, 19, 12, 21, 19, 22, 12, 16, 16, 15, 17, 20, 19]
FLOPs = 1953.11M
Top-1 Accuracy = 55.03 | Top-5 Accuracy = 78.72 | Loss = 2.0159
Testing Model 77 took 2 mins and 18 secs

Testing Model 78
[20, 22, 21, 22, 13, 22, 13, 22, 16, 22, 19, 20, 14, 12, 16, 18, 22, 23, 23, 20]
FLOPs = 2045.06M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.75 | Loss = 2.0106
Testing Model 78 took 2 mins and 11 secs

Testing Model 79
[19, 20, 21, 16, 22, 20, 13, 23, 14, 23, 23, 23, 19, 14, 20, 13, 23, 17, 21, 16]
FLOPs = 1954.12M
Top-1 Accuracy = 54.92 | Top-5 Accuracy = 78.58 | Loss = 2.0234
Testing Model 79 took 2 mins and 14 secs

Testing Model 80
[15, 22, 17, 19, 21, 18, 17, 19, 20, 23, 16, 17, 23, 17, 19, 20, 21, 22, 17, 22]
FLOPs = 1992.35M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.74 | Loss = 2.0172
Testing Model 80 took 2 mins and 14 secs

Testing Model 81
[21, 20, 22, 19, 22, 18, 23, 19, 20, 23, 16, 17, 15, 17, 14, 20, 21, 18, 17, 22]
FLOPs = 1997.81M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.66 | Loss = 2.0161
Testing Model 81 took 2 mins and 12 secs

Testing Model 82
[18, 20, 17, 17, 21, 22, 17, 20, 22, 13, 16, 20, 23, 18, 19, 20, 21, 23, 18, 20]
FLOPs = 1962.22M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.77 | Loss = 2.0138
Testing Model 82 took 2 mins and 9 secs

Testing Model 83
[20, 20, 21, 17, 13, 22, 21, 22, 16, 22, 18, 20, 22, 18, 16, 18, 15, 17, 23, 20]
FLOPs = 1966.64M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.74 | Loss = 2.0156
Testing Model 83 took 2 mins and 18 secs

Testing Model 84
[17, 22, 14, 22, 21, 17, 18, 21, 15, 16, 20, 19, 23, 22, 22, 23, 15, 20, 22, 19]
FLOPs = 2034.36M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.71 | Loss = 2.0142
Testing Model 84 took 2 mins and 17 secs

Testing Model 85
[17, 22, 23, 22, 20, 20, 13, 22, 22, 12, 19, 15, 22, 12, 15, 22, 15, 19, 20, 19]
FLOPs = 1977.42M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.71 | Loss = 2.0134
Testing Model 85 took 2 mins and 13 secs

Testing Model 86
[17, 22, 23, 16, 22, 18, 19, 16, 22, 16, 21, 15, 23, 19, 15, 16, 21, 19, 22, 19]
FLOPs = 1958.09M
Top-1 Accuracy = 55.01 | Top-5 Accuracy = 78.71 | Loss = 2.0148
Testing Model 86 took 2 mins and 8 secs

Testing Model 87
[18, 20, 19, 18, 13, 18, 23, 20, 20, 22, 18, 17, 14, 17, 19, 17, 22, 22, 23, 20]
FLOPs = 1963.54M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.80 | Loss = 2.0141
Testing Model 87 took 1 mins and 56 secs

Testing Model 88
[19, 23, 22, 18, 22, 12, 23, 15, 20, 16, 23, 17, 15, 17, 19, 23, 13, 21, 20, 18]
FLOPs = 1954.18M
Top-1 Accuracy = 55.03 | Top-5 Accuracy = 78.74 | Loss = 2.0179
Testing Model 88 took 2 mins and 10 secs

Testing Model 89
[19, 22, 21, 16, 22, 18, 23, 23, 19, 23, 21, 17, 15, 12, 20, 16, 22, 17, 22, 19]
FLOPs = 2000.33M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.69 | Loss = 2.0169
Testing Model 89 took 2 mins and 10 secs

Testing Model 90
[17, 20, 14, 17, 21, 17, 21, 20, 17, 22, 20, 20, 19, 18, 19, 23, 22, 23, 23, 20]
FLOPs = 1999.97M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.79 | Loss = 2.0132
Testing Model 90 took 2 mins and 9 secs

Testing Model 91
[21, 22, 21, 18, 22, 18, 19, 23, 19, 23, 14, 17, 19, 17, 19, 17, 22, 17, 17, 19]
FLOPs = 1983.58M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.73 | Loss = 2.0188
Testing Model 91 took 2 mins and 0 secs

Testing Model 92
[19, 23, 21, 16, 22, 12, 19, 23, 19, 23, 21, 22, 18, 12, 13, 23, 22, 21, 22, 18]
FLOPs = 2030.48M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.69 | Loss = 2.0175
Testing Model 92 took 2 mins and 0 secs

Testing Model 93
[17, 22, 23, 18, 15, 18, 20, 16, 22, 16, 16, 21, 23, 21, 19, 22, 20, 19, 20, 18]
FLOPs = 2022.77M
Top-1 Accuracy = 55.01 | Top-5 Accuracy = 78.63 | Loss = 2.0187
Testing Model 93 took 2 mins and 13 secs

Testing Model 94
[17, 18, 14, 22, 21, 22, 20, 19, 15, 15, 20, 19, 19, 21, 22, 23, 15, 21, 22, 20]
FLOPs = 1996.58M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.77 | Loss = 2.0139
Testing Model 94 took 2 mins and 9 secs

Testing Model 95
[19, 18, 20, 22, 20, 12, 18, 15, 15, 16, 20, 22, 18, 22, 22, 23, 23, 21, 20, 18]
FLOPs = 2028.92M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.72 | Loss = 2.0141
Testing Model 95 took 2 mins and 15 secs

Testing Model 96
[14, 14, 21, 16, 21, 22, 20, 23, 18, 22, 21, 21, 22, 12, 20, 16, 22, 21, 22, 19]
FLOPs = 1978.79M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.63 | Loss = 2.0182
Testing Model 96 took 2 mins and 10 secs

Testing Model 97
[19, 20, 20, 16, 22, 18, 23, 23, 19, 23, 21, 19, 19, 12, 13, 23, 22, 17, 22, 18]
FLOPs = 1999.94M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.68 | Loss = 2.0193
Testing Model 97 took 2 mins and 15 secs

Testing Model 98
[15, 20, 23, 19, 21, 20, 20, 21, 22, 16, 16, 15, 23, 19, 15, 20, 21, 19, 18, 19]
FLOPs = 1997.32M
Top-1 Accuracy = 54.98 | Top-5 Accuracy = 78.71 | Loss = 2.0174
Testing Model 98 took 1 mins and 58 secs

Testing Model 99
[20, 22, 21, 18, 22, 20, 13, 22, 20, 23, 19, 17, 22, 12, 19, 17, 15, 22, 20, 20]
FLOPs = 2004.06M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.77 | Loss = 2.0130
Testing Model 99 took 2 mins and 13 secs

Testing Model 100
[21, 22, 22, 19, 22, 20, 23, 19, 22, 13, 16, 17, 15, 23, 19, 17, 13, 22, 18, 22]
FLOPs = 2024.42M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.79 | Loss = 2.0127
Testing Model 100 took 2 mins and 10 secs

> Select
Iteration 1 : Showing Top 50 results
1. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.433782577514648
2. [20. 22. 21. 22. 20. 20. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.377861022949219
3. [18. 20. 17. 17. 21. 22. 17. 20. 22. 13. 16. 20. 23. 18. 19. 20. 21. 23.
 18. 20.] 
Reward = 15.347654342651367
4. [19. 23. 20. 18. 20. 12. 23. 15. 12. 16. 23. 22. 18. 18. 13. 23. 23. 21.
 20. 18.] 
Reward = 15.3290376663208
5. [20. 20. 21. 17. 13. 22. 21. 22. 16. 22. 18. 20. 22. 18. 16. 18. 15. 17.
 23. 20.] 
Reward = 15.284989356994629
6. [20. 22. 21. 22. 20. 22. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.278973579406738
7. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 21. 22. 21. 19. 15. 20. 21.
 21. 21.] 
Reward = 15.270090103149414
8. [21. 22. 22. 18. 22. 18. 23. 19. 10. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.258641242980957
9. [19. 20. 21. 22. 20. 20. 19. 23. 19. 12. 21. 19. 22. 12. 16. 16. 15. 17.
 20. 19.] 
Reward = 15.254758834838867
10. [18. 20. 19. 18. 13. 18. 23. 20. 20. 22. 18. 17. 14. 17. 19. 17. 22. 22.
 23. 20.] 
Reward = 15.254735946655273
11. [21. 22. 22. 18. 22. 18. 23. 19. 20. 23. 14. 17. 17. 17. 19. 17. 13. 22.
 15. 19.] 
Reward = 15.25451946258545
12. [15. 20. 17. 19. 21. 20. 17. 21. 22. 13. 16. 20. 23. 23. 14. 20. 21. 18.
 18. 22.] 
Reward = 15.253179550170898
13. [17. 22. 23. 18. 15. 18. 20. 16. 22. 16. 18. 15. 23. 19. 15. 22. 21. 19.
 20. 19.] 
Reward = 15.243968963623047
14. [17. 22. 14. 18. 15. 18. 20. 16. 22. 16. 29. 15. 23. 19. 15. 22. 21. 23.
 20. 19.] 
Reward = 15.24040412902832
15. [19. 23. 22. 18. 22. 12. 23. 15. 20. 16. 23. 17. 15. 17. 19. 23. 13. 21.
 20. 18.] 
Reward = 15.235612869262695
16. [17. 18. 14. 22. 21. 17. 18. 21. 15. 15. 20. 19. 19. 22. 22. 23. 15. 20.
 22. 20.] 
Reward = 15.222638130187988
17. [18. 20. 19. 17. 13. 22. 21. 20. 17. 23. 18. 20. 14. 18. 19. 18. 22. 23.
 23. 18.] 
Reward = 15.222023010253906
18. [19. 20. 21. 16. 22. 18. 19. 23. 15. 23. 21. 19. 19. 12. 20. 16. 22. 17.
 22. 19.] 
Reward = 15.21458625793457
19. [21. 22. 22. 18. 22. 18. 23. 19. 20. 23. 14. 17. 15. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.195782661437988
20. [18. 20. 19. 17. 13. 22. 21. 20. 17. 22. 18. 20. 14. 18. 19. 18. 22. 23.
 23. 20.] 
Reward = 15.190483093261719
21. [18. 21. 20. 15. 21. 20. 13. 23. 14. 17. 23. 23. 23. 14. 23. 13. 23. 21.
 21. 16.] 
Reward = 15.187790870666504
22. [14. 14. 16. 22. 21. 22. 20. 19. 18. 22. 16. 21. 22. 21. 19. 15. 20. 21.
 22. 18.] 
Reward = 15.181986808776855
23. [17. 22. 23. 22. 20. 20. 13. 22. 22. 12. 19. 15. 22. 12. 15. 22. 15. 19.
 20. 19.] 
Reward = 15.171262741088867
24. [17. 22. 23. 16. 22. 18. 19. 16. 22. 16. 21. 15. 23. 19. 15. 16. 21. 19.
 22. 19.] 
Reward = 15.155604362487793
25. [19. 20. 21. 16. 22. 18. 19. 23. 19. 23. 21. 19. 19. 12. 20. 16. 22. 17.
 22. 19.] 
Reward = 15.063105583190918
26. [21. 23. 22. 21. 19. 14. 19. 22. 19. 21. 14. 20. 15. 13. 12. 15. 18. 22.
 22. 22.] 
Reward = 15.048895835876465
27. [17. 27. 14. 22. 21. 17. 18. 21. 15. 15. 21. 19. 19. 22. 22.  7. 15. 20.
 22. 20.] 
Reward = 15.037888526916504
28. [14. 14. 21. 16. 21. 22. 20. 23. 18. 22. 21. 21. 22. 12. 20. 16. 22. 21.
 22. 19.] 
Reward = 15.036185264587402
29. [19. 20. 21. 16. 22. 20. 13. 23. 14. 23. 23. 23. 19. 14. 20. 13. 23. 17.
 21. 16.] 
Reward = 15.015564918518066
30. [15. 22. 17. 19. 21. 18. 17. 19. 20. 23. 16. 17. 23. 17. 19. 20. 21. 22.
 17. 22.] 
Reward = 15.010957717895508
31. [19. 22. 17. 20. 22. 23. 19. 22. 22. 14. 21. 15. 14. 22. 19. 15. 19. 20.
 18. 20.] 
Reward = 15.001506805419922
32. [20. 22. 21. 18. 22. 20. 13. 22. 20. 23. 19. 17. 22. 12. 19. 17. 15. 22.
 20. 20.] 
Reward = 14.997318267822266
33. [21. 13. 20. 21. 22. 17. 17. 23. 23. 20. 15. 13. 17. 20. 22. 21. 23. 14.
 21. 19.] 
Reward = 14.99339771270752
34. [17. 21. 18. 23. 14. 13. 19. 16. 21. 16. 20. 12. 23. 22. 21. 19. 20. 16.
 21. 23.] 
Reward = 14.987858772277832
35. [17. 20. 14. 17. 21. 17. 21. 20. 17. 22. 20. 20. 19. 18. 19. 23. 22. 23.
 23. 20.] 
Reward = 14.981833457946777
36. [17. 29. 23. 18. 15. 18. 20. 16. 22. 16. 18. 15. 23. 19. 15. 22.  8. 19.
 20. 19.] 
Reward = 14.9675931930542
37. [21. 22. 21. 18. 22. 18. 19. 23. 19. 23. 14. 17. 19. 17. 19. 17. 22. 17.
 17. 19.] 
Reward = 14.966984748840332
38. [23. 23. 18. 21. 17. 15. 20. 18. 23. 23. 20. 21. 21. 15. 12. 16. 17. 17.
 20. 22.] 
Reward = 14.956939697265625
39. [17. 18. 14. 22. 21. 22. 20. 19. 15. 15. 20. 19. 19. 21. 22. 23. 15. 21.
 22. 20.] 
Reward = 14.94366455078125
40. [19. 20. 20. 16. 22. 18. 23. 23. 19. 23. 21. 19. 19. 12. 13. 23. 22. 17.
 22. 18.] 
Reward = 14.924141883850098
41. [20. 23. 19. 21. 22. 15. 22. 17. 15. 22. 18. 22. 12. 17. 22. 22. 13. 14.
 23. 21.] 
Reward = 14.916147232055664
42. [14. 19. 21. 15. 20. 15. 22. 23. 23. 20. 16. 22. 17. 18. 19. 20. 22. 19.
 22. 22.] 
Reward = 14.914803504943848
43. [18. 16. 21. 17. 20. 18. 20. 17. 18. 22. 20. 19. 17. 23. 21. 23. 23. 14.
 22. 18.] 
Reward = 14.903217315673828
44. [16. 16. 22. 21. 16. 13. 14. 17. 20. 23. 22. 19. 19. 12. 23. 14. 23. 23.
 18. 23.] 
Reward = 14.902915954589844
45. [19. 20. 21. 16. 22. 18. 19. 23. 19. 23. 21. 19. 19. 12. 20. 16. 22. 13.
 22. 19.] 
Reward = 14.893783569335938
46. [23. 14. 21. 23. 15. 18. 17. 20. 23. 18. 22. 13. 14. 21. 17. 22. 23. 15.
 22. 18.] 
Reward = 14.889446258544922
47. [20. 22. 21. 22. 20.  8. 23. 22. 29. 12. 19. 20. 10. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 14.88257884979248
48. [15. 22. 21. 22. 13. 19. 22. 22. 13. 18. 20. 13. 13. 12. 23. 18. 21. 22.
 22. 23.] 
Reward = 14.851967811584473
49. [21. 20. 22. 19. 22. 18. 23. 19. 20. 23. 16. 17. 15. 17. 14. 20. 21. 18.
 17. 22.] 
Reward = 14.850220680236816
50. [18. 20. 19. 17. 13. 22. 21. 20. 17. 11. 18. 20. 14. 18. 19. 29. 22. 23.
 23. 20.] 
Reward = 14.846819877624512
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 1 took 1 hour 48 mins 47 secs



Testing Model 101
[20, 22, 21, 22, 20, 22, 19, 22, 16, 12, 21, 20, 22, 12, 16, 22, 15, 17, 20, 20]
FLOPs = 2025.25M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.71 | Loss = 2.0131
Testing Model 101 took 1 mins and 59 secs

Testing Model 102
[21, 22, 22, 18, 22, 18, 23, 19, 10, 23, 14, 22, 23, 17, 19, 17, 13, 19, 17, 19]
FLOPs = 1966.97M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.77 | Loss = 2.0187
Testing Model 102 took 2 mins and 13 secs

Testing Model 103
[14, 14, 16, 22, 21, 22, 20, 19, 13, 11, 16, 21, 22, 21, 19, 27, 20, 21, 21, 21]
FLOPs = 1991.14M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.67 | Loss = 2.0162
Testing Model 103 took 1 mins and 59 secs

Testing Model 104
[20, 22, 21, 22, 20, 20, 13, 21, 16, 12, 19, 20, 22, 12, 16, 22, 15, 17, 21, 20]
FLOPs = 1957.86M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.79 | Loss = 2.0119
Testing Model 104 took 2 mins and 9 secs

Testing Model 105
[18, 29, 19, 18, 13, 18, 21, 20, 20, 22, 18, 17, 14, 17, 19, 17, 22, 22, 23, 20]
FLOPs = 2040.07M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.77 | Loss = 2.0123
Testing Model 105 took 1 mins and 59 secs

Testing Model 106
[21, 22, 22, 18, 22, 18, 14, 19, 20, 23, 14, 17, 23, 17, 19, 17, 13, 22, 17, 19]
FLOPs = 1952.48M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.65 | Loss = 2.0195
Testing Model 106 took 2 mins and 14 secs

Testing Model 107
[19, 20, 21, 22, 20, 20, 24, 23, 19, 12, 21, 19, 22, 12, 16, 16, 15, 17, 20, 19]
FLOPs = 1990.99M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.76 | Loss = 2.0162
Testing Model 107 took 2 mins and 7 secs

Testing Model 108
[18, 30, 19, 18, 13, 18, 23, 20, 17, 22, 18, 17, 14, 17, 19, 17, 22, 22, 23, 20]
FLOPs = 2049.12M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.81 | Loss = 2.0157
Testing Model 108 took 2 mins and 14 secs

Testing Model 109
[16, 22, 21, 22, 20, 25, 13, 21, 16, 12, 19, 20, 22, 12, 16, 22, 15, 17, 20, 20]
FLOPs = 1971.46M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.72 | Loss = 2.0156
Testing Model 109 took 2 mins and 5 secs

Testing Model 110
[20, 20, 21, 17, 13, 29, 21, 22, 16, 22, 18, 20, 22, 18, 7, 18, 15, 17, 23, 20]
FLOPs = 1981.44M
Top-1 Accuracy = 54.90 | Top-5 Accuracy = 78.54 | Loss = 2.0212
Testing Model 110 took 2 mins and 13 secs

Testing Model 111
[20, 22, 21, 28, 20, 22, 13, 22, 16, 12, 19, 20, 22, 12, 16, 22, 15, 10, 20, 20]
FLOPs = 2025.77M
Top-1 Accuracy = 54.83 | Top-5 Accuracy = 78.55 | Loss = 2.0245
Testing Model 111 took 2 mins and 0 secs

Testing Model 112
[18, 20, 19, 18, 13, 18, 23, 20, 20, 22, 18, 17, 26, 17, 19, 17, 22, 22, 23, 20]
FLOPs = 2045.33M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.73 | Loss = 2.0127
Testing Model 112 took 2 mins and 5 secs

Testing Model 113
[20, 22, 21, 22, 20, 20, 13, 22, 26, 12, 19, 20, 22, 12, 16, 22, 15, 17, 20, 20]
FLOPs = 2031.22M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.73 | Loss = 2.0124
Testing Model 113 took 2 mins and 10 secs

Testing Model 114
[14, 27, 16, 22, 21, 22, 20, 19, 13, 22, 16, 21, 11, 21, 12, 15, 20, 21, 21, 21]
FLOPs = 1985.82M
Top-1 Accuracy = 55.01 | Top-5 Accuracy = 78.61 | Loss = 2.0210
Testing Model 114 took 2 mins and 7 secs

Testing Model 115
[21, 22, 22, 18, 22, 18, 23, 19, 10, 24, 14, 17, 23, 17, 19, 17, 12, 22, 17, 19]
FLOPs = 1953.07M
Top-1 Accuracy = 55.01 | Top-5 Accuracy = 78.72 | Loss = 2.0207
Testing Model 115 took 1 mins and 58 secs

Testing Model 116
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 9, 26, 15, 20, 21, 21, 21]
FLOPs = 1965.10M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.62 | Loss = 2.0161
Testing Model 116 took 2 mins and 2 secs

Testing Model 117
[19, 18, 23, 22, 20, 20, 19, 23, 19, 12, 21, 19, 4, 12, 16, 16, 15, 29, 20, 19]
FLOPs = 1966.18M
Top-1 Accuracy = 54.85 | Top-5 Accuracy = 78.60 | Loss = 2.0260
Testing Model 117 took 2 mins and 2 secs

Testing Model 118
[18, 20, 17, 17, 21, 22, 17, 20, 22, 13, 16, 20, 23, 18, 19, 20, 21, 23, 21, 20]
FLOPs = 1985.67M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.76 | Loss = 2.0134
Testing Model 118 took 2 mins and 7 secs

Testing Model 119
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 21, 22, 21, 24, 15, 20, 21, 21, 21]
FLOPs = 2004.40M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.63 | Loss = 2.0177
Testing Model 119 took 1 mins and 58 secs

Testing Model 120
[20, 22, 21, 22, 20, 20, 13, 21, 16, 25, 19, 20, 22, 12, 16, 22, 15, 13, 20, 20]
FLOPs = 2006.90M
Top-1 Accuracy = 54.95 | Top-5 Accuracy = 78.65 | Loss = 2.0177
Testing Model 120 took 2 mins and 0 secs

Testing Model 121
[21, 22, 22, 18, 22, 18, 23, 12, 10, 23, 14, 17, 23, 17, 19, 17, 13, 22, 17, 27]
FLOPs = 1968.23M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.75 | Loss = 2.0198
Testing Model 121 took 2 mins and 2 secs

Testing Model 122
[19, 20, 21, 22, 20, 20, 19, 23, 24, 12, 21, 19, 22, 12, 16, 16, 0, 17, 20, 24]
FLOPs = 1961.79M
Top-1 Accuracy = 54.59 | Top-5 Accuracy = 78.25 | Loss = 2.0473
Testing Model 122 took 1 mins and 59 secs

Testing Model 123
[18, 20, 17, 17, 21, 22, 17, 20, 22, 13, 16, 20, 23, 18, 18, 20, 21, 23, 18, 20]
FLOPs = 1955.55M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.71 | Loss = 2.0160
Testing Model 123 took 2 mins and 0 secs

Testing Model 124
[20, 22, 21, 22, 20, 20, 13, 22, 16, 12, 19, 20, 22, 12, 17, 22, 15, 26, 5, 20]
FLOPs = 1951.57M
Top-1 Accuracy = 54.02 | Top-5 Accuracy = 77.84 | Loss = 2.0753
Testing Model 124 took 1 mins and 58 secs

Testing Model 125
[18, 20, 19, 18, 13, 18, 23, 20, 20, 22, 18, 17, 14, 17, 24, 17, 22, 22, 23, 20]
FLOPs = 1998.80M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.76 | Loss = 2.0136
Testing Model 125 took 2 mins and 1 secs

Testing Model 126
[21, 14, 16, 22, 22, 22, 23, 19, 10, 22, 14, 21, 23, 21, 19, 17, 20, 22, 21, 19]
FLOPs = 2016.38M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.76 | Loss = 2.0143
Testing Model 126 took 1 mins and 58 secs

Testing Model 127
[20, 22, 20, 22, 20, 12, 23, 15, 16, 16, 19, 20, 22, 12, 13, 22, 23, 21, 20, 20]
FLOPs = 2003.47M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.75 | Loss = 2.0139
Testing Model 127 took 2 mins and 0 secs

Testing Model 128
[20, 14, 21, 22, 21, 20, 20, 19, 13, 22, 16, 21, 22, 21, 16, 22, 20, 17, 20, 20]
FLOPs = 2024.16M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.72 | Loss = 2.0143
Testing Model 128 took 2 mins and 2 secs

Testing Model 129
[19, 20, 20, 18, 20, 22, 21, 22, 16, 16, 18, 20, 22, 18, 16, 23, 15, 17, 20, 18]
FLOPs = 1957.30M
Top-1 Accuracy = 54.99 | Top-5 Accuracy = 78.64 | Loss = 2.0190
Testing Model 129 took 2 mins and 9 secs

Testing Model 130
[20, 22, 22, 22, 20, 22, 13, 19, 10, 23, 19, 20, 23, 17, 19, 17, 13, 17, 17, 20]
FLOPs = 1991.16M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.71 | Loss = 2.0179
Testing Model 130 took 2 mins and 0 secs

Testing Model 131
[19, 22, 20, 18, 20, 20, 23, 21, 16, 12, 23, 20, 18, 18, 16, 23, 23, 17, 20, 18]
FLOPs = 2009.70M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.66 | Loss = 2.0174
Testing Model 131 took 2 mins and 5 secs

Testing Model 132
[20, 22, 21, 22, 20, 22, 21, 22, 16, 12, 18, 20, 22, 12, 16, 22, 15, 17, 23, 20]
FLOPs = 2043.01M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.77 | Loss = 2.0109
Testing Model 132 took 2 mins and 17 secs

Testing Model 133
[19, 23, 20, 18, 13, 12, 23, 15, 20, 22, 23, 22, 18, 17, 13, 17, 22, 21, 23, 18]
FLOPs = 1978.19M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.73 | Loss = 2.0174
Testing Model 133 took 2 mins and 7 secs

Testing Model 134
[18, 20, 17, 17, 21, 22, 17, 19, 22, 13, 16, 20, 23, 18, 19, 20, 21, 23, 21, 21]
FLOPs = 1985.35M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.75 | Loss = 2.0135
Testing Model 134 took 2 mins and 0 secs

Testing Model 135
[20, 20, 21, 17, 13, 22, 23, 22, 16, 22, 18, 17, 22, 18, 19, 18, 15, 17, 23, 20]
FLOPs = 1977.43M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.71 | Loss = 2.0137
Testing Model 135 took 1 mins and 58 secs

Testing Model 136
[20, 22, 21, 17, 20, 20, 21, 22, 16, 22, 18, 20, 22, 12, 16, 18, 15, 17, 20, 20]
FLOPs = 1951.67M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.72 | Loss = 2.0136
Testing Model 136 took 2 mins and 0 secs

Testing Model 137
[20, 20, 21, 17, 22, 22, 21, 19, 16, 23, 18, 20, 22, 17, 16, 18, 15, 22, 23, 19]
FLOPs = 2026.52M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.81 | Loss = 2.0126
Testing Model 137 took 2 mins and 2 secs

Testing Model 138
[21, 22, 22, 22, 22, 18, 23, 22, 16, 12, 19, 17, 22, 12, 19, 17, 13, 17, 17, 20]
FLOPs = 1970.33M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.72 | Loss = 2.0180
Testing Model 138 took 2 mins and 3 secs

Testing Model 139
[18, 20, 17, 17, 13, 22, 21, 22, 16, 22, 18, 20, 23, 18, 19, 20, 15, 23, 18, 20]
FLOPs = 1951.67M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.72 | Loss = 2.0184
Testing Model 139 took 1 mins and 58 secs

Testing Model 140
[18, 23, 20, 18, 13, 18, 23, 20, 20, 16, 18, 22, 14, 17, 13, 23, 22, 21, 23, 20]
FLOPs = 2002.65M
Top-1 Accuracy = 55.03 | Top-5 Accuracy = 78.68 | Loss = 2.0161
Testing Model 140 took 2 mins and 6 secs

Testing Model 141
[14, 14, 21, 22, 21, 22, 19, 23, 13, 12, 21, 21, 22, 21, 19, 16, 20, 21, 20, 21]
FLOPs = 2024.68M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.73 | Loss = 2.0152
Testing Model 141 took 1 mins and 59 secs

Testing Model 142
[20, 22, 21, 22, 13, 22, 21, 22, 16, 12, 19, 20, 22, 12, 16, 22, 15, 17, 20, 20]
FLOPs = 1987.96M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.70 | Loss = 2.0144
Testing Model 142 took 2 mins and 2 secs

Testing Model 143
[20, 23, 21, 22, 20, 12, 13, 15, 16, 12, 23, 22, 22, 18, 13, 23, 23, 21, 20, 20]
FLOPs = 2026.73M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.73 | Loss = 2.0108
Testing Model 143 took 2 mins and 2 secs

Testing Model 144
[18, 20, 19, 22, 20, 18, 19, 20, 20, 22, 18, 17, 22, 12, 16, 16, 22, 17, 20, 19]
FLOPs = 1964.17M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.72 | Loss = 2.0170
Testing Model 144 took 2 mins and 1 secs

Testing Model 145
[18, 22, 17, 18, 21, 18, 23, 19, 22, 23, 16, 17, 23, 17, 19, 20, 21, 22, 18, 19]
FLOPs = 2025.08M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.80 | Loss = 2.0170
Testing Model 145 took 2 mins and 3 secs

Testing Model 146
[18, 20, 17, 18, 13, 22, 23, 20, 22, 22, 18, 20, 14, 17, 19, 17, 22, 23, 18, 20]
FLOPs = 1970.05M
Top-1 Accuracy = 54.97 | Top-5 Accuracy = 78.72 | Loss = 2.0172
Testing Model 146 took 2 mins and 7 secs

Testing Model 147
[18, 20, 19, 18, 13, 22, 23, 22, 16, 22, 18, 17, 22, 17, 19, 17, 22, 22, 20, 20]
FLOPs = 2010.52M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.75 | Loss = 2.0152
Testing Model 147 took 2 mins and 8 secs

Testing Model 148
[20, 20, 21, 22, 13, 20, 21, 21, 16, 22, 18, 20, 22, 12, 16, 22, 15, 17, 20, 20]
FLOPs = 2001.13M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.68 | Loss = 2.0141
Testing Model 148 took 1 mins and 58 secs

Testing Model 149
[14, 22, 21, 22, 20, 22, 20, 19, 13, 12, 19, 21, 22, 21, 19, 15, 20, 17, 21, 20]
FLOPs = 2022.83M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.71 | Loss = 2.0179
Testing Model 149 took 2 mins and 6 secs

Testing Model 150
[20, 14, 16, 22, 21, 22, 20, 22, 13, 22, 16, 21, 22, 21, 19, 18, 20, 17, 23, 20]
FLOPs = 2012.09M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.72 | Loss = 2.0148
Testing Model 150 took 1 mins and 57 secs

> Select
Iteration 2 : Showing Top 50 results
1. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
2. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.433782577514648
3. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.417957305908203
4. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.416141510009766
5. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 19. 20. 15. 23.
 18. 20.] 
Reward = 15.400196075439453
6. [20. 22. 21. 22. 20. 20. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.377861022949219
7. [18. 20. 17. 17. 21. 22. 17. 20. 22. 13. 16. 20. 23. 18. 19. 20. 21. 23.
 18. 20.] 
Reward = 15.347654342651367
8. [21. 22. 22. 18. 22. 18. 14. 19. 20. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.344067573547363
9. [19. 23. 20. 18. 20. 12. 23. 15. 12. 16. 23. 22. 18. 18. 13. 23. 23. 21.
 20. 18.] 
Reward = 15.3290376663208
10. [20. 20. 21. 17. 13. 22. 21. 22. 16. 22. 18. 20. 22. 18. 16. 18. 15. 17.
 23. 20.] 
Reward = 15.284989356994629
11. [18. 20. 17. 17. 21. 22. 17. 20. 22. 13. 16. 20. 23. 18. 18. 20. 21. 23.
 18. 20.] 
Reward = 15.28398609161377
12. [20. 22. 21. 22. 20. 22. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.278973579406738
13. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 21. 22. 21. 19. 15. 20. 21.
 21. 21.] 
Reward = 15.270090103149414
14. [21. 22. 22. 18. 22. 18. 23. 19. 10. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.258641242980957
15. [19. 20. 21. 22. 20. 20. 19. 23. 19. 12. 21. 19. 22. 12. 16. 16. 15. 17.
 20. 19.] 
Reward = 15.254758834838867
16. [18. 20. 19. 18. 13. 18. 23. 20. 20. 22. 18. 17. 14. 17. 19. 17. 22. 22.
 23. 20.] 
Reward = 15.254735946655273
17. [21. 22. 22. 18. 22. 18. 23. 19. 20. 23. 14. 17. 17. 17. 19. 17. 13. 22.
 15. 19.] 
Reward = 15.25451946258545
18. [15. 20. 17. 19. 21. 20. 17. 21. 22. 13. 16. 20. 23. 23. 14. 20. 21. 18.
 18. 22.] 
Reward = 15.253179550170898
19. [18. 20. 19. 22. 20. 18. 19. 20. 20. 22. 18. 17. 22. 12. 16. 16. 22. 17.
 20. 19.] 
Reward = 15.251967430114746
20. [17. 22. 23. 18. 15. 18. 20. 16. 22. 16. 18. 15. 23. 19. 15. 22. 21. 19.
 20. 19.] 
Reward = 15.243968963623047
21. [17. 22. 14. 18. 15. 18. 20. 16. 22. 16. 29. 15. 23. 19. 15. 22. 21. 23.
 20. 19.] 
Reward = 15.24040412902832
22. [16. 22. 21. 22. 20. 25. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.238067626953125
23. [19. 23. 22. 18. 22. 12. 23. 15. 20. 16. 23. 17. 15. 17. 19. 23. 13. 21.
 20. 18.] 
Reward = 15.235612869262695
24. [17. 18. 14. 22. 21. 17. 18. 21. 15. 15. 20. 19. 19. 22. 22. 23. 15. 20.
 22. 20.] 
Reward = 15.222638130187988
25. [21. 22. 22. 22. 22. 18. 23. 22. 16. 12. 19. 17. 22. 12. 19. 17. 13. 17.
 17. 20.] 
Reward = 15.222392082214355
26. [18. 20. 19. 17. 13. 22. 21. 20. 17. 23. 18. 20. 14. 18. 19. 18. 22. 23.
 23. 18.] 
Reward = 15.222023010253906
27. [18. 20. 17. 17. 21. 22. 17. 19. 22. 13. 16. 20. 23. 18. 19. 20. 21. 23.
 21. 21.] 
Reward = 15.221491813659668
28. [21. 22. 22. 18. 22. 18. 23. 19. 10. 24. 14. 17. 23. 17. 19. 17. 12. 22.
 17. 19.] 
Reward = 15.216036796569824
29. [19. 20. 21. 16. 22. 18. 19. 23. 15. 23. 21. 19. 19. 12. 20. 16. 22. 17.
 22. 19.] 
Reward = 15.21458625793457
30. [21. 22. 22. 18. 22. 18. 23. 19. 20. 23. 14. 17. 15. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.195782661437988
31. [20. 20. 21. 17. 13. 22. 23. 22. 16. 22. 18. 17. 22. 18. 19. 18. 15. 17.
 23. 20.] 
Reward = 15.194707870483398
32. [18. 20. 19. 17. 13. 22. 21. 20. 17. 22. 18. 20. 14. 18. 19. 18. 22. 23.
 23. 20.] 
Reward = 15.190483093261719
33. [18. 21. 20. 15. 21. 20. 13. 23. 14. 17. 23. 23. 23. 14. 23. 13. 23. 21.
 21. 16.] 
Reward = 15.187790870666504
34. [21. 22. 22. 18. 22. 18. 23. 19. 10. 23. 14. 22. 23. 17. 19. 17. 13. 19.
 17. 19.] 
Reward = 15.187155723571777
35. [14. 14. 16. 22. 21. 22. 20. 19. 18. 22. 16. 21. 22. 21. 19. 15. 20. 21.
 22. 18.] 
Reward = 15.181986808776855
36. [18. 20. 17. 17. 21. 22. 17. 20. 22. 13. 16. 20. 23. 18. 19. 20. 21. 23.
 21. 20.] 
Reward = 15.178715705871582
37. [17. 22. 23. 22. 20. 20. 13. 22. 22. 12. 19. 15. 22. 12. 15. 22. 15. 19.
 20. 19.] 
Reward = 15.171262741088867
38. [17. 22. 23. 16. 22. 18. 19. 16. 22. 16. 21. 15. 23. 19. 15. 16. 21. 19.
 22. 19.] 
Reward = 15.155604362487793
39. [19. 20. 20. 18. 20. 22. 21. 22. 16. 16. 18. 20. 22. 18. 16. 23. 15. 17.
 20. 18.] 
Reward = 15.132741928100586
40. [21. 22. 22. 18. 22. 18. 23. 12. 10. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 17. 27.] 
Reward = 15.119366645812988
41. [20. 22. 21. 22. 13. 22. 21. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.115280151367188
42. [19. 23. 20. 18. 13. 12. 23. 15. 20. 22. 23. 22. 18. 17. 13. 17. 22. 21.
 23. 18.] 
Reward = 15.096837043762207
43. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 21. 22. 21. 24. 15. 20. 21.
 21. 21.] 
Reward = 15.079720497131348
44. [19. 20. 21. 16. 22. 18. 19. 23. 19. 23. 21. 19. 19. 12. 20. 16. 22. 17.
 22. 19.] 
Reward = 15.063105583190918
45. [21. 23. 22. 21. 19. 14. 19. 22. 19. 21. 14. 20. 15. 13. 12. 15. 18. 22.
 22. 22.] 
Reward = 15.048895835876465
46. [17. 27. 14. 22. 21. 17. 18. 21. 15. 15. 21. 19. 19. 22. 22.  7. 15. 20.
 22. 20.] 
Reward = 15.037888526916504
47. [14. 14. 21. 16. 21. 22. 20. 23. 18. 22. 21. 21. 22. 12. 20. 16. 22. 21.
 22. 19.] 
Reward = 15.036185264587402
48. [14. 14. 16. 22. 21. 22. 20. 19. 13. 11. 16. 21. 22. 21. 19. 27. 20. 21.
 21. 21.] 
Reward = 15.027470588684082
49. [19. 20. 21. 16. 22. 20. 13. 23. 14. 23. 23. 23. 19. 14. 20. 13. 23. 17.
 21. 16.] 
Reward = 15.015564918518066
50. [15. 22. 17. 19. 21. 18. 17. 19. 20. 23. 16. 17. 23. 17. 19. 20. 21. 22.
 17. 22.] 
Reward = 15.010957717895508
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 2 took 1 hour 43 mins 31 secs



Testing Model 151
[20, 22, 21, 22, 20, 20, 13, 21, 16, 12, 28, 20, 22, 12, 16, 22, 15, 17, 21, 20]
FLOPs = 2029.07M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.74 | Loss = 2.0145
Testing Model 151 took 2 mins and 0 secs

Testing Model 152
[23, 20, 17, 17, 13, 22, 21, 29, 16, 22, 18, 20, 23, 18, 19, 20, 15, 23, 18, 20]
FLOPs = 2041.30M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.70 | Loss = 2.0154
Testing Model 152 took 2 mins and 7 secs

Testing Model 153
[20, 20, 21, 17, 13, 22, 21, 22, 16, 22, 18, 21, 22, 18, 16, 18, 15, 17, 23, 20]
FLOPs = 1974.07M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.76 | Loss = 2.0133
Testing Model 153 took 1 mins and 55 secs

Testing Model 154
[18, 20, 17, 17, 21, 22, 17, 20, 22, 22, 16, 20, 23, 18, 19, 20, 21, 23, 18, 20]
FLOPs = 2018.72M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.75 | Loss = 2.0162
Testing Model 154 took 2 mins and 1 secs

Testing Model 155
[19, 23, 20, 21, 20, 12, 23, 15, 12, 16, 23, 22, 18, 18, 13, 23, 23, 21, 20, 18]
FLOPs = 2012.00M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.71 | Loss = 2.0174
Testing Model 155 took 2 mins and 5 secs

Testing Model 156
[14, 14, 16, 22, 21, 30, 20, 19, 13, 22, 16, 23, 22, 9, 26, 15, 20, 21, 21, 14]
FLOPs = 1977.58M
Top-1 Accuracy = 54.79 | Top-5 Accuracy = 78.37 | Loss = 2.0340
Testing Model 156 took 2 mins and 1 secs

Testing Model 157
[18, 20, 17, 17, 21, 22, 27, 20, 22, 20, 16, 20, 23, 18, 19, 5, 21, 23, 18, 20]
FLOPs = 2000.36M
Top-1 Accuracy = 54.87 | Top-5 Accuracy = 78.55 | Loss = 2.0308
Testing Model 157 took 2 mins and 1 secs

Testing Model 158
[19, 23, 20, 18, 20, 12, 23, 15, 12, 16, 23, 29, 18, 18, 13, 23, 23, 21, 20, 18]
FLOPs = 2019.31M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.74 | Loss = 2.0190
Testing Model 158 took 2 mins and 11 secs

Testing Model 159
[20, 22, 27, 17, 20, 12, 21, 22, 16, 22, 18, 20, 22, 12, 19, 18, 15, 25, 20, 15]
FLOPs = 2033.86M
Top-1 Accuracy = 54.96 | Top-5 Accuracy = 78.61 | Loss = 2.0210
Testing Model 159 took 2 mins and 2 secs

Testing Model 160
[17, 20, 17, 18, 21, 22, 17, 20, 22, 13, 16, 20, 23, 18, 19, 20, 21, 23, 18, 20]
FLOPs = 1979.20M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.77 | Loss = 2.0128
Testing Model 160 took 2 mins and 4 secs

Testing Model 161
[14, 14, 16, 22, 21, 22, 30, 19, 13, 18, 16, 23, 22, 12, 26, 15, 20, 21, 21, 21]
FLOPs = 2031.02M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.67 | Loss = 2.0183
Testing Model 161 took 2 mins and 4 secs

Testing Model 162
[16, 22, 22, 18, 22, 18, 14, 19, 20, 23, 14, 17, 23, 17, 19, 17, 20, 22, 17, 19]
FLOPs = 1971.44M
Top-1 Accuracy = 55.00 | Top-5 Accuracy = 78.77 | Loss = 2.0178
Testing Model 162 took 2 mins and 4 secs

Testing Model 163
[18, 20, 17, 17, 13, 22, 21, 25, 16, 22, 18, 20, 23, 18, 19, 20, 15, 23, 18, 20]
FLOPs = 1976.53M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.72 | Loss = 2.0173
Testing Model 163 took 1 mins and 59 secs

Testing Model 164
[20, 20, 21, 17, 13, 22, 21, 22, 20, 22, 18, 20, 19, 18, 16, 18, 15, 17, 23, 20]
FLOPs = 1972.26M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.71 | Loss = 2.0152
Testing Model 164 took 2 mins and 2 secs

Testing Model 165
[14, 14, 16, 22, 21, 21, 20, 25, 13, 22, 19, 23, 22, 4, 26, 15, 20, 21, 21, 21]
FLOPs = 2000.34M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.58 | Loss = 2.0215
Testing Model 165 took 2 mins and 5 secs

Testing Model 166
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 3, 23, 22, 9, 26, 15, 26, 21, 21, 21]
FLOPs = 1954.01M
Top-1 Accuracy = 54.92 | Top-5 Accuracy = 78.49 | Loss = 2.0266
Testing Model 166 took 2 mins and 3 secs

Testing Model 167
[18, 20, 17, 17, 21, 22, 17, 20, 22, 13, 16, 20, 23, 23, 19, 20, 21, 23, 18, 20]
FLOPs = 1996.91M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.69 | Loss = 2.0136
Testing Model 167 took 1 mins and 55 secs

Testing Model 168
[18, 20, 17, 17, 21, 22, 17, 20, 22, 13, 13, 20, 23, 18, 19, 20, 21, 23, 28, 20]
FLOPs = 2030.61M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.78 | Loss = 2.0137
Testing Model 168 took 2 mins and 2 secs

Testing Model 169
[18, 20, 17, 17, 13, 23, 21, 22, 16, 22, 18, 20, 23, 18, 19, 20, 15, 23, 18, 20]
FLOPs = 1959.47M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.74 | Loss = 2.0156
Testing Model 169 took 1 mins and 52 secs

Testing Model 170
[20, 22, 21, 17, 20, 20, 21, 22, 16, 22, 18, 20, 22, 12, 18, 18, 15, 17, 20, 20]
FLOPs = 1963.58M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.67 | Loss = 2.0143
Testing Model 170 took 2 mins and 2 secs

Testing Model 171
[21, 22, 22, 18, 22, 18, 14, 19, 20, 23, 14, 17, 23, 17, 30, 17, 13, 22, 17, 19]
FLOPs = 2038.39M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.68 | Loss = 2.0167
Testing Model 171 took 2 mins and 3 secs

Testing Model 172
[21, 22, 22, 18, 22, 18, 14, 19, 20, 23, 14, 17, 23, 17, 19, 17, 13, 22, 20, 19]
FLOPs = 1975.31M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.71 | Loss = 2.0138
Testing Model 172 took 2 mins and 2 secs

Testing Model 173
[20, 22, 21, 22, 20, 26, 13, 21, 16, 12, 19, 20, 22, 12, 16, 22, 15, 17, 21, 20]
FLOPs = 2006.48M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.71 | Loss = 2.0149
Testing Model 173 took 2 mins and 2 secs

Testing Model 174
[20, 20, 21, 17, 15, 22, 21, 22, 16, 22, 18, 21, 22, 18, 16, 18, 15, 17, 23, 20]
FLOPs = 1984.37M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.76 | Loss = 2.0142
Testing Model 174 took 2 mins and 0 secs

Testing Model 175
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 29, 23, 22, 9, 26, 15, 20, 21, 21, 7]
FLOPs = 1964.78M
Top-1 Accuracy = 53.75 | Top-5 Accuracy = 77.83 | Loss = 2.0767
Testing Model 175 took 1 mins and 59 secs

Testing Model 176
[19, 23, 20, 18, 20, 20, 23, 22, 16, 16, 23, 20, 22, 18, 13, 23, 15, 17, 20, 20]
FLOPs = 2027.04M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.69 | Loss = 2.0157
Testing Model 176 took 2 mins and 0 secs

Testing Model 177
[19, 23, 20, 18, 20, 22, 23, 20, 12, 13, 16, 20, 18, 18, 13, 20, 21, 21, 20, 20]
FLOPs = 1955.69M
Top-1 Accuracy = 55.04 | Top-5 Accuracy = 78.72 | Loss = 2.0144
Testing Model 177 took 2 mins and 2 secs

Testing Model 178
[21, 22, 22, 18, 21, 22, 14, 19, 22, 13, 16, 20, 23, 17, 19, 20, 21, 22, 18, 19]
FLOPs = 2034.33M
Top-1 Accuracy = 55.04 | Top-5 Accuracy = 78.79 | Loss = 2.0152
Testing Model 178 took 2 mins and 11 secs

Testing Model 179
[20, 22, 21, 17, 20, 20, 21, 22, 16, 22, 19, 20, 22, 12, 16, 22, 15, 17, 23, 20]
FLOPs = 2010.53M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.71 | Loss = 2.0143
Testing Model 179 took 1 mins and 54 secs

Testing Model 180
[20, 14, 21, 22, 21, 20, 20, 19, 16, 22, 16, 20, 22, 9, 26, 15, 20, 21, 20, 20]
FLOPs = 2021.28M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.72 | Loss = 2.0155
Testing Model 180 took 2 mins and 4 secs

Testing Model 181
[20, 22, 21, 22, 13, 22, 21, 22, 16, 12, 19, 20, 22, 12, 16, 22, 15, 17, 23, 20]
FLOPs = 2012.66M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.72 | Loss = 2.0128
Testing Model 181 took 2 mins and 2 secs

Testing Model 182
[14, 22, 21, 17, 20, 20, 21, 22, 13, 22, 16, 23, 22, 12, 26, 15, 20, 17, 21, 21]
FLOPs = 2016.12M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.67 | Loss = 2.0171
Testing Model 182 took 2 mins and 2 secs

Testing Model 183
[20, 22, 21, 17, 13, 20, 21, 22, 16, 22, 19, 20, 22, 18, 16, 18, 15, 17, 20, 20]
FLOPs = 1955.33M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.68 | Loss = 2.0138
Testing Model 183 took 1 mins and 59 secs

Testing Model 184
[20, 20, 22, 18, 22, 18, 21, 19, 20, 23, 18, 20, 23, 18, 16, 18, 13, 17, 23, 20]
FLOPs = 2025.52M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.67 | Loss = 2.0148
Testing Model 184 took 2 mins and 2 secs

Testing Model 185
[19, 23, 20, 17, 20, 20, 21, 15, 16, 22, 23, 20, 18, 18, 13, 18, 23, 17, 20, 18]
FLOPs = 1951.96M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.62 | Loss = 2.0192
Testing Model 185 took 2 mins and 11 secs

Testing Model 186
[20, 23, 20, 18, 20, 20, 21, 22, 12, 22, 18, 20, 22, 12, 16, 23, 15, 21, 20, 18]
FLOPs = 1995.50M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.69 | Loss = 2.0147
Testing Model 186 took 2 mins and 1 secs

Testing Model 187
[20, 22, 21, 17, 21, 22, 17, 20, 16, 22, 18, 20, 23, 12, 16, 20, 21, 17, 20, 20]
FLOPs = 1989.27M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.70 | Loss = 2.0153
Testing Model 187 took 2 mins and 8 secs

Testing Model 188
[18, 20, 22, 18, 13, 18, 14, 22, 20, 22, 18, 20, 23, 18, 19, 20, 13, 22, 17, 19]
FLOPs = 1958.31M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.69 | Loss = 2.0175
Testing Model 188 took 1 mins and 58 secs

Testing Model 189
[19, 22, 20, 17, 20, 20, 23, 22, 16, 22, 23, 22, 18, 18, 13, 18, 23, 17, 20, 18]
FLOPs = 2028.84M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.69 | Loss = 2.0174
Testing Model 189 took 2 mins and 1 secs

Testing Model 190
[20, 22, 16, 22, 20, 22, 21, 22, 13, 22, 18, 23, 22, 9, 16, 18, 15, 17, 21, 21]
FLOPs = 1991.14M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.74 | Loss = 2.0157
Testing Model 190 took 2 mins and 6 secs

Testing Model 191
[18, 20, 21, 22, 13, 20, 13, 22, 16, 22, 19, 20, 23, 12, 19, 20, 15, 23, 18, 20]
FLOPs = 2007.44M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.74 | Loss = 2.0157
Testing Model 191 took 2 mins and 5 secs

Testing Model 192
[18, 20, 17, 17, 13, 22, 21, 22, 16, 22, 18, 20, 23, 18, 16, 18, 15, 23, 23, 20]
FLOPs = 1959.80M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.75 | Loss = 2.0132
Testing Model 192 took 2 mins and 1 secs

Testing Model 193
[20, 22, 21, 22, 20, 20, 13, 22, 16, 22, 19, 20, 22, 12, 16, 18, 15, 17, 20, 20]
FLOPs = 1995.59M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.71 | Loss = 2.0155
Testing Model 193 took 2 mins and 4 secs

Testing Model 194
[20, 23, 21, 22, 20, 12, 13, 22, 16, 12, 19, 20, 18, 12, 16, 23, 23, 21, 20, 20]
FLOPs = 1989.10M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.82 | Loss = 2.0126
Testing Model 194 took 2 mins and 9 secs

Testing Model 195
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 19, 23, 22, 9, 26, 22, 15, 21, 20, 20]
FLOPs = 1981.34M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.70 | Loss = 2.0168
Testing Model 195 took 2 mins and 9 secs

Testing Model 196
[19, 22, 20, 18, 22, 18, 14, 15, 20, 23, 23, 22, 18, 17, 13, 23, 23, 21, 20, 19]
FLOPs = 2032.77M
Top-1 Accuracy = 55.03 | Top-5 Accuracy = 78.73 | Loss = 2.0145
Testing Model 196 took 1 mins and 56 secs

Testing Model 197
[20, 22, 16, 22, 20, 20, 20, 19, 16, 22, 19, 20, 22, 12, 16, 22, 20, 21, 21, 20]
FLOPs = 2046.54M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.74 | Loss = 2.0132
Testing Model 197 took 2 mins and 2 secs

Testing Model 198
[20, 22, 20, 18, 20, 12, 23, 21, 16, 12, 19, 20, 22, 18, 16, 23, 15, 21, 21, 18]
FLOPs = 1950.00M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.77 | Loss = 2.0180
Testing Model 198 took 2 mins and 2 secs

Testing Model 199
[20, 22, 21, 17, 13, 22, 13, 21, 16, 22, 18, 20, 22, 18, 19, 22, 15, 23, 18, 20]
FLOPs = 1983.26M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.74 | Loss = 2.0137
Testing Model 199 took 2 mins and 1 secs

Testing Model 200
[20, 22, 20, 17, 20, 20, 21, 22, 12, 22, 18, 20, 22, 12, 13, 23, 23, 21, 20, 18]
FLOPs = 2001.36M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.71 | Loss = 2.0165
Testing Model 200 took 2 mins and 6 secs

> Select
Iteration 3 : Showing Top 50 results
1. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
2. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.433782577514648
3. [19. 23. 20. 17. 20. 20. 21. 15. 16. 22. 23. 20. 18. 18. 13. 18. 23. 17.
 20. 18.] 
Reward = 15.420969009399414
4. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.417957305908203
5. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.416141510009766
6. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 19. 20. 15. 23.
 18. 20.] 
Reward = 15.400196075439453
7. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.381397247314453
8. [20. 22. 21. 22. 20. 20. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.377861022949219
9. [20. 22. 21. 17. 13. 20. 21. 22. 16. 22. 19. 20. 22. 18. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.373248100280762
10. [20. 22. 20. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 23. 15. 21.
 21. 18.] 
Reward = 15.366320610046387
11. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 18. 18. 15. 17.
 20. 20.] 
Reward = 15.349184036254883
12. [18. 20. 17. 17. 21. 22. 17. 20. 22. 13. 16. 20. 23. 18. 19. 20. 21. 23.
 18. 20.] 
Reward = 15.347654342651367
13. [21. 22. 22. 18. 22. 18. 14. 19. 20. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.344067573547363
14. [19. 23. 20. 18. 20. 12. 23. 15. 12. 16. 23. 22. 18. 18. 13. 23. 23. 21.
 20. 18.] 
Reward = 15.3290376663208
15. [18. 20. 17. 17. 13. 23. 21. 22. 16. 22. 18. 20. 23. 18. 19. 20. 15. 23.
 18. 20.] 
Reward = 15.289787292480469
16. [20. 20. 21. 17. 13. 22. 21. 22. 20. 22. 18. 20. 19. 18. 16. 18. 15. 17.
 23. 20.] 
Reward = 15.288784980773926
17. [20. 20. 21. 17. 13. 22. 21. 22. 16. 22. 18. 20. 22. 18. 16. 18. 15. 17.
 23. 20.] 
Reward = 15.284989356994629
18. [18. 20. 17. 17. 21. 22. 17. 20. 22. 13. 16. 20. 23. 18. 18. 20. 21. 23.
 18. 20.] 
Reward = 15.28398609161377
19. [20. 22. 21. 22. 20. 22. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.278973579406738
20. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 21. 22. 21. 19. 15. 20. 21.
 21. 21.] 
Reward = 15.270090103149414
21. [20. 20. 21. 17. 13. 22. 21. 22. 16. 22. 18. 21. 22. 18. 16. 18. 15. 17.
 23. 20.] 
Reward = 15.261762619018555
22. [21. 22. 22. 18. 22. 18. 23. 19. 10. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.258641242980957
23. [19. 20. 21. 22. 20. 20. 19. 23. 19. 12. 21. 19. 22. 12. 16. 16. 15. 17.
 20. 19.] 
Reward = 15.254758834838867
24. [18. 20. 19. 18. 13. 18. 23. 20. 20. 22. 18. 17. 14. 17. 19. 17. 22. 22.
 23. 20.] 
Reward = 15.254735946655273
25. [21. 22. 22. 18. 22. 18. 23. 19. 20. 23. 14. 17. 17. 17. 19. 17. 13. 22.
 15. 19.] 
Reward = 15.25451946258545
26. [15. 20. 17. 19. 21. 20. 17. 21. 22. 13. 16. 20. 23. 23. 14. 20. 21. 18.
 18. 22.] 
Reward = 15.253179550170898
27. [18. 20. 19. 22. 20. 18. 19. 20. 20. 22. 18. 17. 22. 12. 16. 16. 22. 17.
 20. 19.] 
Reward = 15.251967430114746
28. [21. 22. 22. 18. 22. 18. 14. 19. 20. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 20. 19.] 
Reward = 15.248624801635742
29. [19. 23. 20. 18. 20. 22. 23. 20. 12. 13. 16. 20. 18. 18. 13. 20. 21. 21.
 20. 20.] 
Reward = 15.247174263000488
30. [17. 22. 23. 18. 15. 18. 20. 16. 22. 16. 18. 15. 23. 19. 15. 22. 21. 19.
 20. 19.] 
Reward = 15.243968963623047
31. [17. 22. 14. 18. 15. 18. 20. 16. 22. 16. 29. 15. 23. 19. 15. 22. 21. 23.
 20. 19.] 
Reward = 15.24040412902832
32. [16. 22. 21. 22. 20. 25. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.238067626953125
33. [19. 23. 22. 18. 22. 12. 23. 15. 20. 16. 23. 17. 15. 17. 19. 23. 13. 21.
 20. 18.] 
Reward = 15.235612869262695
34. [18. 20. 22. 18. 13. 18. 14. 22. 20. 22. 18. 20. 23. 18. 19. 20. 13. 22.
 17. 19.] 
Reward = 15.231287956237793
35. [17. 18. 14. 22. 21. 17. 18. 21. 15. 15. 20. 19. 19. 22. 22. 23. 15. 20.
 22. 20.] 
Reward = 15.222638130187988
36. [21. 22. 22. 22. 22. 18. 23. 22. 16. 12. 19. 17. 22. 12. 19. 17. 13. 17.
 17. 20.] 
Reward = 15.222392082214355
37. [18. 20. 19. 17. 13. 22. 21. 20. 17. 23. 18. 20. 14. 18. 19. 18. 22. 23.
 23. 18.] 
Reward = 15.222023010253906
38. [18. 20. 17. 17. 21. 22. 17. 19. 22. 13. 16. 20. 23. 18. 19. 20. 21. 23.
 21. 21.] 
Reward = 15.221491813659668
39. [21. 22. 22. 18. 22. 18. 23. 19. 10. 24. 14. 17. 23. 17. 19. 17. 12. 22.
 17. 19.] 
Reward = 15.216036796569824
40. [19. 20. 21. 16. 22. 18. 19. 23. 15. 23. 21. 19. 19. 12. 20. 16. 22. 17.
 22. 19.] 
Reward = 15.21458625793457
41. [21. 22. 22. 18. 22. 18. 23. 19. 20. 23. 14. 17. 15. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.195782661437988
42. [20. 20. 21. 17. 13. 22. 23. 22. 16. 22. 18. 17. 22. 18. 19. 18. 15. 17.
 23. 20.] 
Reward = 15.194707870483398
43. [18. 20. 19. 17. 13. 22. 21. 20. 17. 22. 18. 20. 14. 18. 19. 18. 22. 23.
 23. 20.] 
Reward = 15.190483093261719
44. [18. 21. 20. 15. 21. 20. 13. 23. 14. 17. 23. 23. 23. 14. 23. 13. 23. 21.
 21. 16.] 
Reward = 15.187790870666504
45. [21. 22. 22. 18. 22. 18. 23. 19. 10. 23. 14. 22. 23. 17. 19. 17. 13. 19.
 17. 19.] 
Reward = 15.187155723571777
46. [14. 14. 16. 22. 21. 22. 20. 19. 18. 22. 16. 21. 22. 21. 19. 15. 20. 21.
 22. 18.] 
Reward = 15.181986808776855
47. [18. 20. 17. 17. 21. 22. 17. 20. 22. 13. 16. 20. 23. 18. 19. 20. 21. 23.
 21. 20.] 
Reward = 15.178715705871582
48. [17. 22. 23. 22. 20. 20. 13. 22. 22. 12. 19. 15. 22. 12. 15. 22. 15. 19.
 20. 19.] 
Reward = 15.171262741088867
49. [17. 22. 23. 16. 22. 18. 19. 16. 22. 16. 21. 15. 23. 19. 15. 16. 21. 19.
 22. 19.] 
Reward = 15.155604362487793
50. [20. 23. 21. 22. 20. 12. 13. 22. 16. 12. 19. 20. 18. 12. 16. 23. 23. 21.
 20. 20.] 
Reward = 15.142501831054688
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 3 took 1 hour 42 mins 37 secs



Testing Model 201
[20, 22, 21, 22, 20, 20, 13, 21, 16, 12, 19, 20, 22, 12, 16, 22, 15, 17, 21, 29]
FLOPs = 2037.56M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.80 | Loss = 2.0134
Testing Model 201 took 2 mins and 6 secs

Testing Model 202
[19, 23, 20, 17, 20, 20, 21, 15, 16, 22, 23, 20, 18, 18, 13, 18, 23, 17, 24, 18]
FLOPs = 1985.12M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.66 | Loss = 2.0177
Testing Model 202 took 1 mins and 56 secs

Testing Model 203
[19, 23, 26, 17, 20, 20, 21, 15, 16, 22, 23, 20, 18, 18, 13, 18, 23, 17, 20, 18]
FLOPs = 2035.63M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.66 | Loss = 2.0200
Testing Model 203 took 2 mins and 2 secs

Testing Model 204
[18, 20, 17, 17, 13, 22, 21, 22, 16, 22, 18, 20, 23, 18, 16, 12, 30, 23, 23, 20]
FLOPs = 2035.29M
Top-1 Accuracy = 55.00 | Top-5 Accuracy = 78.70 | Loss = 2.0177
Testing Model 204 took 2 mins and 0 secs

Testing Model 205
[20, 22, 20, 18, 20, 12, 23, 21, 16, 23, 19, 20, 22, 18, 16, 8, 22, 21, 21, 25]
FLOPs = 2037.99M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.73 | Loss = 2.0190
Testing Model 205 took 1 mins and 57 secs

Testing Model 206
[20, 22, 21, 22, 20, 20, 13, 22, 16, 12, 19, 20, 22, 12, 16, 22, 19, 17, 20, 20]
FLOPs = 1985.49M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.71 | Loss = 2.0158
Testing Model 206 took 2 mins and 2 secs

Testing Model 207
[24, 22, 22, 24, 20, 20, 21, 22, 16, 7, 18, 20, 22, 12, 16, 18, 15, 17, 20, 20]
FLOPs = 2019.32M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.70 | Loss = 2.0150
Testing Model 207 took 2 mins and 3 secs

Testing Model 208
[20, 22, 21, 22, 20, 20, 13, 21, 16, 12, 19, 20, 22, 12, 16, 22, 15, 17, 29, 20]
FLOPs = 2029.71M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.74 | Loss = 2.0129
Testing Model 208 took 2 mins and 5 secs

Testing Model 209
[20, 22, 20, 18, 25, 12, 23, 21, 16, 12, 19, 20, 22, 18, 16, 23, 15, 21, 21, 18]
FLOPs = 1985.25M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.74 | Loss = 2.0167
Testing Model 209 took 2 mins and 0 secs

Testing Model 210
[11, 20, 17, 17, 13, 22, 18, 22, 20, 22, 18, 30, 23, 18, 16, 18, 13, 23, 23, 20]
FLOPs = 2006.63M
Top-1 Accuracy = 54.91 | Top-5 Accuracy = 78.56 | Loss = 2.0263
Testing Model 210 took 1 mins and 54 secs

Testing Model 211
[5, 22, 20, 18, 20, 17, 23, 21, 16, 12, 19, 20, 22, 18, 16, 23, 29, 21, 21, 18]
FLOPs = 2009.20M
Top-1 Accuracy = 54.66 | Top-5 Accuracy = 78.27 | Loss = 2.0442
Testing Model 211 took 2 mins and 1 secs

Testing Model 212
[14, 14, 10, 22, 21, 22, 20, 19, 13, 22, 16, 28, 22, 9, 26, 15, 20, 27, 21, 21]
FLOPs = 1985.40M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.62 | Loss = 2.0232
Testing Model 212 took 1 mins and 58 secs

Testing Model 213
[29, 20, 17, 17, 13, 22, 21, 22, 16, 22, 18, 20, 23, 18, 16, 18, 15, 20, 23, 20]
FLOPs = 1990.30M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.73 | Loss = 2.0127
Testing Model 213 took 2 mins and 5 secs

Testing Model 214
[18, 20, 17, 17, 13, 22, 21, 22, 16, 22, 17, 20, 23, 18, 19, 20, 15, 23, 18, 30]
FLOPs = 2036.85M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.77 | Loss = 2.0139
Testing Model 214 took 1 mins and 56 secs

Testing Model 215
[18, 20, 17, 17, 13, 22, 21, 22, 16, 22, 18, 20, 23, 18, 19, 20, 15, 23, 27, 20]
FLOPs = 2027.59M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.73 | Loss = 2.0146
Testing Model 215 took 2 mins and 0 secs

Testing Model 216
[18, 20, 17, 17, 13, 22, 21, 22, 16, 22, 18, 20, 27, 18, 16, 18, 15, 23, 23, 20]
FLOPs = 1990.13M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.73 | Loss = 2.0145
Testing Model 216 took 2 mins and 6 secs

Testing Model 217
[18, 25, 17, 17, 13, 11, 21, 22, 16, 26, 18, 20, 23, 17, 16, 18, 15, 23, 23, 20]
FLOPs = 1962.90M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.73 | Loss = 2.0147
Testing Model 217 took 1 mins and 56 secs

Testing Model 218
[20, 22, 21, 22, 28, 20, 13, 21, 16, 12, 19, 20, 22, 14, 16, 22, 2, 17, 20, 20]
FLOPs = 1958.74M
Top-1 Accuracy = 54.83 | Top-5 Accuracy = 78.39 | Loss = 2.0321
Testing Model 218 took 2 mins and 2 secs

Testing Model 219
[20, 22, 21, 17, 20, 20, 21, 22, 16, 16, 19, 20, 22, 12, 16, 18, 15, 28, 20, 20]
FLOPs = 2014.24M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.72 | Loss = 2.0142
Testing Model 219 took 2 mins and 5 secs

Testing Model 220
[20, 22, 21, 22, 20, 20, 13, 21, 16, 12, 19, 20, 22, 12, 16, 22, 15, 17, 24, 20]
FLOPs = 1983.17M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.71 | Loss = 2.0120
Testing Model 220 took 2 mins and 1 secs

Testing Model 221
[20, 22, 21, 22, 20, 5, 18, 21, 16, 12, 19, 20, 22, 24, 16, 22, 15, 17, 20, 23]
FLOPs = 2003.01M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.76 | Loss = 2.0130
Testing Model 221 took 2 mins and 6 secs

Testing Model 222
[14, 16, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 9, 26, 15, 20, 21, 21, 21]
FLOPs = 1985.28M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.65 | Loss = 2.0151
Testing Model 222 took 1 mins and 59 secs

Testing Model 223
[18, 20, 17, 17, 13, 22, 21, 22, 4, 22, 18, 20, 23, 18, 27, 20, 15, 23, 18, 20]
FLOPs = 1954.25M
Top-1 Accuracy = 55.00 | Top-5 Accuracy = 78.69 | Loss = 2.0199
Testing Model 223 took 2 mins and 7 secs

Testing Model 224
[14, 14, 19, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 9, 26, 15, 20, 21, 21, 21]
FLOPs = 2005.25M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.62 | Loss = 2.0180
Testing Model 224 took 1 mins and 54 secs

Testing Model 225
[17, 20, 17, 17, 13, 22, 21, 22, 16, 27, 18, 20, 23, 18, 19, 20, 15, 23, 18, 20]
FLOPs = 1987.02M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.73 | Loss = 2.0165
Testing Model 225 took 1 mins and 59 secs

Testing Model 226
[20, 14, 21, 22, 20, 22, 13, 21, 13, 22, 19, 20, 22, 12, 26, 22, 20, 17, 20, 21]
FLOPs = 2044.23M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.77 | Loss = 2.0136
Testing Model 226 took 2 mins and 7 secs

Testing Model 227
[20, 22, 17, 17, 13, 22, 21, 22, 16, 22, 19, 20, 23, 18, 16, 22, 15, 23, 21, 20]
FLOPs = 2007.89M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.74 | Loss = 2.0138
Testing Model 227 took 1 mins and 57 secs

Testing Model 228
[20, 22, 20, 18, 20, 12, 21, 22, 16, 12, 18, 20, 22, 18, 16, 23, 15, 21, 23, 18]
FLOPs = 1953.11M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.71 | Loss = 2.0155
Testing Model 228 took 2 mins and 4 secs

Testing Model 229
[20, 22, 21, 22, 20, 20, 21, 22, 16, 22, 19, 20, 22, 12, 16, 18, 15, 17, 20, 20]
FLOPs = 2046.63M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.73 | Loss = 2.0131
Testing Model 229 took 1 mins and 56 secs

Testing Model 230
[19, 20, 17, 17, 20, 22, 21, 15, 16, 22, 23, 20, 18, 18, 16, 18, 23, 23, 23, 18]
FLOPs = 1985.69M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.65 | Loss = 2.0153
Testing Model 230 took 2 mins and 1 secs

Testing Model 231
[14, 22, 20, 22, 21, 22, 23, 19, 13, 12, 19, 23, 22, 9, 16, 23, 20, 21, 21, 18]
FLOPs = 2038.98M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.63 | Loss = 2.0190
Testing Model 231 took 2 mins and 1 secs

Testing Model 232
[20, 23, 20, 17, 20, 20, 21, 15, 16, 12, 23, 20, 18, 18, 16, 22, 23, 17, 20, 20]
FLOPs = 1952.07M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.76 | Loss = 2.0143
Testing Model 232 took 2 mins and 2 secs

Testing Model 233
[20, 22, 21, 17, 13, 20, 21, 22, 16, 22, 18, 20, 23, 18, 16, 18, 15, 17, 23, 20]
FLOPs = 1980.54M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.69 | Loss = 2.0125
Testing Model 233 took 1 mins and 59 secs

Testing Model 234
[20, 14, 16, 22, 21, 22, 13, 19, 13, 22, 19, 20, 22, 9, 26, 22, 20, 17, 20, 21]
FLOPs = 1953.35M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.75 | Loss = 2.0146
Testing Model 234 took 2 mins and 0 secs

Testing Model 235
[20, 22, 21, 17, 20, 20, 21, 19, 13, 22, 16, 23, 22, 12, 26, 15, 20, 17, 20, 20]
FLOPs = 2003.19M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.64 | Loss = 2.0155
Testing Model 235 took 2 mins and 4 secs

Testing Model 236
[20, 22, 21, 22, 20, 20, 21, 22, 16, 12, 18, 20, 22, 12, 16, 18, 15, 17, 20, 20]
FLOPs = 1974.01M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.69 | Loss = 2.0149
Testing Model 236 took 1 mins and 57 secs

Testing Model 237
[20, 22, 21, 18, 20, 12, 21, 21, 16, 22, 19, 20, 22, 18, 16, 23, 15, 17, 21, 20]
FLOPs = 1995.63M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.76 | Loss = 2.0126
Testing Model 237 took 2 mins and 4 secs

Testing Model 238
[18, 20, 17, 17, 13, 22, 21, 22, 16, 22, 18, 20, 23, 18, 19, 20, 15, 23, 23, 20]
FLOPs = 1991.96M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.73 | Loss = 2.0144
Testing Model 238 took 2 mins and 0 secs

Testing Model 239
[18, 22, 21, 22, 20, 20, 13, 22, 16, 12, 18, 20, 22, 18, 19, 22, 15, 17, 21, 20]
FLOPs = 2006.00M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.78 | Loss = 2.0135
Testing Model 239 took 1 mins and 59 secs

Testing Model 240
[20, 22, 21, 18, 20, 12, 23, 21, 16, 12, 19, 20, 22, 18, 16, 22, 15, 21, 21, 20]
FLOPs = 1970.56M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.82 | Loss = 2.0131
Testing Model 240 took 2 mins and 7 secs

Testing Model 241
[20, 22, 21, 22, 13, 20, 21, 22, 16, 22, 19, 20, 22, 12, 16, 22, 15, 17, 20, 20]
FLOPs = 2038.25M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.66 | Loss = 2.0147
Testing Model 241 took 2 mins and 0 secs

Testing Model 242
[18, 20, 17, 22, 20, 22, 21, 22, 16, 22, 18, 20, 22, 12, 16, 22, 15, 23, 18, 20]
FLOPs = 2032.42M
Top-1 Accuracy = 55.02 | Top-5 Accuracy = 78.74 | Loss = 2.0164
Testing Model 242 took 2 mins and 0 secs

Testing Model 243
[20, 22, 21, 18, 20, 12, 23, 22, 16, 22, 19, 20, 22, 18, 16, 18, 15, 17, 20, 18]
FLOPs = 1961.79M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.68 | Loss = 2.0191
Testing Model 243 took 1 mins and 59 secs

Testing Model 244
[18, 20, 20, 17, 13, 22, 21, 22, 16, 22, 18, 20, 18, 18, 13, 20, 23, 23, 20, 20]
FLOPs = 1990.43M
Top-1 Accuracy = 55.03 | Top-5 Accuracy = 78.73 | Loss = 2.0158
Testing Model 244 took 2 mins and 0 secs

Testing Model 245
[20, 14, 21, 22, 20, 22, 20, 22, 16, 12, 16, 20, 22, 9, 26, 22, 15, 21, 21, 21]
FLOPs = 2017.43M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.79 | Loss = 2.0159
Testing Model 245 took 2 mins and 2 secs

Testing Model 246
[20, 22, 21, 22, 20, 20, 21, 22, 16, 12, 19, 20, 22, 12, 16, 22, 15, 17, 21, 20]
FLOPs = 2017.89M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.75 | Loss = 2.0145
Testing Model 246 took 2 mins and 2 secs

Testing Model 247
[19, 23, 21, 17, 13, 20, 21, 22, 16, 22, 23, 20, 22, 18, 16, 18, 23, 17, 20, 20]
FLOPs = 2044.44M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.70 | Loss = 2.0137
Testing Model 247 took 2 mins and 2 secs

Testing Model 248
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 12, 16, 18, 15, 17, 20, 18]
FLOPs = 1950.70M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.67 | Loss = 2.0190
Testing Model 248 took 2 mins and 2 secs

Testing Model 249
[20, 14, 16, 22, 21, 20, 20, 19, 16, 22, 19, 23, 22, 9, 16, 22, 15, 21, 21, 21]
FLOPs = 1953.23M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.78 | Loss = 2.0122
Testing Model 249 took 2 mins and 0 secs

Testing Model 250
[20, 20, 21, 17, 20, 22, 21, 22, 16, 22, 18, 20, 22, 18, 19, 18, 15, 23, 20, 20]
FLOPs = 2046.88M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.77 | Loss = 2.0098
Testing Model 250 took 2 mins and 3 secs

> Select
Iteration 4 : Showing Top 50 results
1. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.574835777282715
2. [20. 14. 16. 22. 21. 22. 13. 19. 13. 22. 19. 20. 22.  9. 26. 22. 20. 17.
 20. 21.] 
Reward = 15.494070053100586
3. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
4. [20. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.471687316894531
5. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.433782577514648
6. [18. 25. 17. 17. 13. 11. 21. 22. 16. 26. 18. 20. 23. 17. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.428112983703613
7. [20. 14. 16. 22. 21. 20. 20. 19. 16. 22. 19. 23. 22.  9. 16. 22. 15. 21.
 21. 21.] 
Reward = 15.423428535461426
8. [19. 23. 20. 17. 20. 20. 21. 15. 16. 22. 23. 20. 18. 18. 13. 18. 23. 17.
 20. 18.] 
Reward = 15.420969009399414
9. [20. 22. 21. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 22. 15. 21.
 21. 20.] 
Reward = 15.418389320373535
10. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.417957305908203
11. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.416141510009766
12. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 19. 20. 15. 23.
 18. 20.] 
Reward = 15.400196075439453
13. [20. 22. 20. 18. 20. 12. 21. 22. 16. 12. 18. 20. 22. 18. 16. 23. 15. 21.
 23. 18.] 
Reward = 15.392885208129883
14. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.381397247314453
15. [20. 22. 21. 22. 20. 20. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.377861022949219
16. [20. 22. 21. 18. 20. 12. 23. 22. 16. 22. 19. 20. 22. 18. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.376130104064941
17. [20. 22. 21. 17. 13. 20. 21. 22. 16. 22. 19. 20. 22. 18. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.373248100280762
18. [20. 22. 20. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 23. 15. 21.
 21. 18.] 
Reward = 15.366320610046387
19. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 18. 18. 15. 17.
 20. 20.] 
Reward = 15.349184036254883
20. [18. 20. 17. 17. 21. 22. 17. 20. 22. 13. 16. 20. 23. 18. 19. 20. 21. 23.
 18. 20.] 
Reward = 15.347654342651367
21. [21. 22. 22. 18. 22. 18. 14. 19. 20. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.344067573547363
22. [19. 23. 20. 18. 20. 12. 23. 15. 12. 16. 23. 22. 18. 18. 13. 23. 23. 21.
 20. 18.] 
Reward = 15.3290376663208
23. [20. 22. 21. 22. 20. 20. 21. 22. 16. 12. 18. 20. 22. 12. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.305963516235352
24. [18. 20. 17. 17. 13. 23. 21. 22. 16. 22. 18. 20. 23. 18. 19. 20. 15. 23.
 18. 20.] 
Reward = 15.289787292480469
25. [20. 20. 21. 17. 13. 22. 21. 22. 20. 22. 18. 20. 19. 18. 16. 18. 15. 17.
 23. 20.] 
Reward = 15.288784980773926
26. [20. 20. 21. 17. 13. 22. 21. 22. 16. 22. 18. 20. 22. 18. 16. 18. 15. 17.
 23. 20.] 
Reward = 15.284989356994629
27. [18. 20. 17. 17. 21. 22. 17. 20. 22. 13. 16. 20. 23. 18. 18. 20. 21. 23.
 18. 20.] 
Reward = 15.28398609161377
28. [20. 22. 21. 22. 20. 22. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.278973579406738
29. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 21. 22. 21. 19. 15. 20. 21.
 21. 21.] 
Reward = 15.270090103149414
30. [20. 20. 21. 17. 13. 22. 21. 22. 16. 22. 18. 21. 22. 18. 16. 18. 15. 17.
 23. 20.] 
Reward = 15.261762619018555
31. [21. 22. 22. 18. 22. 18. 23. 19. 10. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.258641242980957
32. [19. 20. 21. 22. 20. 20. 19. 23. 19. 12. 21. 19. 22. 12. 16. 16. 15. 17.
 20. 19.] 
Reward = 15.254758834838867
33. [18. 20. 19. 18. 13. 18. 23. 20. 20. 22. 18. 17. 14. 17. 19. 17. 22. 22.
 23. 20.] 
Reward = 15.254735946655273
34. [21. 22. 22. 18. 22. 18. 23. 19. 20. 23. 14. 17. 17. 17. 19. 17. 13. 22.
 15. 19.] 
Reward = 15.25451946258545
35. [15. 20. 17. 19. 21. 20. 17. 21. 22. 13. 16. 20. 23. 23. 14. 20. 21. 18.
 18. 22.] 
Reward = 15.253179550170898
36. [18. 20. 19. 22. 20. 18. 19. 20. 20. 22. 18. 17. 22. 12. 16. 16. 22. 17.
 20. 19.] 
Reward = 15.251967430114746
37. [21. 22. 22. 18. 22. 18. 14. 19. 20. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 20. 19.] 
Reward = 15.248624801635742
38. [19. 23. 20. 18. 20. 22. 23. 20. 12. 13. 16. 20. 18. 18. 13. 20. 21. 21.
 20. 20.] 
Reward = 15.247174263000488
39. [17. 22. 23. 18. 15. 18. 20. 16. 22. 16. 18. 15. 23. 19. 15. 22. 21. 19.
 20. 19.] 
Reward = 15.243968963623047
40. [17. 22. 14. 18. 15. 18. 20. 16. 22. 16. 29. 15. 23. 19. 15. 22. 21. 23.
 20. 19.] 
Reward = 15.24040412902832
41. [16. 22. 21. 22. 20. 25. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.238067626953125
42. [19. 23. 22. 18. 22. 12. 23. 15. 20. 16. 23. 17. 15. 17. 19. 23. 13. 21.
 20. 18.] 
Reward = 15.235612869262695
43. [18. 20. 22. 18. 13. 18. 14. 22. 20. 22. 18. 20. 23. 18. 19. 20. 13. 22.
 17. 19.] 
Reward = 15.231287956237793
44. [17. 18. 14. 22. 21. 17. 18. 21. 15. 15. 20. 19. 19. 22. 22. 23. 15. 20.
 22. 20.] 
Reward = 15.222638130187988
45. [21. 22. 22. 22. 22. 18. 23. 22. 16. 12. 19. 17. 22. 12. 19. 17. 13. 17.
 17. 20.] 
Reward = 15.222392082214355
46. [18. 20. 19. 17. 13. 22. 21. 20. 17. 23. 18. 20. 14. 18. 19. 18. 22. 23.
 23. 18.] 
Reward = 15.222023010253906
47. [18. 20. 17. 17. 21. 22. 17. 19. 22. 13. 16. 20. 23. 18. 19. 20. 21. 23.
 21. 21.] 
Reward = 15.221491813659668
48. [21. 22. 22. 18. 22. 18. 23. 19. 10. 24. 14. 17. 23. 17. 19. 17. 12. 22.
 17. 19.] 
Reward = 15.216036796569824
49. [19. 20. 21. 16. 22. 18. 19. 23. 15. 23. 21. 19. 19. 12. 20. 16. 22. 17.
 22. 19.] 
Reward = 15.21458625793457
50. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 24. 20.] 
Reward = 15.197202682495117
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 4 took 1 hour 41 mins 30 secs



Testing Model 251
[14, 19, 16, 22, 21, 22, 6, 19, 13, 22, 16, 25, 22, 9, 28, 15, 20, 21, 21, 21]
FLOPs = 1974.22M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.61 | Loss = 2.0189
Testing Model 251 took 2 mins and 4 secs

Testing Model 252
[19, 23, 30, 17, 20, 17, 21, 15, 9, 22, 23, 20, 18, 18, 13, 18, 23, 17, 20, 18]
FLOPs = 2029.09M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.56 | Loss = 2.0188
Testing Model 252 took 2 mins and 2 secs

Testing Model 253
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 19, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1963.29M
Top-1 Accuracy = 55.24 | Top-5 Accuracy = 78.77 | Loss = 2.0139
Testing Model 253 took 2 mins and 3 secs

Testing Model 254
[19, 23, 20, 17, 20, 20, 21, 15, 16, 22, 29, 20, 18, 18, 1, 18, 23, 17, 26, 18]
FLOPs = 2004.51M
Top-1 Accuracy = 54.57 | Top-5 Accuracy = 78.33 | Loss = 2.0397
Testing Model 254 took 2 mins and 3 secs

Testing Model 255
[17, 14, 16, 22, 21, 20, 20, 5, 16, 22, 19, 23, 22, 9, 29, 22, 15, 21, 21, 21]
FLOPs = 1962.79M
Top-1 Accuracy = 54.90 | Top-5 Accuracy = 78.60 | Loss = 2.0234
Testing Model 255 took 1 mins and 54 secs

Testing Model 256
[20, 22, 21, 18, 20, 12, 23, 21, 28, 12, 19, 20, 12, 18, 16, 22, 15, 28, 9, 20]
FLOPs = 1981.37M
Top-1 Accuracy = 54.53 | Top-5 Accuracy = 78.36 | Loss = 2.0426
Testing Model 256 took 1 mins and 59 secs

Testing Model 257
[19, 23, 20, 17, 20, 20, 21, 15, 16, 22, 23, 20, 18, 18, 13, 18, 23, 19, 20, 18]
FLOPs = 1967.83M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.61 | Loss = 2.0180
Testing Model 257 took 2 mins and 1 secs

Testing Model 258
[18, 25, 17, 17, 13, 11, 21, 22, 16, 26, 18, 20, 23, 17, 16, 18, 15, 30, 23, 20]
FLOPs = 2030.63M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.73 | Loss = 2.0143
Testing Model 258 took 1 mins and 57 secs

Testing Model 259
[20, 16, 16, 22, 30, 13, 29, 19, 13, 22, 19, 20, 22, 9, 26, 6, 20, 17, 20, 21]
FLOPs = 2001.31M
Top-1 Accuracy = 54.83 | Top-5 Accuracy = 78.52 | Loss = 2.0272
Testing Model 259 took 1 mins and 57 secs

Testing Model 260
[20, 23, 20, 17, 20, 20, 27, 15, 16, 12, 23, 20, 18, 18, 16, 22, 23, 17, 20, 20]
FLOPs = 2002.65M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.71 | Loss = 2.0151
Testing Model 260 took 2 mins and 0 secs

Testing Model 261
[20, 22, 21, 22, 21, 20, 13, 21, 16, 12, 19, 20, 22, 12, 16, 22, 15, 17, 21, 29]
FLOPs = 2044.15M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.80 | Loss = 2.0120
Testing Model 261 took 2 mins and 2 secs

Testing Model 262
[20, 22, 21, 30, 20, 20, 13, 21, 16, 12, 19, 20, 22, 12, 16, 22, 15, 17, 10, 20]
FLOPs = 2024.35M
Top-1 Accuracy = 54.74 | Top-5 Accuracy = 78.42 | Loss = 2.0371
Testing Model 262 took 2 mins and 2 secs

Testing Model 263
[19, 23, 20, 17, 20, 20, 20, 15, 16, 22, 23, 29, 18, 18, 13, 18, 23, 17, 20, 18]
FLOPs = 2024.24M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.66 | Loss = 2.0175
Testing Model 263 took 2 mins and 5 secs

Testing Model 264
[19, 23, 20, 17, 20, 20, 21, 15, 16, 22, 23, 20, 18, 18, 23, 18, 23, 17, 20, 18]
FLOPs = 2015.27M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.67 | Loss = 2.0186
Testing Model 264 took 1 mins and 57 secs

Testing Model 265
[20, 22, 21, 27, 20, 20, 13, 21, 16, 12, 19, 20, 22, 12, 16, 22, 13, 17, 11, 20]
FLOPs = 1963.83M
Top-1 Accuracy = 54.76 | Top-5 Accuracy = 78.45 | Loss = 2.0343
Testing Model 265 took 2 mins and 5 secs

Testing Model 266
[14, 14, 16, 17, 21, 22, 20, 19, 10, 22, 16, 30, 22, 9, 29, 15, 23, 21, 21, 21]
FLOPs = 1967.64M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.63 | Loss = 2.0220
Testing Model 266 took 1 mins and 57 secs

Testing Model 267
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 9, 26, 23, 20, 24, 21, 21]
FLOPs = 2049.18M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.70 | Loss = 2.0173
Testing Model 267 took 2 mins and 2 secs

Testing Model 268
[20, 22, 21, 22, 20, 20, 13, 21, 16, 12, 19, 20, 22, 12, 20, 22, 15, 17, 20, 20]
FLOPs = 1977.37M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.74 | Loss = 2.0148
Testing Model 268 took 2 mins and 2 secs

Testing Model 269
[20, 14, 16, 22, 21, 20, 20, 19, 8, 22, 19, 30, 22, 9, 16, 22, 15, 21, 21, 21]
FLOPs = 1977.65M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.71 | Loss = 2.0133
Testing Model 269 took 1 mins and 57 secs

Testing Model 270
[21, 23, 20, 17, 20, 20, 21, 15, 16, 12, 23, 20, 18, 18, 16, 22, 23, 17, 20, 20]
FLOPs = 1957.41M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.70 | Loss = 2.0142
Testing Model 270 took 1 mins and 59 secs

Testing Model 271
[14, 21, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 9, 26, 15, 20, 21, 21, 21]
FLOPs = 2036.41M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.65 | Loss = 2.0153
Testing Model 271 took 2 mins and 1 secs

Testing Model 272
[19, 23, 20, 17, 20, 20, 19, 22, 16, 22, 29, 20, 18, 18, 13, 18, 23, 17, 20, 18]
FLOPs = 2043.12M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.64 | Loss = 2.0190
Testing Model 272 took 2 mins and 0 secs

Testing Model 273
[20, 22, 21, 22, 20, 20, 13, 21, 20, 12, 19, 20, 22, 12, 16, 22, 15, 17, 21, 20]
FLOPs = 1983.93M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.70 | Loss = 2.0121
Testing Model 273 took 2 mins and 5 secs

Testing Model 274
[20, 14, 16, 22, 21, 22, 13, 19, 13, 22, 19, 20, 29, 9, 26, 22, 20, 17, 20, 21]
FLOPs = 2011.97M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.68 | Loss = 2.0157
Testing Model 274 took 1 mins and 59 secs

Testing Model 275
[18, 25, 17, 17, 13, 11, 21, 22, 16, 26, 18, 20, 27, 17, 16, 18, 15, 23, 23, 20]
FLOPs = 1993.23M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.77 | Loss = 2.0128
Testing Model 275 took 1 mins and 59 secs

Testing Model 276
[20, 23, 21, 17, 20, 20, 21, 21, 16, 12, 19, 20, 18, 18, 16, 22, 23, 17, 21, 20]
FLOPs = 1990.17M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.72 | Loss = 2.0157
Testing Model 276 took 1 mins and 59 secs

Testing Model 277
[19, 25, 20, 17, 13, 11, 21, 22, 16, 26, 18, 20, 23, 18, 16, 18, 23, 23, 20, 18]
FLOPs = 2029.22M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.67 | Loss = 2.0173
Testing Model 277 took 2 mins and 1 secs

Testing Model 278
[20, 14, 20, 22, 20, 22, 20, 15, 13, 12, 23, 20, 22, 18, 16, 15, 23, 21, 21, 21]
FLOPs = 1971.01M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.75 | Loss = 2.0131
Testing Model 278 took 1 mins and 59 secs

Testing Model 279
[20, 22, 16, 18, 21, 20, 23, 21, 16, 12, 19, 23, 22, 18, 16, 22, 15, 21, 21, 21]
FLOPs = 1993.39M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.78 | Loss = 2.0126
Testing Model 279 took 1 mins and 58 secs

Testing Model 280
[20, 23, 20, 17, 20, 20, 21, 15, 16, 22, 23, 20, 18, 18, 13, 22, 23, 17, 20, 18]
FLOPs = 1984.43M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.65 | Loss = 2.0196
Testing Model 280 took 2 mins and 0 secs

Testing Model 281
[19, 23, 16, 22, 21, 20, 21, 19, 16, 22, 23, 20, 18, 18, 16, 18, 15, 17, 20, 18]
FLOPs = 1982.33M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.64 | Loss = 2.0189
Testing Model 281 took 2 mins and 3 secs

Testing Model 282
[20, 22, 20, 17, 21, 20, 21, 21, 16, 22, 19, 20, 22, 12, 16, 22, 15, 21, 20, 21]
FLOPs = 2009.88M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.77 | Loss = 2.0121
Testing Model 282 took 2 mins and 2 secs

Testing Model 283
[19, 23, 20, 22, 20, 20, 21, 15, 16, 22, 23, 20, 22, 12, 13, 18, 23, 17, 21, 18]
FLOPs = 2042.76M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.60 | Loss = 2.0164
Testing Model 283 took 2 mins and 2 secs

Testing Model 284
[20, 23, 20, 17, 20, 20, 20, 19, 13, 12, 16, 23, 18, 18, 16, 22, 20, 21, 20, 21]
FLOPs = 1951.36M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.76 | Loss = 2.0123
Testing Model 284 took 2 mins and 2 secs

Testing Model 285
[20, 22, 21, 22, 20, 12, 23, 21, 16, 12, 19, 20, 22, 12, 16, 22, 15, 21, 21, 20]
FLOPs = 2009.19M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.84 | Loss = 2.0116
Testing Model 285 took 2 mins and 4 secs

Testing Model 286
[20, 22, 21, 17, 20, 20, 21, 15, 16, 22, 23, 20, 18, 18, 16, 22, 15, 17, 20, 20]
FLOPs = 1966.77M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.66 | Loss = 2.0150
Testing Model 286 took 2 mins and 11 secs

Testing Model 287
[20, 22, 16, 22, 20, 22, 13, 19, 16, 22, 19, 20, 22, 12, 16, 22, 20, 17, 20, 20]
FLOPs = 1976.61M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.71 | Loss = 2.0160
Testing Model 287 took 2 mins and 0 secs

Testing Model 288
[20, 23, 20, 18, 20, 20, 23, 21, 16, 12, 23, 20, 18, 18, 16, 22, 23, 17, 21, 20]
FLOPs = 2042.46M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.69 | Loss = 2.0129
Testing Model 288 took 2 mins and 8 secs

Testing Model 289
[20, 22, 20, 22, 20, 20, 21, 21, 16, 12, 23, 20, 22, 12, 16, 22, 15, 17, 21, 20]
FLOPs = 2025.95M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.72 | Loss = 2.0119
Testing Model 289 took 2 mins and 12 secs

Testing Model 290
[20, 22, 21, 22, 20, 20, 13, 21, 16, 12, 19, 20, 22, 12, 16, 22, 15, 21, 21, 20]
FLOPs = 1991.74M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.81 | Loss = 2.0112
Testing Model 290 took 2 mins and 0 secs

Testing Model 291
[20, 22, 21, 18, 20, 20, 23, 21, 16, 12, 23, 20, 22, 18, 16, 18, 15, 21, 21, 20]
FLOPs = 2022.81M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.81 | Loss = 2.0133
Testing Model 291 took 2 mins and 6 secs

Testing Model 292
[20, 22, 21, 22, 20, 12, 23, 21, 16, 12, 19, 20, 22, 18, 16, 22, 15, 17, 21, 20]
FLOPs = 2012.09M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.77 | Loss = 2.0140
Testing Model 292 took 2 mins and 2 secs

Testing Model 293
[20, 25, 17, 17, 21, 11, 21, 22, 16, 22, 18, 20, 23, 17, 16, 18, 20, 23, 23, 20]
FLOPs = 2020.68M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.76 | Loss = 2.0114
Testing Model 293 took 2 mins and 1 secs

Testing Model 294
[20, 22, 16, 22, 20, 22, 13, 19, 16, 12, 19, 20, 22, 18, 26, 22, 15, 17, 21, 21]
FLOPs = 2008.55M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.79 | Loss = 2.0149
Testing Model 294 took 2 mins and 5 secs

Testing Model 295
[14, 22, 20, 17, 21, 20, 21, 21, 16, 22, 23, 23, 22, 9, 16, 18, 20, 21, 20, 18]
FLOPs = 2002.27M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.62 | Loss = 2.0197
Testing Model 295 took 2 mins and 4 secs

Testing Model 296
[20, 23, 20, 17, 20, 20, 21, 15, 16, 22, 23, 20, 18, 18, 16, 18, 23, 17, 20, 18]
FLOPs = 1974.02M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.64 | Loss = 2.0178
Testing Model 296 took 2 mins and 1 secs

Testing Model 297
[20, 14, 16, 22, 21, 22, 20, 19, 16, 22, 19, 23, 22, 9, 26, 22, 15, 21, 21, 21]
FLOPs = 2041.21M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.77 | Loss = 2.0143
Testing Model 297 took 2 mins and 10 secs

Testing Model 298
[20, 14, 20, 17, 21, 22, 21, 15, 16, 22, 19, 20, 22, 9, 26, 22, 23, 17, 20, 20]
FLOPs = 1961.16M
Top-1 Accuracy = 55.04 | Top-5 Accuracy = 78.74 | Loss = 2.0164
Testing Model 298 took 1 mins and 57 secs

Testing Model 299
[20, 22, 21, 22, 20, 20, 13, 21, 16, 22, 23, 20, 22, 12, 16, 18, 15, 17, 20, 20]
FLOPs = 2017.00M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.75 | Loss = 2.0132
Testing Model 299 took 2 mins and 9 secs

Testing Model 300
[20, 22, 20, 22, 20, 20, 13, 15, 16, 12, 23, 20, 18, 18, 16, 18, 23, 17, 20, 20]
FLOPs = 1955.13M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.73 | Loss = 2.0147
Testing Model 300 took 2 mins and 4 secs

> Select
Iteration 5 : Showing Top 50 results
1. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.574835777282715
2. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.54874038696289
3. [20. 23. 20. 17. 20. 20. 20. 19. 13. 12. 16. 23. 18. 18. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.531522750854492
4. [20. 14. 16. 22. 21. 22. 13. 19. 13. 22. 19. 20. 22.  9. 26. 22. 20. 17.
 20. 21.] 
Reward = 15.494070053100586
5. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
6. [20. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.471687316894531
7. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.433782577514648
8. [18. 25. 17. 17. 13. 11. 21. 22. 16. 26. 18. 20. 23. 17. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.428112983703613
9. [20. 14. 16. 22. 21. 20. 20. 19. 16. 22. 19. 23. 22.  9. 16. 22. 15. 21.
 21. 21.] 
Reward = 15.423428535461426
10. [19. 23. 20. 17. 20. 20. 21. 15. 16. 22. 23. 20. 18. 18. 13. 18. 23. 17.
 20. 18.] 
Reward = 15.420969009399414
11. [20. 22. 21. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 22. 15. 21.
 21. 20.] 
Reward = 15.418389320373535
12. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.417957305908203
13. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.416141510009766
14. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 19. 20. 15. 23.
 18. 20.] 
Reward = 15.400196075439453
15. [20. 22. 20. 18. 20. 12. 21. 22. 16. 12. 18. 20. 22. 18. 16. 23. 15. 21.
 23. 18.] 
Reward = 15.392885208129883
16. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.381397247314453
17. [20. 22. 21. 22. 20. 20. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.377861022949219
18. [20. 22. 21. 18. 20. 12. 23. 22. 16. 22. 19. 20. 22. 18. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.376130104064941
19. [20. 22. 21. 17. 13. 20. 21. 22. 16. 22. 19. 20. 22. 18. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.373248100280762
20. [20. 22. 20. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 23. 15. 21.
 21. 18.] 
Reward = 15.366320610046387
21. [20. 22. 20. 22. 20. 20. 13. 15. 16. 12. 23. 20. 18. 18. 16. 18. 23. 17.
 20. 20.] 
Reward = 15.36349105834961
22. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 18. 18. 15. 17.
 20. 20.] 
Reward = 15.349184036254883
23. [18. 20. 17. 17. 21. 22. 17. 20. 22. 13. 16. 20. 23. 18. 19. 20. 21. 23.
 18. 20.] 
Reward = 15.347654342651367
24. [21. 22. 22. 18. 22. 18. 14. 19. 20. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.344067573547363
25. [19. 23. 20. 18. 20. 12. 23. 15. 12. 16. 23. 22. 18. 18. 13. 23. 23. 21.
 20. 18.] 
Reward = 15.3290376663208
26. [20. 22. 21. 22. 20. 20. 13. 21. 20. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.319889068603516
27. [20. 22. 21. 22. 20. 20. 21. 22. 16. 12. 18. 20. 22. 12. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.305963516235352
28. [21. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.291874885559082
29. [18. 20. 17. 17. 13. 23. 21. 22. 16. 22. 18. 20. 23. 18. 19. 20. 15. 23.
 18. 20.] 
Reward = 15.289787292480469
30. [20. 20. 21. 17. 13. 22. 21. 22. 20. 22. 18. 20. 19. 18. 16. 18. 15. 17.
 23. 20.] 
Reward = 15.288784980773926
31. [20. 20. 21. 17. 13. 22. 21. 22. 16. 22. 18. 20. 22. 18. 16. 18. 15. 17.
 23. 20.] 
Reward = 15.284989356994629
32. [18. 20. 17. 17. 21. 22. 17. 20. 22. 13. 16. 20. 23. 18. 18. 20. 21. 23.
 18. 20.] 
Reward = 15.28398609161377
33. [20. 22. 21. 22. 20. 22. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.278973579406738
34. [20. 23. 20. 17. 20. 20. 21. 15. 16. 22. 23. 20. 18. 18. 16. 18. 23. 17.
 20. 18.] 
Reward = 15.278093338012695
35. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 21. 22. 21. 19. 15. 20. 21.
 21. 21.] 
Reward = 15.270090103149414
36. [20. 22. 21. 17. 20. 20. 21. 15. 16. 22. 23. 20. 18. 18. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.267871856689453
37. [20. 20. 21. 17. 13. 22. 21. 22. 16. 22. 18. 21. 22. 18. 16. 18. 15. 17.
 23. 20.] 
Reward = 15.261762619018555
38. [21. 22. 22. 18. 22. 18. 23. 19. 10. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.258641242980957
39. [19. 20. 21. 22. 20. 20. 19. 23. 19. 12. 21. 19. 22. 12. 16. 16. 15. 17.
 20. 19.] 
Reward = 15.254758834838867
40. [18. 20. 19. 18. 13. 18. 23. 20. 20. 22. 18. 17. 14. 17. 19. 17. 22. 22.
 23. 20.] 
Reward = 15.254735946655273
41. [21. 22. 22. 18. 22. 18. 23. 19. 20. 23. 14. 17. 17. 17. 19. 17. 13. 22.
 15. 19.] 
Reward = 15.25451946258545
42. [15. 20. 17. 19. 21. 20. 17. 21. 22. 13. 16. 20. 23. 23. 14. 20. 21. 18.
 18. 22.] 
Reward = 15.253179550170898
43. [18. 20. 19. 22. 20. 18. 19. 20. 20. 22. 18. 17. 22. 12. 16. 16. 22. 17.
 20. 19.] 
Reward = 15.251967430114746
44. [14. 14. 16. 17. 21. 22. 20. 19. 10. 22. 16. 30. 22.  9. 29. 15. 23. 21.
 21. 21.] 
Reward = 15.25084400177002
45. [21. 22. 22. 18. 22. 18. 14. 19. 20. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 20. 19.] 
Reward = 15.248624801635742
46. [19. 23. 20. 18. 20. 22. 23. 20. 12. 13. 16. 20. 18. 18. 13. 20. 21. 21.
 20. 20.] 
Reward = 15.247174263000488
47. [17. 22. 23. 18. 15. 18. 20. 16. 22. 16. 18. 15. 23. 19. 15. 22. 21. 19.
 20. 19.] 
Reward = 15.243968963623047
48. [17. 22. 14. 18. 15. 18. 20. 16. 22. 16. 29. 15. 23. 19. 15. 22. 21. 23.
 20. 19.] 
Reward = 15.24040412902832
49. [16. 22. 21. 22. 20. 25. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.238067626953125
50. [19. 23. 22. 18. 22. 12. 23. 15. 20. 16. 23. 17. 15. 17. 19. 23. 13. 21.
 20. 18.] 
Reward = 15.235612869262695
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 5 took 1 hour 42 mins 15 secs



Testing Model 301
[18, 25, 17, 17, 13, 25, 21, 22, 16, 26, 18, 20, 23, 17, 16, 18, 15, 24, 23, 11]
FLOPs = 2007.60M
Top-1 Accuracy = 54.48 | Top-5 Accuracy = 78.21 | Loss = 2.0392
Testing Model 301 took 2 mins and 0 secs

Testing Model 302
[18, 25, 7, 28, 13, 11, 6, 22, 16, 26, 11, 20, 23, 17, 16, 18, 27, 23, 23, 20]
FLOPs = 1982.31M
Top-1 Accuracy = 54.97 | Top-5 Accuracy = 78.66 | Loss = 2.0213
Testing Model 302 took 2 mins and 3 secs

Testing Model 303
[18, 25, 17, 17, 13, 11, 21, 22, 16, 26, 18, 20, 18, 17, 16, 18, 25, 23, 23, 25]
FLOPs = 2038.00M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.82 | Loss = 2.0120
Testing Model 303 took 2 mins and 0 secs

Testing Model 304
[21, 14, 16, 22, 21, 22, 27, 19, 13, 22, 19, 20, 22, 9, 26, 22, 20, 17, 20, 21]
FLOPs = 2048.95M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.69 | Loss = 2.0151
Testing Model 304 took 2 mins and 0 secs

Testing Model 305
[20, 14, 25, 22, 21, 14, 20, 19, 16, 22, 19, 23, 22, 9, 16, 22, 15, 21, 21, 18]
FLOPs = 2020.31M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.68 | Loss = 2.0176
Testing Model 305 took 2 mins and 4 secs

Testing Model 306
[20, 14, 16, 22, 24, 22, 13, 19, 13, 22, 19, 20, 22, 9, 26, 22, 20, 17, 20, 21]
FLOPs = 1973.35M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.73 | Loss = 2.0175
Testing Model 306 took 1 mins and 58 secs

Testing Model 307
[14, 14, 16, 22, 21, 28, 20, 19, 13, 22, 7, 23, 22, 9, 26, 15, 19, 21, 21, 21]
FLOPs = 1960.20M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.56 | Loss = 2.0221
Testing Model 307 took 1 mins and 58 secs

Testing Model 308
[19, 23, 20, 17, 20, 23, 21, 15, 16, 22, 23, 20, 18, 18, 13, 18, 23, 17, 21, 18]
FLOPs = 1983.41M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.60 | Loss = 2.0187
Testing Model 308 took 2 mins and 1 secs

Testing Model 309
[20, 14, 16, 22, 21, 22, 13, 19, 15, 22, 19, 20, 22, 9, 26, 22, 20, 17, 20, 21]
FLOPs = 1964.54M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.75 | Loss = 2.0147
Testing Model 309 took 1 mins and 56 secs

Testing Model 310
[20, 22, 20, 17, 20, 20, 21, 21, 16, 28, 23, 20, 22, 12, 16, 18, 15, 17, 20, 18]
FLOPs = 1998.90M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.62 | Loss = 2.0177
Testing Model 310 took 2 mins and 0 secs

Testing Model 311
[18, 25, 17, 17, 13, 11, 21, 22, 16, 26, 18, 20, 23, 17, 16, 18, 26, 23, 23, 20]
FLOPs = 2038.49M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.73 | Loss = 2.0145
Testing Model 311 took 1 mins and 56 secs

Testing Model 312
[20, 22, 24, 22, 20, 20, 13, 21, 16, 12, 19, 20, 22, 12, 16, 22, 15, 17, 20, 20]
FLOPs = 1989.81M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.73 | Loss = 2.0131
Testing Model 312 took 2 mins and 4 secs

Testing Model 313
[20, 22, 21, 22, 20, 20, 13, 21, 16, 12, 19, 22, 22, 12, 16, 29, 15, 17, 20, 20]
FLOPs = 2025.20M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.71 | Loss = 2.0146
Testing Model 313 took 2 mins and 5 secs

Testing Model 314
[19, 23, 20, 17, 20, 20, 21, 15, 16, 22, 23, 20, 18, 18, 13, 18, 23, 28, 20, 18]
FLOPs = 2048.78M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.67 | Loss = 2.0174
Testing Model 314 took 2 mins and 1 secs

Testing Model 315
[14, 14, 16, 22, 21, 9, 20, 19, 24, 22, 16, 23, 22, 9, 26, 15, 20, 21, 21, 21]
FLOPs = 1962.66M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.62 | Loss = 2.0192
Testing Model 315 took 2 mins and 0 secs

Testing Model 316
[18, 25, 17, 17, 13, 11, 21, 22, 16, 26, 18, 20, 23, 17, 16, 18, 18, 23, 23, 20]
FLOPs = 1980.84M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.71 | Loss = 2.0131
Testing Model 316 took 2 mins and 1 secs

Testing Model 317
[20, 22, 21, 22, 20, 20, 13, 21, 24, 12, 19, 20, 22, 12, 16, 22, 5, 17, 20, 20]
FLOPs = 1954.74M
Top-1 Accuracy = 54.98 | Top-5 Accuracy = 78.56 | Loss = 2.0245
Testing Model 317 took 2 mins and 0 secs

Testing Model 318
[13, 25, 17, 17, 13, 11, 28, 22, 16, 26, 18, 20, 23, 17, 16, 18, 15, 23, 23, 20]
FLOPs = 1999.94M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.66 | Loss = 2.0188
Testing Model 318 took 1 mins and 59 secs

Testing Model 319
[14, 14, 16, 22, 21, 22, 20, 19, 13, 27, 21, 23, 22, 9, 26, 15, 20, 21, 21, 21]
FLOPs = 2033.80M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.66 | Loss = 2.0163
Testing Model 319 took 1 mins and 59 secs

Testing Model 320
[18, 25, 17, 17, 13, 11, 21, 22, 16, 26, 18, 20, 23, 17, 16, 18, 15, 23, 23, 25]
FLOPs = 2005.30M
Top-1 Accuracy = 55.26 | Top-5 Accuracy = 78.76 | Loss = 2.0137
Testing Model 320 took 1 mins and 59 secs

Testing Model 321
[20, 22, 21, 22, 20, 20, 13, 21, 16, 26, 19, 20, 22, 12, 16, 22, 15, 17, 20, 20]
FLOPs = 2046.54M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.72 | Loss = 2.0125
Testing Model 321 took 2 mins and 1 secs

Testing Model 322
[20, 22, 29, 22, 20, 10, 13, 21, 16, 12, 19, 20, 22, 22, 16, 22, 15, 17, 4, 20]
FLOPs = 1961.44M
Top-1 Accuracy = 53.72 | Top-5 Accuracy = 77.72 | Loss = 2.0878
Testing Model 322 took 2 mins and 6 secs

Testing Model 323
[21, 22, 21, 22, 25, 20, 13, 21, 16, 6, 19, 20, 22, 12, 16, 22, 15, 17, 20, 20]
FLOPs = 1961.99M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.70 | Loss = 2.0165
Testing Model 323 took 2 mins and 7 secs

Testing Model 324
[20, 21, 20, 17, 28, 20, 20, 19, 13, 12, 16, 23, 18, 18, 16, 22, 20, 21, 20, 20]
FLOPs = 1979.86M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.76 | Loss = 2.0123
Testing Model 324 took 2 mins and 2 secs

Testing Model 325
[20, 22, 20, 17, 20, 23, 9, 21, 24, 22, 23, 20, 22, 12, 16, 18, 15, 17, 20, 18]
FLOPs = 1955.55M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.68 | Loss = 2.0186
Testing Model 325 took 1 mins and 57 secs

Testing Model 326
[20, 22, 21, 22, 20, 10, 13, 19, 16, 12, 19, 23, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1971.71M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.70 | Loss = 2.0137
Testing Model 326 took 2 mins and 9 secs

Testing Model 327
[20, 22, 16, 22, 20, 22, 13, 21, 13, 22, 19, 20, 22, 9, 26, 22, 15, 17, 21, 20]
FLOPs = 2008.92M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.72 | Loss = 2.0151
Testing Model 327 took 1 mins and 59 secs

Testing Model 328
[20, 22, 16, 22, 21, 22, 13, 21, 16, 22, 19, 20, 22, 12, 16, 22, 20, 17, 20, 21]
FLOPs = 2007.89M
Top-1 Accuracy = 55.04 | Top-5 Accuracy = 78.67 | Loss = 2.0172
Testing Model 328 took 2 mins and 8 secs

Testing Model 329
[20, 22, 16, 22, 21, 22, 13, 21, 16, 12, 19, 20, 22, 22, 16, 22, 20, 17, 20, 21]
FLOPs = 2012.80M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.70 | Loss = 2.0138
Testing Model 329 took 1 mins and 58 secs

Testing Model 330
[20, 14, 20, 17, 21, 22, 20, 15, 13, 22, 23, 23, 18, 18, 26, 15, 23, 17, 20, 20]
FLOPs = 1966.91M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.70 | Loss = 2.0172
Testing Model 330 took 1 mins and 59 secs

Testing Model 331
[20, 23, 20, 17, 20, 20, 20, 15, 13, 12, 23, 23, 18, 18, 16, 22, 23, 21, 20, 21]
FLOPs = 1990.80M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.76 | Loss = 2.0113
Testing Model 331 took 2 mins and 3 secs

Testing Model 332
[20, 22, 21, 17, 20, 20, 21, 15, 16, 22, 23, 20, 18, 18, 16, 22, 15, 17, 21, 20]
FLOPs = 1974.62M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.70 | Loss = 2.0144
Testing Model 332 took 1 mins and 55 secs

Testing Model 333
[20, 25, 21, 17, 20, 20, 13, 21, 16, 26, 19, 20, 22, 17, 16, 18, 15, 17, 23, 20]
FLOPs = 2013.77M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.73 | Loss = 2.0114
Testing Model 333 took 2 mins and 1 secs

Testing Model 334
[20, 22, 21, 22, 21, 22, 13, 21, 16, 12, 19, 20, 22, 9, 26, 22, 15, 17, 20, 21]
FLOPs = 2038.37M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.77 | Loss = 2.0138
Testing Model 334 took 2 mins and 2 secs

Testing Model 335
[18, 25, 17, 22, 20, 10, 13, 22, 16, 26, 18, 20, 23, 17, 16, 22, 15, 17, 23, 20]
FLOPs = 2010.52M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.73 | Loss = 2.0126
Testing Model 335 took 2 mins and 7 secs

Testing Model 336
[20, 23, 20, 17, 21, 20, 20, 19, 16, 22, 19, 23, 22, 9, 16, 22, 20, 21, 20, 21]
FLOPs = 2038.43M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.81 | Loss = 2.0112
Testing Model 336 took 1 mins and 58 secs

Testing Model 337
[18, 25, 20, 17, 20, 11, 21, 22, 16, 26, 18, 20, 18, 17, 13, 18, 23, 17, 20, 20]
FLOPs = 1970.99M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.74 | Loss = 2.0156
Testing Model 337 took 2 mins and 6 secs

Testing Model 338
[19, 23, 20, 17, 20, 20, 20, 19, 16, 22, 23, 20, 18, 18, 13, 18, 23, 21, 20, 18]
FLOPs = 2006.60M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.65 | Loss = 2.0164
Testing Model 338 took 1 mins and 55 secs

Testing Model 339
[19, 23, 16, 17, 20, 22, 21, 15, 16, 22, 23, 20, 18, 18, 26, 18, 23, 17, 20, 21]
FLOPs = 2020.80M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.75 | Loss = 2.0142
Testing Model 339 took 2 mins and 8 secs

Testing Model 340
[20, 22, 16, 22, 20, 20, 13, 21, 16, 22, 19, 23, 22, 12, 16, 22, 15, 17, 20, 21]
FLOPs = 1976.47M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.71 | Loss = 2.0121
Testing Model 340 took 1 mins and 56 secs

Testing Model 341
[18, 25, 17, 17, 20, 20, 21, 22, 16, 26, 18, 20, 23, 17, 16, 18, 15, 17, 20, 18]
FLOPs = 1968.61M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.58 | Loss = 2.0197
Testing Model 341 took 2 mins and 9 secs

Testing Model 342
[20, 23, 21, 22, 20, 20, 21, 21, 16, 12, 19, 20, 18, 18, 16, 22, 15, 17, 20, 20]
FLOPs = 2020.40M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.74 | Loss = 2.0127
Testing Model 342 took 1 mins and 59 secs

Testing Model 343
[20, 14, 16, 22, 21, 20, 20, 19, 13, 22, 16, 23, 22, 9, 16, 22, 20, 21, 21, 21]
FLOPs = 1952.49M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.75 | Loss = 2.0123
Testing Model 343 took 2 mins and 7 secs

Testing Model 344
[20, 14, 16, 22, 21, 22, 13, 19, 16, 22, 19, 20, 22, 12, 26, 22, 15, 17, 20, 21]
FLOPs = 1952.20M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.70 | Loss = 2.0145
Testing Model 344 took 1 mins and 56 secs

Testing Model 345
[20, 23, 20, 17, 20, 20, 20, 19, 13, 22, 16, 20, 18, 18, 16, 18, 20, 21, 20, 21]
FLOPs = 1964.12M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.72 | Loss = 2.0137
Testing Model 345 took 2 mins and 3 secs

Testing Model 346
[19, 22, 20, 22, 20, 20, 13, 21, 16, 12, 23, 20, 22, 18, 13, 22, 23, 17, 21, 18]
FLOPs = 2029.07M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.70 | Loss = 2.0169
Testing Model 346 took 2 mins and 0 secs

Testing Model 347
[20, 23, 20, 17, 20, 20, 21, 15, 16, 12, 23, 23, 18, 18, 16, 22, 20, 21, 20, 21]
FLOPs = 1995.63M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.77 | Loss = 2.0121
Testing Model 347 took 2 mins and 2 secs

Testing Model 348
[18, 14, 16, 22, 21, 22, 21, 22, 13, 22, 18, 20, 23, 9, 26, 18, 15, 23, 23, 20]
FLOPs = 2019.93M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.66 | Loss = 2.0141
Testing Model 348 took 1 mins and 54 secs

Testing Model 349
[20, 22, 16, 22, 20, 22, 13, 21, 13, 12, 19, 20, 22, 22, 26, 22, 15, 17, 20, 20]
FLOPs = 2021.57M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.75 | Loss = 2.0128
Testing Model 349 took 1 mins and 58 secs

Testing Model 350
[20, 23, 16, 22, 20, 22, 20, 19, 13, 22, 16, 23, 22, 9, 16, 22, 20, 21, 20, 21]
FLOPs = 2046.98M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.75 | Loss = 2.0113
Testing Model 350 took 1 mins and 56 secs

> Select
Iteration 6 : Showing Top 50 results
1. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.574835777282715
2. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.54874038696289
3. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.534582138061523
4. [20. 23. 20. 17. 20. 20. 20. 19. 13. 12. 16. 23. 18. 18. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.531522750854492
5. [20. 14. 16. 22. 21. 22. 13. 19. 13. 22. 19. 20. 22.  9. 26. 22. 20. 17.
 20. 21.] 
Reward = 15.494070053100586
6. [20. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  9. 16. 22. 20. 21.
 21. 21.] 
Reward = 15.483205795288086
7. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
8. [20. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.471687316894531
9. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.433782577514648
10. [20. 22. 21. 22. 20. 10. 13. 19. 16. 12. 19. 23. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.430253028869629
11. [18. 25. 17. 17. 13. 11. 21. 22. 16. 26. 18. 20. 23. 17. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.428112983703613
12. [20. 14. 16. 22. 21. 20. 20. 19. 16. 22. 19. 23. 22.  9. 16. 22. 15. 21.
 21. 21.] 
Reward = 15.423428535461426
13. [19. 23. 20. 17. 20. 20. 21. 15. 16. 22. 23. 20. 18. 18. 13. 18. 23. 17.
 20. 18.] 
Reward = 15.420969009399414
14. [20. 22. 21. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 22. 15. 21.
 21. 20.] 
Reward = 15.418389320373535
15. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.417957305908203
16. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.416141510009766
17. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 19. 20. 15. 23.
 18. 20.] 
Reward = 15.400196075439453
18. [20. 22. 20. 18. 20. 12. 21. 22. 16. 12. 18. 20. 22. 18. 16. 23. 15. 21.
 23. 18.] 
Reward = 15.392885208129883
19. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.381397247314453
20. [20. 22. 21. 22. 20. 20. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.377861022949219
21. [20. 22. 21. 18. 20. 12. 23. 22. 16. 22. 19. 20. 22. 18. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.376130104064941
22. [20. 22. 21. 17. 13. 20. 21. 22. 16. 22. 19. 20. 22. 18. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.373248100280762
23. [14. 14. 16. 22. 21.  9. 20. 19. 24. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.370867729187012
24. [20. 22. 20. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 23. 15. 21.
 21. 18.] 
Reward = 15.366320610046387
25. [20. 22. 20. 22. 20. 20. 13. 15. 16. 12. 23. 20. 18. 18. 16. 18. 23. 17.
 20. 20.] 
Reward = 15.36349105834961
26. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 18. 18. 15. 17.
 20. 20.] 
Reward = 15.349184036254883
27. [18. 20. 17. 17. 21. 22. 17. 20. 22. 13. 16. 20. 23. 18. 19. 20. 21. 23.
 18. 20.] 
Reward = 15.347654342651367
28. [21. 22. 22. 18. 22. 18. 14. 19. 20. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.344067573547363
29. [19. 23. 20. 18. 20. 12. 23. 15. 12. 16. 23. 22. 18. 18. 13. 23. 23. 21.
 20. 18.] 
Reward = 15.3290376663208
30. [18. 25. 20. 17. 20. 11. 21. 22. 16. 26. 18. 20. 18. 17. 13. 18. 23. 17.
 20. 20.] 
Reward = 15.326105117797852
31. [20. 22. 20. 17. 20. 23.  9. 21. 24. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.323432922363281
32. [20. 22. 21. 22. 20. 20. 13. 21. 20. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.319889068603516
33. [20. 22. 21. 22. 20. 20. 21. 22. 16. 12. 18. 20. 22. 12. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.305963516235352
34. [21. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.291874885559082
35. [18. 20. 17. 17. 13. 23. 21. 22. 16. 22. 18. 20. 23. 18. 19. 20. 15. 23.
 18. 20.] 
Reward = 15.289787292480469
36. [20. 20. 21. 17. 13. 22. 21. 22. 20. 22. 18. 20. 19. 18. 16. 18. 15. 17.
 23. 20.] 
Reward = 15.288784980773926
37. [18. 25. 17. 17. 20. 20. 21. 22. 16. 26. 18. 20. 23. 17. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.28793716430664
38. [20. 20. 21. 17. 13. 22. 21. 22. 16. 22. 18. 20. 22. 18. 16. 18. 15. 17.
 23. 20.] 
Reward = 15.284989356994629
39. [18. 20. 17. 17. 21. 22. 17. 20. 22. 13. 16. 20. 23. 18. 18. 20. 21. 23.
 18. 20.] 
Reward = 15.28398609161377
40. [20. 22. 21. 22. 20. 22. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.278973579406738
41. [20. 23. 20. 17. 20. 20. 21. 15. 16. 22. 23. 20. 18. 18. 16. 18. 23. 17.
 20. 18.] 
Reward = 15.278093338012695
42. [18. 25. 17. 17. 13. 11. 21. 22. 16. 26. 18. 20. 23. 17. 16. 18. 18. 23.
 23. 20.] 
Reward = 15.277165412902832
43. [20. 22. 16. 22. 20. 20. 13. 21. 16. 22. 19. 23. 22. 12. 16. 22. 15. 17.
 20. 21.] 
Reward = 15.271968841552734
44. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 21. 22. 21. 19. 15. 20. 21.
 21. 21.] 
Reward = 15.270090103149414
45. [20. 22. 21. 17. 20. 20. 21. 15. 16. 22. 23. 20. 18. 18. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.267871856689453
46. [14. 14. 16. 22. 21. 28. 20. 19. 13. 22.  7. 23. 22.  9. 26. 15. 19. 21.
 21. 21.] 
Reward = 15.266392707824707
47. [20. 20. 21. 17. 13. 22. 21. 22. 16. 22. 18. 21. 22. 18. 16. 18. 15. 17.
 23. 20.] 
Reward = 15.261762619018555
48. [21. 22. 22. 18. 22. 18. 23. 19. 10. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.258641242980957
49. [19. 20. 21. 22. 20. 20. 19. 23. 19. 12. 21. 19. 22. 12. 16. 16. 15. 17.
 20. 19.] 
Reward = 15.254758834838867
50. [18. 20. 19. 18. 13. 18. 23. 20. 20. 22. 18. 17. 14. 17. 19. 17. 22. 22.
 23. 20.] 
Reward = 15.254735946655273
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 6 took 1 hour 41 mins 25 secs



Testing Model 351
[20, 22, 20, 17, 20, 20, 21, 28, 16, 22, 23, 20, 22, 12, 16, 18, 15, 17, 20, 18]
FLOPs = 2015.50M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.62 | Loss = 2.0165
Testing Model 351 took 1 mins and 54 secs

Testing Model 352
[20, 23, 20, 17, 20, 20, 21, 15, 16, 12, 23, 25, 18, 18, 16, 22, 23, 17, 20, 20]
FLOPs = 1994.01M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.72 | Loss = 2.0151
Testing Model 352 took 1 mins and 56 secs

Testing Model 353
[20, 14, 16, 22, 21, 20, 20, 28, 20, 22, 24, 17, 22, 9, 16, 22, 20, 21, 21, 17]
FLOPs = 2041.69M
Top-1 Accuracy = 54.94 | Top-5 Accuracy = 78.65 | Loss = 2.0174
Testing Model 353 took 1 mins and 53 secs

Testing Model 354
[20, 23, 20, 17, 20, 20, 25, 15, 16, 12, 23, 20, 18, 18, 16, 22, 23, 17, 20, 20]
FLOPs = 1984.89M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.75 | Loss = 2.0152
Testing Model 354 took 2 mins and 2 secs

Testing Model 355
[14, 14, 16, 22, 21, 22, 28, 19, 13, 22, 16, 23, 22, 9, 26, 15, 20, 21, 21, 21]
FLOPs = 2025.62M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.63 | Loss = 2.0172
Testing Model 355 took 1 mins and 54 secs

Testing Model 356
[20, 22, 21, 22, 20, 10, 13, 19, 16, 11, 19, 23, 22, 22, 16, 28, 17, 17, 21, 20]
FLOPs = 2030.08M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.73 | Loss = 2.0122
Testing Model 356 took 2 mins and 0 secs

Testing Model 357
[20, 23, 20, 17, 20, 28, 21, 18, 30, 12, 23, 20, 18, 18, 16, 0, 23, 17, 20, 20]
FLOPs = 2042.06M
Top-1 Accuracy = 54.44 | Top-5 Accuracy = 78.01 | Loss = 2.0591
Testing Model 357 took 2 mins and 5 secs

Testing Model 358
[20, 22, 27, 22, 20, 2, 10, 21, 16, 12, 19, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1992.76M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.80 | Loss = 2.0152
Testing Model 358 took 1 mins and 57 secs

Testing Model 359
[20, 23, 30, 17, 20, 20, 20, 19, 13, 12, 16, 18, 18, 18, 16, 22, 20, 21, 20, 21]
FLOPs = 2031.55M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.76 | Loss = 2.0113
Testing Model 359 took 2 mins and 5 secs

Testing Model 360
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 19, 9, 22, 22, 30, 22, 15, 17, 21, 20]
FLOPs = 1994.36M
Top-1 Accuracy = 54.94 | Top-5 Accuracy = 78.58 | Loss = 2.0204
Testing Model 360 took 1 mins and 55 secs

Testing Model 361
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 9, 26, 22, 20, 21, 21, 21]
FLOPs = 2013.43M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.67 | Loss = 2.0167
Testing Model 361 took 1 mins and 59 secs

Testing Model 362
[20, 22, 20, 21, 20, 20, 21, 21, 16, 22, 23, 20, 22, 21, 16, 18, 15, 17, 14, 18]
FLOPs = 2033.91M
Top-1 Accuracy = 54.95 | Top-5 Accuracy = 78.61 | Loss = 2.0254
Testing Model 362 took 2 mins and 3 secs

Testing Model 363
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 30, 22, 9, 26, 15, 20, 21, 21, 21]
FLOPs = 2029.60M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.64 | Loss = 2.0183
Testing Model 363 took 1 mins and 53 secs

Testing Model 364
[14, 14, 17, 22, 21, 22, 20, 1, 13, 22, 16, 23, 22, 9, 26, 27, 20, 21, 21, 21]
FLOPs = 1971.90M
Top-1 Accuracy = 54.69 | Top-5 Accuracy = 78.35 | Loss = 2.0399
Testing Model 364 took 1 mins and 57 secs

Testing Model 365
[20, 25, 16, 5, 26, 22, 30, 19, 13, 22, 19, 18, 22, 9, 26, 22, 20, 17, 20, 29]
FLOPs = 1975.44M
Top-1 Accuracy = 54.50 | Top-5 Accuracy = 78.28 | Loss = 2.0425
Testing Model 365 took 2 mins and 0 secs

Testing Model 366
[20, 14, 16, 22, 21, 22, 13, 19, 25, 22, 19, 20, 22, 9, 26, 22, 20, 17, 20, 15]
FLOPs = 1985.01M
Top-1 Accuracy = 54.88 | Top-5 Accuracy = 78.48 | Loss = 2.0257
Testing Model 366 took 2 mins and 2 secs

Testing Model 367
[20, 23, 20, 17, 20, 20, 21, 15, 16, 12, 23, 26, 18, 18, 16, 22, 23, 17, 19, 20]
FLOPs = 1995.83M
Top-1 Accuracy = 55.02 | Top-5 Accuracy = 78.70 | Loss = 2.0151
Testing Model 367 took 1 mins and 57 secs

Testing Model 368
[20, 23, 20, 17, 20, 20, 20, 27, 13, 12, 16, 23, 18, 18, 16, 22, 20, 21, 20, 21]
FLOPs = 2023.90M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.78 | Loss = 2.0110
Testing Model 368 took 1 mins and 57 secs

Testing Model 369
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 12, 16, 19, 15, 17, 20, 18]
FLOPs = 1957.38M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.63 | Loss = 2.0178
Testing Model 369 took 2 mins and 3 secs

Testing Model 370
[20, 22, 21, 22, 17, 20, 21, 21, 16, 12, 19, 20, 22, 12, 16, 22, 15, 17, 20, 20]
FLOPs = 1985.54M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.74 | Loss = 2.0140
Testing Model 370 took 1 mins and 58 secs

Testing Model 371
[20, 14, 16, 22, 26, 22, 13, 19, 13, 22, 19, 20, 22, 9, 26, 22, 20, 17, 20, 21]
FLOPs = 1987.82M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.75 | Loss = 2.0157
Testing Model 371 took 2 mins and 0 secs

Testing Model 372
[20, 22, 21, 22, 20, 20, 13, 21, 16, 12, 19, 20, 22, 16, 16, 22, 15, 17, 20, 20]
FLOPs = 1973.98M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.77 | Loss = 2.0135
Testing Model 372 took 2 mins and 2 secs

Testing Model 373
[20, 23, 20, 28, 20, 20, 20, 19, 13, 12, 16, 23, 18, 18, 16, 22, 20, 6, 20, 21]
FLOPs = 2041.27M
Top-1 Accuracy = 54.64 | Top-5 Accuracy = 78.47 | Loss = 2.0337
Testing Model 373 took 2 mins and 5 secs

Testing Model 374
[20, 22, 21, 22, 20, 25, 13, 5, 16, 22, 19, 20, 22, 12, 23, 22, 15, 17, 20, 20]
FLOPs = 1996.17M
Top-1 Accuracy = 54.92 | Top-5 Accuracy = 78.61 | Loss = 2.0237
Testing Model 374 took 1 mins and 56 secs

Testing Model 375
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 26, 15, 20, 21, 21, 21]
FLOPs = 1960.73M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.59 | Loss = 2.0195
Testing Model 375 took 1 mins and 57 secs

Testing Model 376
[20, 22, 20, 22, 20, 10, 21, 15, 16, 12, 19, 20, 22, 18, 16, 22, 23, 17, 20, 20]
FLOPs = 1973.78M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.70 | Loss = 2.0149
Testing Model 376 took 2 mins and 0 secs

Testing Model 377
[20, 14, 16, 22, 21, 20, 13, 19, 16, 22, 19, 23, 22, 12, 26, 22, 15, 21, 21, 21]
FLOPs = 2004.50M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.83 | Loss = 2.0130
Testing Model 377 took 2 mins and 2 secs

Testing Model 378
[20, 22, 20, 17, 21, 22, 21, 21, 13, 22, 23, 20, 22, 12, 16, 18, 15, 17, 20, 21]
FLOPs = 1977.76M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.72 | Loss = 2.0157
Testing Model 378 took 2 mins and 1 secs

Testing Model 379
[20, 14, 16, 22, 20, 20, 21, 19, 16, 12, 23, 20, 18, 18, 26, 22, 20, 17, 20, 21]
FLOPs = 1986.76M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.78 | Loss = 2.0145
Testing Model 379 took 1 mins and 56 secs

Testing Model 380
[14, 22, 16, 22, 20, 22, 13, 19, 13, 12, 19, 23, 22, 9, 26, 22, 20, 21, 21, 21]
FLOPs = 2002.07M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.72 | Loss = 2.0169
Testing Model 380 took 1 mins and 59 secs

Testing Model 381
[20, 14, 16, 22, 21, 20, 20, 19, 13, 22, 16, 23, 22, 9, 26, 22, 20, 21, 21, 21]
FLOPs = 2026.70M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.77 | Loss = 2.0128
Testing Model 381 took 1 mins and 58 secs

Testing Model 382
[20, 23, 20, 22, 20, 10, 21, 21, 16, 12, 19, 20, 18, 18, 16, 22, 15, 17, 21, 20]
FLOPs = 1953.87M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.76 | Loss = 2.0111
Testing Model 382 took 2 mins and 1 secs

Testing Model 383
[14, 22, 20, 17, 20, 20, 21, 21, 13, 22, 23, 20, 22, 12, 26, 15, 15, 17, 21, 21]
FLOPs = 1986.25M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.71 | Loss = 2.0173
Testing Model 383 took 1 mins and 59 secs

Testing Model 384
[20, 14, 16, 22, 20, 22, 13, 19, 16, 22, 19, 23, 22, 22, 26, 22, 15, 17, 21, 20]
FLOPs = 2036.12M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.76 | Loss = 2.0157
Testing Model 384 took 1 mins and 59 secs

Testing Model 385
[20, 23, 20, 22, 20, 20, 20, 19, 16, 12, 16, 20, 18, 18, 16, 22, 15, 21, 20, 20]
FLOPs = 1997.60M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.78 | Loss = 2.0128
Testing Model 385 took 2 mins and 0 secs

Testing Model 386
[20, 14, 20, 22, 20, 20, 20, 15, 13, 12, 23, 20, 22, 9, 16, 22, 23, 21, 21, 21]
FLOPs = 1953.19M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.76 | Loss = 2.0140
Testing Model 386 took 1 mins and 54 secs

Testing Model 387
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 19, 23, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1989.02M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.75 | Loss = 2.0126
Testing Model 387 took 2 mins and 0 secs

Testing Model 388
[20, 22, 20, 17, 20, 20, 21, 19, 16, 22, 23, 23, 22, 22, 16, 18, 15, 17, 21, 20]
FLOPs = 2042.83M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.73 | Loss = 2.0148
Testing Model 388 took 1 mins and 58 secs

Testing Model 389
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 9, 26, 22, 15, 21, 21, 21]
FLOPs = 1955.21M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.66 | Loss = 2.0186
Testing Model 389 took 1 mins and 56 secs

Testing Model 390
[20, 22, 21, 22, 21, 22, 13, 19, 13, 22, 19, 20, 22, 9, 16, 22, 20, 17, 20, 21]
FLOPs = 2027.74M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.71 | Loss = 2.0148
Testing Model 390 took 1 mins and 57 secs

Testing Model 391
[20, 23, 20, 17, 20, 20, 21, 19, 16, 22, 19, 20, 22, 18, 16, 22, 15, 17, 20, 20]
FLOPs = 1991.46M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.70 | Loss = 2.0148
Testing Model 391 took 1 mins and 57 secs

Testing Model 392
[20, 22, 21, 22, 21, 20, 13, 21, 16, 12, 16, 20, 22, 12, 16, 22, 20, 21, 21, 21]
FLOPs = 2021.25M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.77 | Loss = 2.0094
Testing Model 392 took 1 mins and 58 secs

Testing Model 393
[20, 22, 16, 22, 21, 20, 13, 21, 16, 22, 16, 20, 22, 12, 16, 22, 15, 21, 20, 20]
FLOPs = 1967.27M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.73 | Loss = 2.0147
Testing Model 393 took 1 mins and 54 secs

Testing Model 394
[20, 14, 20, 22, 21, 22, 13, 19, 13, 12, 23, 20, 22, 18, 16, 22, 23, 17, 20, 20]
FLOPs = 1964.44M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.74 | Loss = 2.0137
Testing Model 394 took 1 mins and 56 secs

Testing Model 395
[20, 23, 16, 22, 20, 20, 20, 15, 16, 12, 16, 23, 18, 18, 26, 22, 20, 17, 20, 20]
FLOPs = 2014.07M
Top-1 Accuracy = 55.01 | Top-5 Accuracy = 78.73 | Loss = 2.0142
Testing Model 395 took 1 mins and 58 secs

Testing Model 396
[20, 22, 21, 22, 20, 20, 20, 21, 13, 12, 19, 20, 22, 9, 16, 22, 15, 21, 20, 20]
FLOPs = 1993.23M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.71 | Loss = 2.0138
Testing Model 396 took 1 mins and 59 secs

Testing Model 397
[20, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 12, 16, 22, 20, 21, 20, 21]
FLOPs = 1991.13M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.72 | Loss = 2.0136
Testing Model 397 took 1 mins and 58 secs

Testing Model 398
[20, 14, 16, 22, 21, 22, 20, 19, 13, 22, 19, 23, 22, 9, 26, 15, 20, 21, 21, 21]
FLOPs = 2009.63M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.71 | Loss = 2.0148
Testing Model 398 took 2 mins and 3 secs

Testing Model 399
[20, 23, 20, 17, 20, 20, 21, 15, 16, 22, 23, 20, 18, 18, 16, 18, 23, 17, 20, 20]
FLOPs = 1989.61M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.72 | Loss = 2.0150
Testing Model 399 took 2 mins and 3 secs

Testing Model 400
[20, 22, 20, 22, 20, 10, 20, 19, 16, 12, 19, 23, 18, 18, 16, 22, 15, 21, 20, 20]
FLOPs = 1970.08M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.77 | Loss = 2.0115
Testing Model 400 took 2 mins and 2 secs

> Select
Iteration 7 : Showing Top 50 results
1. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.574835777282715
2. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.54874038696289
3. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.539837837219238
4. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.534582138061523
5. [20. 23. 20. 17. 20. 20. 20. 19. 13. 12. 16. 23. 18. 18. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.531522750854492
6. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22.  9. 26. 22. 15. 21.
 21. 21.] 
Reward = 15.5304536819458
7. [20. 14. 16. 22. 21. 22. 13. 19. 13. 22. 19. 20. 22.  9. 26. 22. 20. 17.
 20. 21.] 
Reward = 15.494070053100586
8. [20. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  9. 16. 22. 20. 21.
 21. 21.] 
Reward = 15.483205795288086
9. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
10. [20. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.471687316894531
11. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 19. 15. 17.
 20. 18.] 
Reward = 15.46304988861084
12. [20. 14. 20. 22. 21. 22. 13. 19. 13. 12. 23. 20. 22. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.44775390625
13. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.433782577514648
14. [20. 22. 20. 22. 20. 10. 20. 19. 16. 12. 19. 23. 18. 18. 16. 22. 15. 21.
 20. 20.] 
Reward = 15.431556701660156
15. [20. 22. 21. 22. 20. 10. 13. 19. 16. 12. 19. 23. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.430253028869629
16. [18. 25. 17. 17. 13. 11. 21. 22. 16. 26. 18. 20. 23. 17. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.428112983703613
17. [20. 14. 16. 22. 21. 20. 20. 19. 16. 22. 19. 23. 22.  9. 16. 22. 15. 21.
 21. 21.] 
Reward = 15.423428535461426
18. [19. 23. 20. 17. 20. 20. 21. 15. 16. 22. 23. 20. 18. 18. 13. 18. 23. 17.
 20. 18.] 
Reward = 15.420969009399414
19. [20. 22. 21. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 22. 15. 21.
 21. 20.] 
Reward = 15.418389320373535
20. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.417957305908203
21. [20. 23. 20. 22. 20. 10. 21. 21. 16. 12. 19. 20. 18. 18. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.416579246520996
22. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.416141510009766
23. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 19. 20. 15. 23.
 18. 20.] 
Reward = 15.400196075439453
24. [20. 22. 20. 18. 20. 12. 21. 22. 16. 12. 18. 20. 22. 18. 16. 23. 15. 21.
 23. 18.] 
Reward = 15.392885208129883
25. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.381397247314453
26. [20. 22. 21. 22. 20. 20. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.377861022949219
27. [20. 22. 21. 18. 20. 12. 23. 22. 16. 22. 19. 20. 22. 18. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.376130104064941
28. [20. 22. 21. 17. 13. 20. 21. 22. 16. 22. 19. 20. 22. 18. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.373248100280762
29. [14. 14. 16. 22. 21.  9. 20. 19. 24. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.370867729187012
30. [20. 22. 20. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 23. 15. 21.
 21. 18.] 
Reward = 15.366320610046387
31. [20. 22. 20. 22. 20. 20. 13. 15. 16. 12. 23. 20. 18. 18. 16. 18. 23. 17.
 20. 20.] 
Reward = 15.36349105834961
32. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 18. 18. 15. 17.
 20. 20.] 
Reward = 15.349184036254883
33. [18. 20. 17. 17. 21. 22. 17. 20. 22. 13. 16. 20. 23. 18. 19. 20. 21. 23.
 18. 20.] 
Reward = 15.347654342651367
34. [21. 22. 22. 18. 22. 18. 14. 19. 20. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.344067573547363
35. [20. 14. 20. 22. 20. 20. 20. 15. 13. 12. 23. 20. 22.  9. 16. 22. 23. 21.
 21. 21.] 
Reward = 15.340524673461914
36. [19. 23. 20. 18. 20. 12. 23. 15. 12. 16. 23. 22. 18. 18. 13. 23. 23. 21.
 20. 18.] 
Reward = 15.3290376663208
37. [18. 25. 20. 17. 20. 11. 21. 22. 16. 26. 18. 20. 18. 17. 13. 18. 23. 17.
 20. 20.] 
Reward = 15.326105117797852
38. [20. 22. 20. 17. 20. 23.  9. 21. 24. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.323432922363281
39. [20. 22. 21. 22. 20. 20. 13. 21. 20. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.319889068603516
40. [20. 22. 21. 22. 20. 20. 21. 22. 16. 12. 18. 20. 22. 12. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.305963516235352
41. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 16. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.30229377746582
42. [21. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.291874885559082
43. [20. 22. 20. 17. 21. 22. 21. 21. 13. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 21.] 
Reward = 15.289995193481445
44. [18. 20. 17. 17. 13. 23. 21. 22. 16. 22. 18. 20. 23. 18. 19. 20. 15. 23.
 18. 20.] 
Reward = 15.289787292480469
45. [20. 20. 21. 17. 13. 22. 21. 22. 20. 22. 18. 20. 19. 18. 16. 18. 15. 17.
 23. 20.] 
Reward = 15.288784980773926
46. [18. 25. 17. 17. 20. 20. 21. 22. 16. 26. 18. 20. 23. 17. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.28793716430664
47. [20. 20. 21. 17. 13. 22. 21. 22. 16. 22. 18. 20. 22. 18. 16. 18. 15. 17.
 23. 20.] 
Reward = 15.284989356994629
48. [18. 20. 17. 17. 21. 22. 17. 20. 22. 13. 16. 20. 23. 18. 18. 20. 21. 23.
 18. 20.] 
Reward = 15.28398609161377
49. [20. 22. 16. 22. 21. 20. 13. 21. 16. 22. 16. 20. 22. 12. 16. 22. 15. 21.
 20. 20.] 
Reward = 15.282332420349121
50. [20. 22. 21. 22. 20. 22. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.278973579406738
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 7 took 1 hour 39 mins 38 secs



Testing Model 401
[20, 14, 16, 26, 21, 22, 13, 19, 13, 22, 19, 20, 22, 9, 27, 22, 20, 17, 20, 21]
FLOPs = 2035.82M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.69 | Loss = 2.0176
Testing Model 401 took 1 mins and 55 secs

Testing Model 402
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 12, 16, 18, 25, 17, 21, 18]
FLOPs = 2025.94M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.69 | Loss = 2.0175
Testing Model 402 took 1 mins and 57 secs

Testing Model 403
[20, 23, 26, 18, 20, 18, 13, 15, 16, 4, 23, 20, 18, 18, 16, 22, 23, 17, 26, 20]
FLOPs = 1995.00M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.71 | Loss = 2.0158
Testing Model 403 took 2 mins and 1 secs

Testing Model 404
[20, 14, 16, 22, 21, 20, 20, 19, 13, 22, 26, 23, 22, 9, 16, 22, 20, 21, 21, 21]
FLOPs = 2020.12M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.75 | Loss = 2.0097
Testing Model 404 took 1 mins and 53 secs

Testing Model 405
[20, 23, 20, 9, 20, 20, 20, 30, 13, 12, 16, 23, 18, 18, 16, 19, 20, 21, 20, 29]
FLOPs = 1957.26M
Top-1 Accuracy = 54.96 | Top-5 Accuracy = 78.63 | Loss = 2.0215
Testing Model 405 took 1 mins and 58 secs

Testing Model 406
[20, 22, 20, 17, 20, 20, 21, 21, 2, 22, 23, 27, 22, 12, 16, 18, 16, 17, 25, 18]
FLOPs = 1992.72M
Top-1 Accuracy = 55.02 | Top-5 Accuracy = 78.60 | Loss = 2.0210
Testing Model 406 took 2 mins and 4 secs

Testing Model 407
[20, 14, 16, 22, 21, 22, 13, 19, 16, 25, 19, 20, 22, 20, 26, 23, 15, 17, 20, 21]
FLOPs = 2032.61M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.75 | Loss = 2.0144
Testing Model 407 took 1 mins and 55 secs

Testing Model 408
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 24, 23, 22, 9, 26, 15, 20, 21, 21, 21]
FLOPs = 2016.80M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.65 | Loss = 2.0174
Testing Model 408 took 1 mins and 56 secs

Testing Model 409
[20, 14, 16, 22, 21, 22, 14, 19, 16, 22, 19, 20, 22, 12, 26, 22, 15, 17, 20, 21]
FLOPs = 1957.50M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.75 | Loss = 2.0158
Testing Model 409 took 1 mins and 59 secs

Testing Model 410
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 12, 7, 18, 15, 17, 20, 24]
FLOPs = 1954.89M
Top-1 Accuracy = 55.03 | Top-5 Accuracy = 78.60 | Loss = 2.0195
Testing Model 410 took 2 mins and 2 secs

Testing Model 411
[14, 14, 16, 22, 13, 22, 27, 19, 13, 22, 16, 23, 22, 9, 26, 15, 20, 21, 21, 21]
FLOPs = 1976.67M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.65 | Loss = 2.0179
Testing Model 411 took 1 mins and 57 secs

Testing Model 412
[20, 23, 20, 17, 20, 20, 21, 15, 16, 12, 23, 20, 19, 18, 16, 28, 23, 17, 20, 20]
FLOPs = 2005.25M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.77 | Loss = 2.0133
Testing Model 412 took 2 mins and 6 secs

Testing Model 413
[20, 14, 16, 22, 21, 22, 13, 19, 27, 22, 19, 20, 22, 12, 7, 30, 15, 17, 20, 21]
FLOPs = 1973.37M
Top-1 Accuracy = 54.93 | Top-5 Accuracy = 78.63 | Loss = 2.0229
Testing Model 413 took 1 mins and 58 secs

Testing Model 414
[20, 22, 21, 22, 20, 10, 13, 17, 16, 12, 29, 20, 22, 22, 16, 22, 3, 17, 21, 20]
FLOPs = 1953.36M
Top-1 Accuracy = 54.98 | Top-5 Accuracy = 78.47 | Loss = 2.0318
Testing Model 414 took 1 mins and 56 secs

Testing Model 415
[20, 14, 16, 22, 22, 22, 13, 19, 13, 22, 19, 20, 22, 9, 26, 22, 28, 17, 20, 21]
FLOPs = 2023.53M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.71 | Loss = 2.0166
Testing Model 415 took 2 mins and 0 secs

Testing Model 416
[14, 17, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 26, 15, 20, 21, 21, 21]
FLOPs = 1991.67M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.65 | Loss = 2.0191
Testing Model 416 took 1 mins and 55 secs

Testing Model 417
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 26, 26, 15, 9, 21, 21, 21]
FLOPs = 2011.95M
Top-1 Accuracy = 54.89 | Top-5 Accuracy = 78.62 | Loss = 2.0247
Testing Model 417 took 1 mins and 56 secs

Testing Model 418
[20, 14, 16, 22, 21, 22, 13, 19, 16, 22, 19, 20, 22, 12, 26, 22, 20, 17, 20, 21]
FLOPs = 1986.07M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.74 | Loss = 2.0158
Testing Model 418 took 1 mins and 59 secs

Testing Model 419
[14, 14, 16, 22, 14, 22, 20, 19, 22, 22, 16, 20, 22, 12, 26, 22, 15, 21, 25, 21]
FLOPs = 2025.06M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.67 | Loss = 2.0183
Testing Model 419 took 1 mins and 57 secs

Testing Model 420
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 15, 23, 13, 21, 26, 15, 20, 21, 21, 21]
FLOPs = 1972.82M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.66 | Loss = 2.0190
Testing Model 420 took 2 mins and 3 secs

Testing Model 421
[20, 14, 18, 22, 21, 22, 13, 19, 30, 22, 19, 10, 22, 12, 26, 22, 15, 17, 20, 21]
FLOPs = 2014.26M
Top-1 Accuracy = 55.00 | Top-5 Accuracy = 78.60 | Loss = 2.0209
Testing Model 421 took 1 mins and 52 secs

Testing Model 422
[14, 14, 16, 22, 21, 22, 20, 19, 3, 22, 16, 23, 22, 8, 26, 15, 27, 21, 21, 21]
FLOPs = 1974.54M
Top-1 Accuracy = 55.03 | Top-5 Accuracy = 78.57 | Loss = 2.0218
Testing Model 422 took 1 mins and 59 secs

Testing Model 423
[21, 14, 16, 22, 4, 30, 20, 19, 13, 22, 16, 23, 22, 9, 26, 15, 20, 21, 21, 21]
FLOPs = 1988.64M
Top-1 Accuracy = 55.02 | Top-5 Accuracy = 78.56 | Loss = 2.0227
Testing Model 423 took 1 mins and 53 secs

Testing Model 424
[14, 14, 16, 22, 15, 23, 20, 19, 13, 22, 16, 20, 22, 9, 26, 22, 15, 21, 27, 21]
FLOPs = 1983.91M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.64 | Loss = 2.0178
Testing Model 424 took 2 mins and 0 secs

Testing Model 425
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 26, 1, 26, 15, 20, 21, 21, 21]
FLOPs = 1965.18M
Top-1 Accuracy = 54.93 | Top-5 Accuracy = 78.44 | Loss = 2.0307
Testing Model 425 took 1 mins and 54 secs

Testing Model 426
[20, 14, 20, 22, 21, 22, 21, 19, 16, 12, 19, 20, 22, 12, 26, 22, 15, 17, 20, 21]
FLOPs = 1986.91M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.74 | Loss = 2.0149
Testing Model 426 took 1 mins and 58 secs

Testing Model 427
[14, 14, 20, 22, 20, 20, 20, 19, 13, 22, 23, 23, 22, 9, 26, 15, 23, 17, 21, 20]
FLOPs = 2027.48M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.67 | Loss = 2.0195
Testing Model 427 took 1 mins and 54 secs

Testing Model 428
[20, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 26, 15, 20, 21, 21, 21]
FLOPs = 1987.77M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.74 | Loss = 2.0160
Testing Model 428 took 1 mins and 57 secs

Testing Model 429
[20, 22, 21, 22, 21, 10, 13, 19, 16, 12, 19, 23, 22, 9, 26, 22, 15, 17, 21, 20]
FLOPs = 1971.13M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.75 | Loss = 2.0121
Testing Model 429 took 2 mins and 3 secs

Testing Model 430
[20, 23, 20, 22, 20, 20, 13, 19, 16, 12, 16, 20, 18, 18, 16, 22, 20, 17, 20, 21]
FLOPs = 1961.29M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.75 | Loss = 2.0137
Testing Model 430 took 1 mins and 53 secs

Testing Model 431
[20, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 9, 26, 22, 15, 21, 21, 21]
FLOPs = 1982.26M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.77 | Loss = 2.0135
Testing Model 431 took 1 mins and 55 secs

Testing Model 432
[20, 22, 20, 17, 20, 20, 21, 19, 16, 12, 23, 23, 22, 12, 16, 18, 20, 21, 20, 18]
FLOPs = 1957.14M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.69 | Loss = 2.0173
Testing Model 432 took 2 mins and 6 secs

Testing Model 433
[20, 22, 21, 22, 20, 20, 21, 21, 16, 12, 23, 20, 22, 12, 16, 22, 15, 17, 20, 18]
FLOPs = 2015.86M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.71 | Loss = 2.0151
Testing Model 433 took 2 mins and 0 secs

Testing Model 434
[20, 14, 16, 22, 21, 20, 20, 19, 13, 22, 19, 23, 22, 9, 26, 22, 20, 21, 21, 21]
FLOPs = 2044.18M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.82 | Loss = 2.0106
Testing Model 434 took 2 mins and 0 secs

Testing Model 435
[14, 14, 20, 17, 21, 20, 20, 19, 13, 22, 16, 23, 18, 18, 26, 22, 20, 21, 21, 21]
FLOPs = 1976.20M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.71 | Loss = 2.0153
Testing Model 435 took 1 mins and 58 secs

Testing Model 436
[20, 14, 16, 22, 21, 22, 13, 19, 13, 22, 19, 23, 22, 9, 26, 22, 20, 21, 20, 21]
FLOPs = 2011.58M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.78 | Loss = 2.0139
Testing Model 436 took 2 mins and 0 secs

Testing Model 437
[20, 14, 21, 22, 20, 20, 13, 19, 13, 22, 19, 20, 22, 22, 16, 22, 20, 21, 21, 21]
FLOPs = 2047.98M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.83 | Loss = 2.0112
Testing Model 437 took 1 mins and 59 secs

Testing Model 438
[20, 23, 20, 22, 20, 20, 21, 15, 16, 12, 16, 20, 22, 9, 16, 22, 20, 17, 21, 20]
FLOPs = 1959.47M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.71 | Loss = 2.0132
Testing Model 438 took 1 mins and 56 secs

Testing Model 439
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 9, 26, 22, 20, 21, 20, 21]
FLOPs = 2005.58M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.68 | Loss = 2.0164
Testing Model 439 took 2 mins and 1 secs

Testing Model 440
[20, 22, 21, 22, 20, 20, 13, 21, 13, 12, 16, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1986.26M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.74 | Loss = 2.0133
Testing Model 440 took 2 mins and 1 secs

Testing Model 441
[20, 23, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 18, 16, 18, 23, 17, 20, 18]
FLOPs = 2048.81M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.61 | Loss = 2.0178
Testing Model 441 took 2 mins and 3 secs

Testing Model 442
[20, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 9, 26, 22, 20, 17, 20, 21]
FLOPs = 1998.75M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.75 | Loss = 2.0159
Testing Model 442 took 1 mins and 53 secs

Testing Model 443
[20, 14, 16, 22, 21, 20, 20, 19, 13, 22, 16, 23, 22, 9, 26, 15, 20, 21, 21, 21]
FLOPs = 1978.38M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.77 | Loss = 2.0141
Testing Model 443 took 1 mins and 57 secs

Testing Model 444
[20, 22, 21, 22, 21, 10, 13, 19, 16, 12, 19, 20, 22, 12, 26, 22, 15, 17, 20, 20]
FLOPs = 1953.14M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.72 | Loss = 2.0132
Testing Model 444 took 2 mins and 1 secs

Testing Model 445
[14, 14, 16, 22, 21, 20, 20, 19, 13, 22, 16, 23, 22, 9, 26, 22, 20, 21, 21, 21]
FLOPs = 1999.66M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.66 | Loss = 2.0163
Testing Model 445 took 1 mins and 58 secs

Testing Model 446
[20, 23, 20, 17, 20, 20, 20, 19, 16, 12, 23, 20, 18, 18, 16, 22, 20, 17, 20, 20]
FLOPs = 1953.57M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.74 | Loss = 2.0135
Testing Model 446 took 2 mins and 0 secs

Testing Model 447
[20, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 9, 26, 22, 20, 21, 21, 21]
FLOPs = 2040.48M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.75 | Loss = 2.0126
Testing Model 447 took 1 mins and 58 secs

Testing Model 448
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 21, 21]
FLOPs = 1958.93M
Top-1 Accuracy = 55.26 | Top-5 Accuracy = 78.69 | Loss = 2.0163
Testing Model 448 took 1 mins and 53 secs

Testing Model 449
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 19, 23, 22, 12, 26, 22, 15, 17, 21, 21]
FLOPs = 1978.75M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.67 | Loss = 2.0192
Testing Model 449 took 2 mins and 0 secs

Testing Model 450
[20, 14, 16, 22, 21, 20, 13, 21, 13, 22, 19, 20, 22, 22, 16, 22, 20, 21, 21, 20]
FLOPs = 1995.94M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.80 | Loss = 2.0119
Testing Model 450 took 1 mins and 57 secs

> Select
Iteration 8 : Showing Top 50 results
1. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.640439987182617
2. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.574835777282715
3. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.54874038696289
4. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.539837837219238
5. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.534582138061523
6. [20. 23. 20. 17. 20. 20. 20. 19. 13. 12. 16. 23. 18. 18. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.531522750854492
7. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22.  9. 26. 22. 15. 21.
 21. 21.] 
Reward = 15.5304536819458
8. [20. 14. 16. 22. 21. 22. 13. 19. 13. 22. 19. 20. 22.  9. 26. 22. 20. 17.
 20. 21.] 
Reward = 15.494070053100586
9. [20. 14. 16. 22. 21. 22. 14. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.489802360534668
10. [20. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  9. 16. 22. 20. 21.
 21. 21.] 
Reward = 15.483205795288086
11. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
12. [20. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.471687316894531
13. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 19. 15. 17.
 20. 18.] 
Reward = 15.46304988861084
14. [20. 14. 20. 22. 21. 22. 13. 19. 13. 12. 23. 20. 22. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.44775390625
15. [20. 22. 21. 22. 21. 10. 13. 19. 16. 12. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 20.] 
Reward = 15.444304466247559
16. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.433782577514648
17. [20. 22. 20. 22. 20. 10. 20. 19. 16. 12. 19. 23. 18. 18. 16. 22. 15. 21.
 20. 20.] 
Reward = 15.431556701660156
18. [20. 22. 21. 22. 20. 10. 13. 19. 16. 12. 19. 23. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.430253028869629
19. [18. 25. 17. 17. 13. 11. 21. 22. 16. 26. 18. 20. 23. 17. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.428112983703613
20. [20. 14. 16. 22. 21. 20. 20. 19. 16. 22. 19. 23. 22.  9. 16. 22. 15. 21.
 21. 21.] 
Reward = 15.423428535461426
21. [19. 23. 20. 17. 20. 20. 21. 15. 16. 22. 23. 20. 18. 18. 13. 18. 23. 17.
 20. 18.] 
Reward = 15.420969009399414
22. [20. 22. 21. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 22. 15. 21.
 21. 20.] 
Reward = 15.418389320373535
23. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.417957305908203
24. [20. 23. 20. 22. 20. 10. 21. 21. 16. 12. 19. 20. 18. 18. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.416579246520996
25. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.416141510009766
26. [20. 23. 20. 17. 20. 20. 20. 19. 16. 12. 23. 20. 18. 18. 16. 22. 20. 17.
 20. 20.] 
Reward = 15.415833473205566
27. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 19. 20. 15. 23.
 18. 20.] 
Reward = 15.400196075439453
28. [20. 22. 20. 18. 20. 12. 21. 22. 16. 12. 18. 20. 22. 18. 16. 23. 15. 21.
 23. 18.] 
Reward = 15.392885208129883
29. [20. 23. 20. 22. 20. 20. 13. 19. 16. 12. 16. 20. 18. 18. 16. 22. 20. 17.
 20. 21.] 
Reward = 15.389420509338379
30. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.381397247314453
31. [20. 22. 21. 22. 20. 20. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.377861022949219
32. [20. 22. 21. 18. 20. 12. 23. 22. 16. 22. 19. 20. 22. 18. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.376130104064941
33. [20. 22. 21. 17. 13. 20. 21. 22. 16. 22. 19. 20. 22. 18. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.373248100280762
34. [14. 14. 16. 22. 21.  9. 20. 19. 24. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.370867729187012
35. [20. 22. 20. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 23. 15. 21.
 21. 18.] 
Reward = 15.366320610046387
36. [20. 22. 20. 22. 20. 20. 13. 15. 16. 12. 23. 20. 18. 18. 16. 18. 23. 17.
 20. 20.] 
Reward = 15.36349105834961
37. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 18. 18. 15. 17.
 20. 20.] 
Reward = 15.349184036254883
38. [18. 20. 17. 17. 21. 22. 17. 20. 22. 13. 16. 20. 23. 18. 19. 20. 21. 23.
 18. 20.] 
Reward = 15.347654342651367
39. [21. 22. 22. 18. 22. 18. 14. 19. 20. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.344067573547363
40. [20. 14. 20. 22. 20. 20. 20. 15. 13. 12. 23. 20. 22.  9. 16. 22. 23. 21.
 21. 21.] 
Reward = 15.340524673461914
41. [19. 23. 20. 18. 20. 12. 23. 15. 12. 16. 23. 22. 18. 18. 13. 23. 23. 21.
 20. 18.] 
Reward = 15.3290376663208
42. [18. 25. 20. 17. 20. 11. 21. 22. 16. 26. 18. 20. 18. 17. 13. 18. 23. 17.
 20. 20.] 
Reward = 15.326105117797852
43. [20. 22. 20. 17. 20. 23.  9. 21. 24. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.323432922363281
44. [20. 22. 21. 22. 20. 20. 13. 21. 20. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.319889068603516
45. [20. 22. 21. 22. 20. 20. 21. 22. 16. 12. 18. 20. 22. 12. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.305963516235352
46. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 16. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.30229377746582
47. [21. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.291874885559082
48. [20. 22. 20. 17. 21. 22. 21. 21. 13. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 21.] 
Reward = 15.289995193481445
49. [18. 20. 17. 17. 13. 23. 21. 22. 16. 22. 18. 20. 23. 18. 19. 20. 15. 23.
 18. 20.] 
Reward = 15.289787292480469
50. [20. 20. 21. 17. 13. 22. 21. 22. 20. 22. 18. 20. 19. 18. 16. 18. 15. 17.
 23. 20.] 
Reward = 15.288784980773926
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 8 took 1 hour 39 mins 6 secs



Testing Model 451
[20, 7, 16, 22, 21, 22, 28, 19, 16, 22, 19, 20, 22, 12, 26, 22, 15, 17, 20, 21]
FLOPs = 1971.31M
Top-1 Accuracy = 55.04 | Top-5 Accuracy = 78.65 | Loss = 2.0210
Testing Model 451 took 1 mins and 58 secs

Testing Model 452
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 12, 19, 18, 15, 17, 20, 18]
FLOPs = 1969.29M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.63 | Loss = 2.0178
Testing Model 452 took 1 mins and 57 secs

Testing Model 453
[20, 21, 16, 22, 21, 20, 20, 19, 13, 22, 16, 23, 22, 9, 20, 22, 2, 21, 21, 21]
FLOPs = 1955.46M
Top-1 Accuracy = 54.77 | Top-5 Accuracy = 78.39 | Loss = 2.0310
Testing Model 453 took 2 mins and 0 secs

Testing Model 454
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 25, 20, 22, 12, 26, 18, 15, 21, 21, 21]
FLOPs = 2018.48M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.72 | Loss = 2.0161
Testing Model 454 took 1 mins and 55 secs

Testing Model 455
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 24, 17, 26, 18, 15, 21, 21, 21]
FLOPs = 2004.88M
Top-1 Accuracy = 55.24 | Top-5 Accuracy = 78.72 | Loss = 2.0171
Testing Model 455 took 1 mins and 58 secs

Testing Model 456
[20, 23, 20, 17, 20, 20, 24, 19, 13, 12, 16, 23, 18, 18, 16, 22, 20, 22, 20, 21]
FLOPs = 1992.22M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.77 | Loss = 2.0119
Testing Model 456 took 1 mins and 58 secs

Testing Model 457
[14, 22, 2, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 23, 26, 18, 22, 21, 21, 21]
FLOPs = 1969.04M
Top-1 Accuracy = 54.65 | Top-5 Accuracy = 78.38 | Loss = 2.0389
Testing Model 457 took 2 mins and 5 secs

Testing Model 458
[9, 19, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 21, 21]
FLOPs = 1984.27M
Top-1 Accuracy = 54.79 | Top-5 Accuracy = 78.48 | Loss = 2.0358
Testing Model 458 took 1 mins and 57 secs

Testing Model 459
[14, 14, 16, 22, 21, 22, 20, 22, 13, 29, 7, 23, 22, 8, 26, 15, 20, 21, 21, 21]
FLOPs = 1994.48M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.56 | Loss = 2.0219
Testing Model 459 took 2 mins and 6 secs

Testing Model 460
[14, 14, 16, 22, 21, 22, 20, 19, 23, 22, 16, 21, 22, 9, 26, 22, 15, 21, 21, 21]
FLOPs = 2025.50M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.66 | Loss = 2.0155
Testing Model 460 took 1 mins and 50 secs

Testing Model 461
[20, 14, 16, 22, 21, 16, 20, 19, 13, 22, 16, 23, 22, 9, 16, 29, 20, 21, 21, 21]
FLOPs = 1989.18M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.77 | Loss = 2.0152
Testing Model 461 took 1 mins and 59 secs

Testing Model 462
[20, 14, 16, 22, 27, 22, 14, 19, 16, 22, 0, 20, 22, 12, 26, 22, 15, 25, 20, 21]
FLOPs = 1987.14M
Top-1 Accuracy = 54.90 | Top-5 Accuracy = 78.43 | Loss = 2.0329
Testing Model 462 took 2 mins and 1 secs

Testing Model 463
[14, 14, 16, 26, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 21, 21]
FLOPs = 2032.48M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.67 | Loss = 2.0167
Testing Model 463 took 1 mins and 55 secs

Testing Model 464
[20, 14, 16, 22, 21, 22, 13, 19, 16, 22, 19, 20, 22, 12, 28, 22, 15, 17, 20, 21]
FLOPs = 1969.09M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.77 | Loss = 2.0160
Testing Model 464 took 2 mins and 1 secs

Testing Model 465
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 2, 20, 22, 22, 14, 22, 28, 17, 21, 20]
FLOPs = 1962.50M
Top-1 Accuracy = 54.91 | Top-5 Accuracy = 78.64 | Loss = 2.0275
Testing Model 465 took 2 mins and 10 secs

Testing Model 466
[20, 22, 21, 22, 20, 15, 13, 21, 16, 12, 19, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1992.51M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.73 | Loss = 2.0130
Testing Model 466 took 2 mins and 1 secs

Testing Model 467
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 22, 21, 21]
FLOPs = 1968.36M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.64 | Loss = 2.0181
Testing Model 467 took 2 mins and 7 secs

Testing Model 468
[14, 14, 16, 22, 21, 22, 21, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 21, 21]
FLOPs = 1965.70M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.65 | Loss = 2.0167
Testing Model 468 took 1 mins and 57 secs

Testing Model 469
[17, 14, 16, 22, 21, 22, 13, 19, 16, 22, 19, 20, 22, 12, 26, 22, 15, 27, 20, 21]
FLOPs = 2031.09M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.73 | Loss = 2.0149
Testing Model 469 took 2 mins and 5 secs

Testing Model 470
[20, 14, 16, 22, 21, 22, 13, 19, 16, 22, 19, 20, 22, 16, 30, 22, 15, 17, 20, 21]
FLOPs = 2011.95M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.80 | Loss = 2.0152
Testing Model 470 took 1 mins and 56 secs

Testing Model 471
[20, 14, 16, 22, 21, 22, 14, 19, 16, 22, 19, 20, 22, 12, 26, 22, 15, 23, 20, 21]
FLOPs = 2009.86M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.79 | Loss = 2.0117
Testing Model 471 took 2 mins and 13 secs

Testing Model 472
[20, 22, 21, 22, 9, 10, 13, 21, 28, 12, 19, 20, 23, 22, 16, 17, 15, 17, 21, 20]
FLOPs = 1970.61M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.71 | Loss = 2.0149
Testing Model 472 took 1 mins and 56 secs

Testing Model 473
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 12, 16, 18, 15, 17, 26, 18]
FLOPs = 2001.97M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.68 | Loss = 2.0167
Testing Model 473 took 2 mins and 0 secs

Testing Model 474
[20, 23, 20, 19, 20, 20, 20, 19, 13, 12, 16, 23, 18, 18, 16, 22, 20, 21, 20, 21]
FLOPs = 1989.66M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.78 | Loss = 2.0095
Testing Model 474 took 2 mins and 3 secs

Testing Model 475
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 18, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 1951.68M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.70 | Loss = 2.0167
Testing Model 475 took 2 mins and 1 secs

Testing Model 476
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 26, 22, 15, 21, 21, 21]
FLOPs = 1975.18M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.68 | Loss = 2.0174
Testing Model 476 took 2 mins and 1 secs

Testing Model 477
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 22, 15, 21, 21, 21]
FLOPs = 1987.93M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.70 | Loss = 2.0164
Testing Model 477 took 1 mins and 58 secs

Testing Model 478
[20, 23, 20, 17, 20, 20, 20, 19, 13, 22, 16, 23, 18, 9, 16, 22, 20, 21, 20, 21]
FLOPs = 1967.81M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.75 | Loss = 2.0139
Testing Model 478 took 2 mins and 1 secs

Testing Model 479
[20, 14, 16, 22, 20, 22, 13, 19, 16, 22, 19, 20, 22, 22, 26, 22, 15, 17, 21, 21]
FLOPs = 2019.62M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.75 | Loss = 2.0141
Testing Model 479 took 2 mins and 5 secs

Testing Model 480
[20, 23, 20, 17, 21, 22, 20, 19, 13, 12, 19, 20, 18, 12, 26, 22, 20, 21, 20, 21]
FLOPs = 2002.84M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.80 | Loss = 2.0109
Testing Model 480 took 2 mins and 0 secs

Testing Model 481
[20, 14, 16, 22, 21, 22, 14, 19, 16, 22, 19, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 1962.38M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.76 | Loss = 2.0156
Testing Model 481 took 2 mins and 2 secs

Testing Model 482
[20, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 26, 22, 15, 21, 21, 21]
FLOPs = 2002.23M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.73 | Loss = 2.0153
Testing Model 482 took 2 mins and 4 secs

Testing Model 483
[20, 22, 21, 22, 21, 10, 13, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 17, 21, 20]
FLOPs = 1978.76M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.74 | Loss = 2.0148
Testing Model 483 took 1 mins and 59 secs

Testing Model 484
[20, 14, 21, 22, 20, 22, 20, 21, 16, 12, 16, 20, 22, 22, 16, 22, 15, 21, 21, 20]
FLOPs = 2008.52M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.79 | Loss = 2.0144
Testing Model 484 took 1 mins and 56 secs

Testing Model 485
[20, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 20, 21, 21, 21]
FLOPs = 2019.84M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.79 | Loss = 2.0146
Testing Model 485 took 1 mins and 53 secs

Testing Model 486
[20, 22, 20, 17, 20, 20, 20, 21, 13, 12, 16, 23, 22, 12, 16, 22, 20, 21, 20, 21]
FLOPs = 1950.52M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.79 | Loss = 2.0119
Testing Model 486 took 1 mins and 54 secs

Testing Model 487
[14, 22, 21, 22, 20, 10, 13, 19, 13, 22, 19, 20, 22, 22, 26, 22, 15, 17, 21, 21]
FLOPs = 2045.96M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.70 | Loss = 2.0164
Testing Model 487 took 2 mins and 0 secs

Testing Model 488
[20, 22, 20, 17, 21, 20, 21, 21, 13, 22, 23, 20, 22, 12, 16, 22, 20, 17, 20, 21]
FLOPs = 2021.10M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.75 | Loss = 2.0121
Testing Model 488 took 1 mins and 57 secs

Testing Model 489
[20, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 8, 26, 22, 20, 21, 21, 21]
FLOPs = 2011.75M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.76 | Loss = 2.0146
Testing Model 489 took 1 mins and 55 secs

Testing Model 490
[20, 22, 21, 22, 21, 10, 20, 19, 16, 12, 16, 23, 22, 9, 16, 22, 20, 17, 21, 21]
FLOPs = 1963.33M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.71 | Loss = 2.0144
Testing Model 490 took 1 mins and 56 secs

Testing Model 491
[20, 14, 16, 22, 21, 22, 13, 19, 13, 22, 16, 23, 22, 12, 26, 22, 20, 17, 21, 21]
FLOPs = 1983.66M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.75 | Loss = 2.0150
Testing Model 491 took 1 mins and 52 secs

Testing Model 492
[20, 14, 21, 22, 20, 22, 13, 21, 16, 12, 19, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1954.92M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.78 | Loss = 2.0149
Testing Model 492 took 1 mins and 53 secs

Testing Model 493
[20, 14, 16, 22, 21, 20, 13, 19, 16, 22, 19, 23, 22, 12, 26, 22, 15, 21, 20, 21]
FLOPs = 1996.65M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.83 | Loss = 2.0122
Testing Model 493 took 1 mins and 55 secs

Testing Model 494
[20, 14, 16, 22, 21, 22, 14, 19, 16, 22, 19, 20, 22, 9, 26, 22, 20, 17, 20, 21]
FLOPs = 1975.78M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.75 | Loss = 2.0174
Testing Model 494 took 1 mins and 54 secs

Testing Model 495
[20, 14, 16, 22, 21, 22, 13, 21, 16, 12, 19, 20, 22, 22, 26, 22, 15, 17, 21, 21]
FLOPs = 1980.26M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.74 | Loss = 2.0162
Testing Model 495 took 1 mins and 52 secs

Testing Model 496
[14, 14, 16, 22, 21, 22, 13, 19, 13, 22, 16, 23, 22, 9, 26, 22, 20, 21, 21, 21]
FLOPs = 1974.90M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.64 | Loss = 2.0161
Testing Model 496 took 1 mins and 56 secs

Testing Model 497
[20, 14, 16, 22, 21, 20, 20, 19, 13, 22, 19, 23, 22, 9, 16, 22, 20, 21, 21, 21]
FLOPs = 1969.98M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.74 | Loss = 2.0123
Testing Model 497 took 1 mins and 52 secs

Testing Model 498
[20, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 9, 26, 22, 20, 21, 20, 21]
FLOPs = 2049.75M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.73 | Loss = 2.0129
Testing Model 498 took 1 mins and 53 secs

Testing Model 499
[20, 14, 16, 22, 21, 22, 20, 19, 13, 22, 19, 20, 22, 9, 26, 22, 20, 17, 20, 21]
FLOPs = 1991.88M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.69 | Loss = 2.0155
Testing Model 499 took 1 mins and 54 secs

Testing Model 500
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 15, 20, 21, 21, 21]
FLOPs = 1973.47M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.67 | Loss = 2.0174
Testing Model 500 took 1 mins and 55 secs

> Select
Iteration 9 : Showing Top 50 results
1. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.640439987182617
2. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.574835777282715
3. [20. 22. 20. 17. 20. 20. 20. 21. 13. 12. 16. 23. 22. 12. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.564648628234863
4. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 18. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.556252479553223
5. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.54874038696289
6. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.539837837219238
7. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.534582138061523
8. [20. 23. 20. 17. 20. 20. 20. 19. 13. 12. 16. 23. 18. 18. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.531522750854492
9. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22.  9. 26. 22. 15. 21.
 21. 21.] 
Reward = 15.5304536819458
10. [20. 14. 16. 22. 21. 22. 13. 19. 13. 22. 19. 20. 22.  9. 26. 22. 20. 17.
 20. 21.] 
Reward = 15.494070053100586
11. [20. 14. 16. 22. 21. 22. 14. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.489802360534668
12. [20. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  9. 16. 22. 20. 21.
 21. 21.] 
Reward = 15.483205795288086
13. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
14. [20. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.471687316894531
15. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 19. 15. 17.
 20. 18.] 
Reward = 15.46304988861084
16. [20. 14. 20. 22. 21. 22. 13. 19. 13. 12. 23. 20. 22. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.44775390625
17. [20. 22. 21. 22. 21. 10. 13. 19. 16. 12. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 20.] 
Reward = 15.444304466247559
18. [14. 14. 16. 22. 21. 22. 21. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.442277908325195
19. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.433782577514648
20. [20. 22. 20. 22. 20. 10. 20. 19. 16. 12. 19. 23. 18. 18. 16. 22. 15. 21.
 20. 20.] 
Reward = 15.431556701660156
21. [20. 22. 21. 22. 20. 10. 13. 19. 16. 12. 19. 23. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.430253028869629
22. [18. 25. 17. 17. 13. 11. 21. 22. 16. 26. 18. 20. 23. 17. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.428112983703613
23. [20. 14. 16. 22. 21. 20. 20. 19. 16. 22. 19. 23. 22.  9. 16. 22. 15. 21.
 21. 21.] 
Reward = 15.423428535461426
24. [19. 23. 20. 17. 20. 20. 21. 15. 16. 22. 23. 20. 18. 18. 13. 18. 23. 17.
 20. 18.] 
Reward = 15.420969009399414
25. [20. 22. 21. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 22. 15. 21.
 21. 20.] 
Reward = 15.418389320373535
26. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.417957305908203
27. [20. 23. 20. 22. 20. 10. 21. 21. 16. 12. 19. 20. 18. 18. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.416579246520996
28. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.416141510009766
29. [20. 23. 20. 17. 20. 20. 20. 19. 16. 12. 23. 20. 18. 18. 16. 22. 20. 17.
 20. 20.] 
Reward = 15.415833473205566
30. [20. 14. 21. 22. 20. 22. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.409370422363281
31. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 22.
 21. 21.] 
Reward = 15.401910781860352
32. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 19. 20. 15. 23.
 18. 20.] 
Reward = 15.400196075439453
33. [20. 22. 20. 18. 20. 12. 21. 22. 16. 12. 18. 20. 22. 18. 16. 23. 15. 21.
 23. 18.] 
Reward = 15.392885208129883
34. [20. 23. 20. 22. 20. 20. 13. 19. 16. 12. 16. 20. 18. 18. 16. 22. 20. 17.
 20. 21.] 
Reward = 15.389420509338379
35. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.381397247314453
36. [20. 22. 21. 22. 20. 20. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.377861022949219
37. [20. 22. 21. 18. 20. 12. 23. 22. 16. 22. 19. 20. 22. 18. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.376130104064941
38. [20. 22. 21. 17. 13. 20. 21. 22. 16. 22. 19. 20. 22. 18. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.373248100280762
39. [14. 14. 16. 22. 21.  9. 20. 19. 24. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.370867729187012
40. [20. 22. 20. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 23. 15. 21.
 21. 18.] 
Reward = 15.366320610046387
41. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 28. 22. 15. 17.
 20. 21.] 
Reward = 15.366180419921875
42. [20. 22. 20. 22. 20. 20. 13. 15. 16. 12. 23. 20. 18. 18. 16. 18. 23. 17.
 20. 20.] 
Reward = 15.36349105834961
43. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 23. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.36010456085205
44. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 19. 18. 15. 17.
 20. 18.] 
Reward = 15.356070518493652
45. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 18. 18. 15. 17.
 20. 20.] 
Reward = 15.349184036254883
46. [18. 20. 17. 17. 21. 22. 17. 20. 22. 13. 16. 20. 23. 18. 19. 20. 21. 23.
 18. 20.] 
Reward = 15.347654342651367
47. [21. 22. 22. 18. 22. 18. 14. 19. 20. 23. 14. 17. 23. 17. 19. 17. 13. 22.
 17. 19.] 
Reward = 15.344067573547363
48. [20. 14. 20. 22. 20. 20. 20. 15. 13. 12. 23. 20. 22.  9. 16. 22. 23. 21.
 21. 21.] 
Reward = 15.340524673461914
49. [19. 23. 20. 18. 20. 12. 23. 15. 12. 16. 23. 22. 18. 18. 13. 23. 23. 21.
 20. 18.] 
Reward = 15.3290376663208
50. [20. 22. 21. 22.  9. 10. 13. 21. 28. 12. 19. 20. 23. 22. 16. 17. 15. 17.
 21. 20.] 
Reward = 15.326154708862305
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 9 took 1 hour 39 mins 32 secs



Testing Model 501
[20, 14, 16, 22, 21, 22, 13, 3, 13, 22, 19, 20, 22, 9, 26, 22, 20, 29, 20, 21]
FLOPs = 1978.54M
Top-1 Accuracy = 54.84 | Top-5 Accuracy = 78.56 | Loss = 2.0279
Testing Model 501 took 1 mins and 52 secs

Testing Model 502
[20, 22, 21, 22, 20, 10, 13, 21, 16, 25, 19, 20, 22, 22, 16, 22, 5, 17, 21, 20]
FLOPs = 2000.66M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.56 | Loss = 2.0241
Testing Model 502 took 1 mins and 55 secs

Testing Model 503
[14, 8, 16, 22, 21, 22, 20, 19, 16, 22, 16, 9, 22, 23, 26, 18, 15, 26, 22, 21]
FLOPs = 1953.12M
Top-1 Accuracy = 54.96 | Top-5 Accuracy = 78.51 | Loss = 2.0276
Testing Model 503 took 1 mins and 52 secs

Testing Model 504
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 27, 21, 21, 21]
FLOPs = 2047.43M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.72 | Loss = 2.0174
Testing Model 504 took 1 mins and 51 secs

Testing Model 505
[30, 23, 20, 17, 20, 20, 20, 19, 13, 12, 16, 23, 18, 18, 16, 22, 20, 21, 20, 15]
FLOPs = 1959.71M
Top-1 Accuracy = 54.90 | Top-5 Accuracy = 78.57 | Loss = 2.0207
Testing Model 505 took 1 mins and 56 secs

Testing Model 506
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 18, 22, 29, 26, 18, 15, 21, 22, 14]
FLOPs = 2024.43M
Top-1 Accuracy = 54.91 | Top-5 Accuracy = 78.46 | Loss = 2.0295
Testing Model 506 took 1 mins and 52 secs

Testing Model 507
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 19, 20, 22, 22, 16, 22, 15, 17, 21, 21]
FLOPs = 1971.14M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.78 | Loss = 2.0097
Testing Model 507 took 1 mins and 55 secs

Testing Model 508
[20, 23, 20, 17, 20, 20, 20, 20, 13, 12, 16, 23, 18, 18, 16, 22, 20, 21, 20, 21]
FLOPs = 1959.96M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.75 | Loss = 2.0117
Testing Model 508 took 1 mins and 52 secs

Testing Model 509
[20, 22, 25, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 12, 16, 18, 15, 17, 20, 18]
FLOPs = 2021.64M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.70 | Loss = 2.0186
Testing Model 509 took 2 mins and 0 secs

Testing Model 510
[14, 14, 16, 22, 21, 22, 20, 21, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 1982.82M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.70 | Loss = 2.0179
Testing Model 510 took 1 mins and 54 secs

Testing Model 511
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 12, 23, 22, 8, 26, 19, 20, 21, 21, 21]
FLOPs = 1964.84M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.67 | Loss = 2.0199
Testing Model 511 took 1 mins and 54 secs

Testing Model 512
[14, 14, 16, 22, 21, 27, 20, 19, 16, 22, 16, 18, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 1990.07M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.69 | Loss = 2.0178
Testing Model 512 took 1 mins and 53 secs

Testing Model 513
[14, 14, 16, 22, 2, 22, 30, 19, 16, 22, 16, 18, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 1953.49M
Top-1 Accuracy = 54.99 | Top-5 Accuracy = 78.57 | Loss = 2.0259
Testing Model 513 took 1 mins and 54 secs

Testing Model 514
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 19, 26, 22, 22, 16, 24, 15, 17, 21, 20]
FLOPs = 2031.87M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.74 | Loss = 2.0142
Testing Model 514 took 1 mins and 59 secs

Testing Model 515
[20, 14, 13, 22, 21, 22, 13, 19, 13, 22, 21, 20, 26, 9, 26, 22, 20, 17, 20, 21]
FLOPs = 1959.70M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.68 | Loss = 2.0159
Testing Model 515 took 1 mins and 52 secs

Testing Model 516
[20, 22, 20, 17, 9, 25, 21, 21, 16, 22, 23, 20, 22, 12, 29, 8, 15, 17, 20, 18]
FLOPs = 1977.24M
Top-1 Accuracy = 54.81 | Top-5 Accuracy = 78.54 | Loss = 2.0277
Testing Model 516 took 1 mins and 55 secs

Testing Model 517
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 19, 20, 22, 22, 16, 22, 15, 13, 30, 20]
FLOPs = 2014.39M
Top-1 Accuracy = 55.01 | Top-5 Accuracy = 78.68 | Loss = 2.0157
Testing Model 517 took 1 mins and 55 secs

Testing Model 518
[14, 14, 16, 22, 27, 22, 20, 19, 13, 22, 16, 23, 22, 8, 26, 15, 20, 21, 21, 16]
FLOPs = 1964.16M
Top-1 Accuracy = 55.04 | Top-5 Accuracy = 78.42 | Loss = 2.0261
Testing Model 518 took 1 mins and 53 secs

Testing Model 519
[13, 23, 20, 17, 20, 18, 20, 19, 13, 12, 16, 23, 30, 18, 23, 22, 20, 21, 20, 21]
FLOPs = 2040.21M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.73 | Loss = 2.0121
Testing Model 519 took 1 mins and 51 secs

Testing Model 520
[20, 23, 20, 17, 20, 20, 21, 19, 13, 12, 16, 23, 18, 18, 16, 22, 20, 21, 20, 21]
FLOPs = 1959.00M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.73 | Loss = 2.0106
Testing Model 520 took 1 mins and 54 secs

Testing Model 521
[20, 14, 16, 22, 21, 22, 13, 19, 13, 22, 19, 28, 22, 9, 26, 22, 20, 17, 20, 21]
FLOPs = 2022.02M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.78 | Loss = 2.0139
Testing Model 521 took 1 mins and 52 secs

Testing Model 522
[20, 22, 20, 17, 20, 20, 20, 21, 13, 12, 16, 25, 22, 12, 16, 22, 20, 21, 20, 21]
FLOPs = 1967.68M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.75 | Loss = 2.0126
Testing Model 522 took 2 mins and 2 secs

Testing Model 523
[14, 14, 16, 22, 21, 22, 18, 19, 13, 22, 16, 29, 22, 9, 26, 22, 15, 21, 21, 21]
FLOPs = 2020.98M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.66 | Loss = 2.0172
Testing Model 523 took 1 mins and 51 secs

Testing Model 524
[20, 23, 20, 17, 23, 20, 20, 19, 13, 12, 16, 29, 18, 18, 16, 22, 20, 21, 20, 21]
FLOPs = 2027.12M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.76 | Loss = 2.0110
Testing Model 524 took 1 mins and 53 secs

Testing Model 525
[14, 23, 16, 22, 0, 22, 20, 19, 13, 22, 16, 23, 22, 8, 26, 15, 20, 21, 21, 21]
FLOPs = 1964.87M
Top-1 Accuracy = 54.85 | Top-5 Accuracy = 78.41 | Loss = 2.0312
Testing Model 525 took 1 mins and 56 secs

Testing Model 526
[14, 23, 20, 17, 20, 20, 20, 19, 13, 22, 16, 20, 18, 18, 26, 18, 15, 21, 20, 21]
FLOPs = 1972.81M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.80 | Loss = 2.0151
Testing Model 526 took 1 mins and 54 secs

Testing Model 527
[20, 14, 21, 22, 20, 22, 13, 19, 16, 22, 19, 20, 22, 22, 16, 22, 15, 17, 20, 20]
FLOPs = 1996.87M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.75 | Loss = 2.0132
Testing Model 527 took 1 mins and 54 secs

Testing Model 528
[14, 22, 16, 22, 21, 22, 13, 21, 16, 12, 16, 20, 22, 9, 26, 22, 15, 21, 21, 21]
FLOPs = 1966.86M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.74 | Loss = 2.0160
Testing Model 528 took 1 mins and 57 secs

Testing Model 529
[14, 22, 20, 22, 20, 22, 20, 21, 16, 22, 16, 20, 22, 8, 16, 15, 20, 17, 21, 21]
FLOPs = 1994.15M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.61 | Loss = 2.0189
Testing Model 529 took 1 mins and 56 secs

Testing Model 530
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 1967.52M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.70 | Loss = 2.0160
Testing Model 530 took 1 mins and 51 secs

Testing Model 531
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 9, 26, 22, 15, 21, 21, 21]
FLOPs = 1972.33M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.66 | Loss = 2.0195
Testing Model 531 took 1 mins and 55 secs

Testing Model 532
[20, 22, 20, 17, 20, 20, 20, 21, 13, 22, 16, 23, 22, 12, 16, 22, 20, 17, 20, 21]
FLOPs = 1983.15M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.73 | Loss = 2.0135
Testing Model 532 took 1 mins and 56 secs

Testing Model 533
[20, 23, 20, 22, 21, 20, 13, 19, 13, 12, 19, 20, 22, 9, 16, 22, 20, 21, 20, 21]
FLOPs = 1978.70M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.78 | Loss = 2.0137
Testing Model 533 took 1 mins and 57 secs

Testing Model 534
[20, 23, 20, 22, 20, 20, 20, 19, 13, 22, 16, 20, 22, 9, 16, 22, 15, 21, 20, 21]
FLOPs = 2028.45M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.78 | Loss = 2.0114
Testing Model 534 took 2 mins and 1 secs

Testing Model 535
[14, 23, 16, 22, 20, 20, 20, 19, 13, 12, 16, 23, 18, 18, 26, 22, 20, 21, 21, 21]
FLOPs = 2046.68M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.79 | Loss = 2.0142
Testing Model 535 took 1 mins and 57 secs

Testing Model 536
[20, 22, 16, 22, 20, 22, 13, 19, 16, 12, 19, 20, 22, 22, 26, 18, 15, 21, 22, 20]
FLOPs = 2043.18M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.82 | Loss = 2.0111
Testing Model 536 took 1 mins and 58 secs

Testing Model 537
[20, 23, 20, 17, 20, 22, 20, 19, 13, 22, 16, 20, 18, 18, 16, 18, 20, 21, 20, 21]
FLOPs = 1979.63M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.76 | Loss = 2.0144
Testing Model 537 took 1 mins and 56 secs

Testing Model 538
[14, 22, 20, 22, 21, 22, 21, 21, 16, 22, 23, 20, 22, 12, 16, 18, 15, 17, 22, 18]
FLOPs = 2047.37M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.64 | Loss = 2.0189
Testing Model 538 took 1 mins and 59 secs

Testing Model 539
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 12, 16, 22, 20, 17, 20, 21]
FLOPs = 2032.79M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.74 | Loss = 2.0142
Testing Model 539 took 1 mins and 56 secs

Testing Model 540
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 8, 26, 18, 20, 21, 21, 21]
FLOPs = 1997.18M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.63 | Loss = 2.0187
Testing Model 540 took 1 mins and 55 secs

Testing Model 541
[20, 22, 16, 22, 20, 22, 20, 19, 13, 22, 16, 20, 22, 12, 16, 22, 20, 17, 20, 21]
FLOPs = 1993.36M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.72 | Loss = 2.0160
Testing Model 541 took 1 mins and 53 secs

Testing Model 542
[20, 14, 16, 22, 21, 22, 20, 19, 16, 22, 19, 20, 22, 12, 26, 18, 15, 17, 20, 21]
FLOPs = 1961.72M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.73 | Loss = 2.0165
Testing Model 542 took 1 mins and 56 secs

Testing Model 543
[20, 23, 20, 17, 20, 20, 13, 19, 13, 12, 19, 23, 22, 18, 26, 22, 20, 21, 20, 21]
FLOPs = 2022.44M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.79 | Loss = 2.0105
Testing Model 543 took 1 mins and 52 secs

Testing Model 544
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 26, 15, 20, 21, 21, 21]
FLOPs = 1980.70M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.68 | Loss = 2.0186
Testing Model 544 took 1 mins and 53 secs

Testing Model 545
[14, 14, 16, 22, 21, 22, 13, 19, 13, 22, 16, 20, 22, 9, 26, 22, 20, 21, 21, 21]
FLOPs = 1950.56M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.64 | Loss = 2.0182
Testing Model 545 took 1 mins and 54 secs

Testing Model 546
[14, 14, 16, 22, 21, 22, 13, 19, 16, 22, 19, 20, 22, 12, 26, 22, 20, 17, 21, 21]
FLOPs = 1966.87M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.60 | Loss = 2.0202
Testing Model 546 took 1 mins and 53 secs

Testing Model 547
[20, 14, 16, 22, 21, 22, 13, 19, 16, 22, 19, 20, 22, 12, 26, 22, 15, 17, 22, 21]
FLOPs = 1968.64M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.76 | Loss = 2.0147
Testing Model 547 took 1 mins and 58 secs

Testing Model 548
[14, 22, 21, 22, 20, 10, 20, 21, 16, 22, 19, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 2043.29M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.67 | Loss = 2.0161
Testing Model 548 took 1 mins and 58 secs

Testing Model 549
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 1951.08M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.70 | Loss = 2.0180
Testing Model 549 took 1 mins and 51 secs

Testing Model 550
[20, 22, 16, 22, 21, 22, 13, 19, 16, 22, 19, 20, 22, 9, 26, 22, 20, 17, 20, 21]
FLOPs = 2049.67M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.76 | Loss = 2.0158
Testing Model 550 took 1 mins and 54 secs

> Select
Iteration 10 : Showing Top 50 results
1. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.640439987182617
2. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.595078468322754
3. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.574835777282715
4. [20. 22. 20. 17. 20. 20. 20. 21. 13. 12. 16. 23. 22. 12. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.564648628234863
5. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 18. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.556252479553223
6. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.54874038696289
7. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.539837837219238
8. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.536077499389648
9. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.534582138061523
10. [20. 23. 20. 17. 20. 20. 20. 19. 13. 12. 16. 23. 18. 18. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.531522750854492
11. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22.  9. 26. 22. 15. 21.
 21. 21.] 
Reward = 15.5304536819458
12. [20. 14. 16. 22. 21. 22. 13. 19. 13. 22. 19. 20. 22.  9. 26. 22. 20. 17.
 20. 21.] 
Reward = 15.494070053100586
13. [20. 14. 16. 22. 21. 22. 14. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.489802360534668
14. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.487140655517578
15. [20. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  9. 16. 22. 20. 21.
 21. 21.] 
Reward = 15.483205795288086
16. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
17. [20. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.471687316894531
18. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 19. 15. 17.
 20. 18.] 
Reward = 15.46304988861084
19. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 21.] 
Reward = 15.448393821716309
20. [20. 14. 20. 22. 21. 22. 13. 19. 13. 12. 23. 20. 22. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.44775390625
21. [20. 22. 21. 22. 21. 10. 13. 19. 16. 12. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 20.] 
Reward = 15.444304466247559
22. [14. 14. 16. 22. 21. 22. 21. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.442277908325195
23. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.433782577514648
24. [20. 22. 20. 22. 20. 10. 20. 19. 16. 12. 19. 23. 18. 18. 16. 22. 15. 21.
 20. 20.] 
Reward = 15.431556701660156
25. [20. 22. 21. 22. 20. 10. 13. 19. 16. 12. 19. 23. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.430253028869629
26. [18. 25. 17. 17. 13. 11. 21. 22. 16. 26. 18. 20. 23. 17. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.428112983703613
27. [20. 14. 16. 22. 21. 20. 20. 19. 16. 22. 19. 23. 22.  9. 16. 22. 15. 21.
 21. 21.] 
Reward = 15.423428535461426
28. [19. 23. 20. 17. 20. 20. 21. 15. 16. 22. 23. 20. 18. 18. 13. 18. 23. 17.
 20. 18.] 
Reward = 15.420969009399414
29. [20. 22. 21. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 22. 15. 21.
 21. 20.] 
Reward = 15.418389320373535
30. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.417957305908203
31. [20. 23. 20. 22. 20. 10. 21. 21. 16. 12. 19. 20. 18. 18. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.416579246520996
32. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.416141510009766
33. [20. 23. 20. 17. 20. 20. 20. 19. 16. 12. 23. 20. 18. 18. 16. 22. 20. 17.
 20. 20.] 
Reward = 15.415833473205566
34. [20. 14. 21. 22. 20. 22. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.409370422363281
35. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 22.
 21. 21.] 
Reward = 15.401910781860352
36. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 19. 20. 15. 23.
 18. 20.] 
Reward = 15.400196075439453
37. [14. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 20. 17.
 21. 21.] 
Reward = 15.397753715515137
38. [20. 22. 20. 18. 20. 12. 21. 22. 16. 12. 18. 20. 22. 18. 16. 23. 15. 21.
 23. 18.] 
Reward = 15.392885208129883
39. [20. 23. 20. 22. 20. 20. 13. 19. 16. 12. 16. 20. 18. 18. 16. 22. 20. 17.
 20. 21.] 
Reward = 15.389420509338379
40. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.381397247314453
41. [20. 22. 21. 22. 20. 20. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.377861022949219
42. [20. 22. 21. 18. 20. 12. 23. 22. 16. 22. 19. 20. 22. 18. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.376130104064941
43. [20. 22. 21. 17. 13. 20. 21. 22. 16. 22. 19. 20. 22. 18. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.373248100280762
44. [14. 14. 16. 22. 21.  9. 20. 19. 24. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.370867729187012
45. [20. 22. 20. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 23. 15. 21.
 21. 18.] 
Reward = 15.366320610046387
46. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 28. 22. 15. 17.
 20. 21.] 
Reward = 15.366180419921875
47. [20. 22. 20. 22. 20. 20. 13. 15. 16. 12. 23. 20. 18. 18. 16. 18. 23. 17.
 20. 20.] 
Reward = 15.36349105834961
48. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 23. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.36010456085205
49. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 19. 18. 15. 17.
 20. 18.] 
Reward = 15.356070518493652
50. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 22. 21.] 
Reward = 15.3550386428833
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 10 took 1 hour 36 mins 15 secs



Testing Model 551
[20, 29, 16, 22, 21, 22, 22, 19, 16, 22, 19, 20, 22, 12, 26, 22, 15, 17, 20, 1]
FLOPs = 2044.95M
Top-1 Accuracy = 51.41 | Top-5 Accuracy = 76.02 | Loss = 2.2078
Testing Model 551 took 1 mins and 57 secs

Testing Model 552
[20, 14, 16, 22, 21, 30, 13, 19, 16, 22, 19, 20, 22, 12, 26, 22, 15, 17, 20, 21]
FLOPs = 2016.32M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.78 | Loss = 2.0163
Testing Model 552 took 1 mins and 52 secs

Testing Model 553
[14, 14, 16, 22, 21, 22, 30, 6, 13, 22, 12, 20, 22, 9, 26, 22, 20, 21, 21, 21]
FLOPs = 1969.42M
Top-1 Accuracy = 55.03 | Top-5 Accuracy = 78.53 | Loss = 2.0241
Testing Model 553 took 1 mins and 54 secs

Testing Model 554
[20, 13, 20, 27, 20, 20, 20, 19, 13, 6, 16, 19, 18, 18, 16, 22, 20, 21, 20, 21]
FLOPs = 1970.55M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.77 | Loss = 2.0146
Testing Model 554 took 1 mins and 56 secs

Testing Model 555
[30, 14, 16, 28, 7, 22, 20, 29, 22, 22, 16, 1, 22, 15, 26, 18, 15, 21, 20, 9]
FLOPs = 2012.66M
Top-1 Accuracy = 53.45 | Top-5 Accuracy = 77.48 | Loss = 2.0961
Testing Model 555 took 1 mins and 56 secs

Testing Model 556
[3, 14, 16, 22, 21, 22, 29, 19, 13, 22, 16, 20, 22, 9, 26, 22, 20, 21, 21, 21]
FLOPs = 2006.54M
Top-1 Accuracy = 54.10 | Top-5 Accuracy = 77.91 | Loss = 2.0709
Testing Model 556 took 1 mins and 56 secs

Testing Model 557
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 18, 22, 12, 26, 18, 15, 21, 22, 28]
FLOPs = 2014.05M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.72 | Loss = 2.0188
Testing Model 557 took 1 mins and 54 secs

Testing Model 558
[20, 14, 16, 22, 21, 22, 13, 19, 16, 22, 22, 20, 22, 12, 26, 22, 15, 17, 20, 21]
FLOPs = 1973.22M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.78 | Loss = 2.0161
Testing Model 558 took 1 mins and 53 secs

Testing Model 559
[20, 14, 16, 22, 21, 22, 13, 29, 16, 22, 19, 20, 22, 12, 19, 22, 15, 17, 20, 21]
FLOPs = 1981.10M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.77 | Loss = 2.0127
Testing Model 559 took 1 mins and 55 secs

Testing Model 560
[25, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 2002.71M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.76 | Loss = 2.0145
Testing Model 560 took 1 mins and 56 secs

Testing Model 561
[14, 25, 16, 22, 21, 22, 2, 19, 16, 22, 18, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 1976.49M
Top-1 Accuracy = 55.01 | Top-5 Accuracy = 78.69 | Loss = 2.0173
Testing Model 561 took 1 mins and 56 secs

Testing Model 562
[14, 14, 22, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 2030.59M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.77 | Loss = 2.0172
Testing Model 562 took 1 mins and 54 secs

Testing Model 563
[20, 22, 21, 22, 20, 12, 13, 21, 16, 12, 19, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1974.30M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.78 | Loss = 2.0131
Testing Model 563 took 1 mins and 56 secs

Testing Model 564
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 5, 23, 22, 8, 26, 15, 27, 21, 21, 21]
FLOPs = 1964.32M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.54 | Loss = 2.0243
Testing Model 564 took 1 mins and 54 secs

Testing Model 565
[14, 14, 16, 22, 21, 22, 13, 19, 13, 22, 16, 21, 22, 9, 26, 22, 20, 21, 21, 21]
FLOPs = 1957.77M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.66 | Loss = 2.0179
Testing Model 565 took 1 mins and 55 secs

Testing Model 566
[20, 14, 5, 30, 21, 22, 13, 19, 16, 22, 19, 20, 22, 12, 26, 28, 15, 17, 20, 21]
FLOPs = 1998.44M
Top-1 Accuracy = 54.92 | Top-5 Accuracy = 78.52 | Loss = 2.0278
Testing Model 566 took 1 mins and 52 secs

Testing Model 567
[17, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 1965.83M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.67 | Loss = 2.0159
Testing Model 567 took 1 mins and 55 secs

Testing Model 568
[14, 14, 16, 22, 21, 22, 12, 30, 13, 22, 16, 28, 22, 8, 21, 15, 20, 21, 21, 21]
FLOPs = 2014.11M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.65 | Loss = 2.0178
Testing Model 568 took 1 mins and 52 secs

Testing Model 569
[20, 14, 16, 22, 21, 22, 13, 23, 16, 22, 19, 20, 22, 12, 26, 22, 15, 17, 20, 21]
FLOPs = 1983.71M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.78 | Loss = 2.0148
Testing Model 569 took 1 mins and 56 secs

Testing Model 570
[20, 22, 21, 22, 25, 10, 13, 21, 16, 12, 19, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1998.54M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.79 | Loss = 2.0144
Testing Model 570 took 2 mins and 0 secs

Testing Model 571
[20, 23, 20, 17, 20, 20, 20, 19, 13, 18, 16, 23, 5, 18, 16, 22, 29, 21, 20, 21]
FLOPs = 1991.87M
Top-1 Accuracy = 54.91 | Top-5 Accuracy = 78.62 | Loss = 2.0188
Testing Model 571 took 1 mins and 58 secs

Testing Model 572
[20, 23, 20, 17, 20, 20, 20, 19, 13, 12, 16, 23, 20, 18, 16, 22, 20, 21, 20, 21]
FLOPs = 1964.94M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.77 | Loss = 2.0112
Testing Model 572 took 1 mins and 52 secs

Testing Model 573
[20, 23, 20, 17, 30, 20, 20, 17, 13, 12, 16, 23, 18, 18, 16, 22, 20, 21, 20, 21]
FLOPs = 2013.50M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.76 | Loss = 2.0119
Testing Model 573 took 1 mins and 55 secs

Testing Model 574
[14, 14, 16, 22, 21, 21, 20, 19, 14, 22, 18, 23, 22, 8, 26, 19, 20, 21, 21, 21]
FLOPs = 1996.62M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.61 | Loss = 2.0178
Testing Model 574 took 1 mins and 56 secs

Testing Model 575
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 19, 20, 22, 22, 14, 22, 15, 17, 21, 20]
FLOPs = 1951.26M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.74 | Loss = 2.0134
Testing Model 575 took 1 mins and 58 secs

Testing Model 576
[20, 22, 21, 22, 21, 10, 20, 21, 16, 12, 16, 23, 22, 22, 16, 15, 20, 17, 21, 20]
FLOPs = 2005.86M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.73 | Loss = 2.0132
Testing Model 576 took 2 mins and 0 secs

Testing Model 577
[20, 22, 20, 17, 20, 20, 20, 21, 13, 22, 23, 23, 22, 12, 16, 18, 15, 21, 20, 18]
FLOPs = 1981.69M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.70 | Loss = 2.0153
Testing Model 577 took 1 mins and 57 secs

Testing Model 578
[20, 22, 20, 22, 20, 10, 20, 19, 13, 12, 19, 23, 22, 18, 16, 22, 20, 21, 20, 21]
FLOPs = 2022.51M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.80 | Loss = 2.0097
Testing Model 578 took 1 mins and 58 secs

Testing Model 579
[20, 23, 16, 22, 20, 20, 20, 19, 13, 22, 16, 20, 22, 12, 26, 22, 15, 17, 20, 21]
FLOPs = 2029.18M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.74 | Loss = 2.0142
Testing Model 579 took 1 mins and 54 secs

Testing Model 580
[14, 22, 20, 22, 21, 20, 13, 19, 13, 22, 16, 20, 22, 9, 26, 22, 15, 21, 20, 21]
FLOPs = 2025.43M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.77 | Loss = 2.0147
Testing Model 580 took 1 mins and 59 secs

Testing Model 581
[14, 22, 16, 22, 21, 22, 13, 19, 16, 22, 19, 20, 22, 9, 16, 22, 20, 17, 21, 21]
FLOPs = 1954.16M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.68 | Loss = 2.0169
Testing Model 581 took 1 mins and 58 secs

Testing Model 582
[20, 22, 16, 17, 21, 20, 21, 21, 16, 22, 23, 20, 22, 12, 26, 18, 15, 17, 20, 18]
FLOPs = 1969.75M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.68 | Loss = 2.0196
Testing Model 582 took 1 mins and 59 secs

Testing Model 583
[20, 14, 16, 22, 21, 22, 13, 19, 16, 22, 19, 20, 22, 12, 26, 22, 15, 21, 21, 21]
FLOPs = 1993.93M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.82 | Loss = 2.0144
Testing Model 583 took 1 mins and 58 secs

Testing Model 584
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 1975.43M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.71 | Loss = 2.0175
Testing Model 584 took 1 mins and 56 secs

Testing Model 585
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 26, 18, 20, 21, 20, 21]
FLOPs = 1967.83M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.69 | Loss = 2.0155
Testing Model 585 took 1 mins and 53 secs

Testing Model 586
[20, 14, 20, 17, 20, 20, 13, 19, 13, 22, 16, 23, 22, 18, 26, 22, 20, 21, 20, 21]
FLOPs = 1977.79M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.79 | Loss = 2.0119
Testing Model 586 took 1 mins and 55 secs

Testing Model 587
[20, 22, 21, 22, 20, 10, 13, 21, 13, 12, 19, 23, 22, 22, 16, 22, 20, 21, 20, 21]
FLOPs = 2038.20M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.80 | Loss = 2.0100
Testing Model 587 took 1 mins and 56 secs

Testing Model 588
[20, 14, 16, 22, 21, 22, 13, 19, 16, 22, 16, 20, 22, 12, 26, 22, 15, 21, 20, 21]
FLOPs = 1968.60M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.72 | Loss = 2.0131
Testing Model 588 took 1 mins and 53 secs

Testing Model 589
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 22, 20, 21, 21, 21]
FLOPs = 2021.80M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.66 | Loss = 2.0165
Testing Model 589 took 1 mins and 56 secs

Testing Model 590
[20, 14, 16, 22, 21, 22, 13, 19, 16, 22, 19, 18, 22, 12, 26, 22, 15, 21, 22, 21]
FLOPs = 1986.68M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.78 | Loss = 2.0141
Testing Model 590 took 1 mins and 54 secs

Testing Model 591
[20, 22, 21, 17, 20, 20, 21, 21, 16, 22, 19, 20, 22, 22, 16, 22, 15, 17, 20, 20]
FLOPs = 2037.97M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.70 | Loss = 2.0142
Testing Model 591 took 1 mins and 57 secs

Testing Model 592
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 16, 20, 22, 12, 16, 22, 20, 21, 20, 21]
FLOPs = 2016.25M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.78 | Loss = 2.0132
Testing Model 592 took 1 mins and 55 secs

Testing Model 593
[20, 22, 20, 17, 20, 20, 21, 21, 13, 22, 23, 20, 22, 12, 16, 22, 20, 17, 20, 18]
FLOPs = 1991.06M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.70 | Loss = 2.0188
Testing Model 593 took 1 mins and 57 secs

Testing Model 594
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 18, 16, 22, 20, 21, 20, 21]
FLOPs = 1983.75M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.69 | Loss = 2.0163
Testing Model 594 took 1 mins and 57 secs

Testing Model 595
[14, 14, 16, 22, 20, 22, 20, 21, 13, 22, 16, 23, 22, 12, 16, 22, 20, 21, 20, 21]
FLOPs = 1956.12M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.73 | Loss = 2.0173
Testing Model 595 took 1 mins and 53 secs

Testing Model 596
[14, 14, 16, 22, 21, 10, 20, 21, 16, 12, 19, 20, 22, 22, 26, 22, 15, 21, 21, 21]
FLOPs = 1958.76M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.64 | Loss = 2.0166
Testing Model 596 took 1 mins and 54 secs

Testing Model 597
[20, 22, 21, 22, 20, 10, 20, 19, 16, 22, 19, 20, 22, 22, 16, 18, 15, 17, 20, 21]
FLOPs = 2026.05M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.79 | Loss = 2.0126
Testing Model 597 took 1 mins and 55 secs

Testing Model 598
[14, 22, 20, 17, 20, 20, 20, 21, 16, 22, 23, 20, 22, 12, 26, 18, 15, 17, 22, 21]
FLOPs = 2023.52M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.73 | Loss = 2.0153
Testing Model 598 took 1 mins and 55 secs

Testing Model 599
[20, 14, 16, 22, 21, 22, 13, 19, 16, 22, 19, 20, 22, 9, 26, 22, 15, 21, 21, 21]
FLOPs = 1978.33M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.74 | Loss = 2.0129
Testing Model 599 took 1 mins and 56 secs

Testing Model 600
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 9, 26, 22, 20, 21, 21, 21]
FLOPs = 1989.08M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.69 | Loss = 2.0159
Testing Model 600 took 1 mins and 54 secs

> Select
Iteration 11 : Showing Top 50 results
1. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.640439987182617
2. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.595078468322754
3. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.574835777282715
4. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 21. 20.] 
Reward = 15.564767837524414
5. [20. 22. 20. 17. 20. 20. 20. 21. 13. 12. 16. 23. 22. 12. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.564648628234863
6. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 18. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.556252479553223
7. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.54874038696289
8. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.539837837219238
9. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.536077499389648
10. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.534582138061523
11. [20. 23. 20. 17. 20. 20. 20. 19. 13. 12. 16. 23. 18. 18. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.531522750854492
12. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22.  9. 26. 22. 15. 21.
 21. 21.] 
Reward = 15.5304536819458
13. [20. 14. 16. 22. 21. 22. 13. 19. 13. 22. 19. 20. 22.  9. 26. 22. 20. 17.
 20. 21.] 
Reward = 15.494070053100586
14. [20. 14. 16. 22. 21. 22. 14. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.489802360534668
15. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.487140655517578
16. [20. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  9. 16. 22. 20. 21.
 21. 21.] 
Reward = 15.483205795288086
17. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
18. [20. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.471687316894531
19. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 21. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.470913887023926
20. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 19. 15. 17.
 20. 18.] 
Reward = 15.46304988861084
21. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 26. 18. 20. 21.
 20. 21.] 
Reward = 15.45567512512207
22. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 21.] 
Reward = 15.448393821716309
23. [20. 14. 20. 22. 21. 22. 13. 19. 13. 12. 23. 20. 22. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.44775390625
24. [20. 22. 21. 22. 21. 10. 13. 19. 16. 12. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 20.] 
Reward = 15.444304466247559
25. [14. 14. 16. 22. 21. 22. 21. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.442277908325195
26. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.433782577514648
27. [20. 22. 20. 22. 20. 10. 20. 19. 16. 12. 19. 23. 18. 18. 16. 22. 15. 21.
 20. 20.] 
Reward = 15.431556701660156
28. [20. 22. 21. 22. 20. 10. 13. 19. 16. 12. 19. 23. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.430253028869629
29. [14. 14. 16. 22. 20. 22. 20. 21. 13. 22. 16. 23. 22. 12. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.428466796875
30. [18. 25. 17. 17. 13. 11. 21. 22. 16. 26. 18. 20. 23. 17. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.428112983703613
31. [20. 14. 16. 22. 21. 20. 20. 19. 16. 22. 19. 23. 22.  9. 16. 22. 15. 21.
 21. 21.] 
Reward = 15.423428535461426
32. [14. 22. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22.  9. 16. 22. 20. 17.
 21. 21.] 
Reward = 15.421411514282227
33. [19. 23. 20. 17. 20. 20. 21. 15. 16. 22. 23. 20. 18. 18. 13. 18. 23. 17.
 20. 18.] 
Reward = 15.420969009399414
34. [20. 22. 21. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 22. 15. 21.
 21. 20.] 
Reward = 15.418389320373535
35. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.417957305908203
36. [20. 23. 20. 22. 20. 10. 21. 21. 16. 12. 19. 20. 18. 18. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.416579246520996
37. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.416141510009766
38. [20. 23. 20. 17. 20. 20. 20. 19. 16. 12. 23. 20. 18. 18. 16. 22. 20. 17.
 20. 20.] 
Reward = 15.415833473205566
39. [20. 14. 21. 22. 20. 22. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.409370422363281
40. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 22.
 21. 21.] 
Reward = 15.401910781860352
41. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 19. 20. 15. 23.
 18. 20.] 
Reward = 15.400196075439453
42. [14. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 20. 17.
 21. 21.] 
Reward = 15.397753715515137
43. [20. 22. 20. 18. 20. 12. 21. 22. 16. 12. 18. 20. 22. 18. 16. 23. 15. 21.
 23. 18.] 
Reward = 15.392885208129883
44. [20. 23. 20. 22. 20. 20. 13. 19. 16. 12. 16. 20. 18. 18. 16. 22. 20. 17.
 20. 21.] 
Reward = 15.389420509338379
45. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.381397247314453
46. [20. 22. 21. 22. 20. 12. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.378522872924805
47. [20. 22. 21. 22. 20. 20. 13. 22. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.377861022949219
48. [20. 22. 21. 18. 20. 12. 23. 22. 16. 22. 19. 20. 22. 18. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.376130104064941
49. [20. 22. 21. 17. 13. 20. 21. 22. 16. 22. 19. 20. 22. 18. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.373248100280762
50. [14. 14. 16. 22. 21.  9. 20. 19. 24. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.370867729187012
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 11 took 1 hour 36 mins 56 secs



Testing Model 601
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 17, 25, 20, 21, 21, 21]
FLOPs = 1965.29M
Top-1 Accuracy = 55.26 | Top-5 Accuracy = 78.64 | Loss = 2.0171
Testing Model 601 took 1 mins and 54 secs

Testing Model 602
[20, 22, 20, 17, 30, 20, 21, 21, 16, 22, 23, 20, 22, 12, 16, 18, 15, 17, 20, 18]
FLOPs = 2026.85M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.66 | Loss = 2.0199
Testing Model 602 took 1 mins and 54 secs

Testing Model 603
[14, 14, 16, 22, 21, 22, 13, 19, 13, 22, 16, 26, 22, 9, 26, 22, 20, 21, 21, 21]
FLOPs = 2001.12M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.68 | Loss = 2.0163
Testing Model 603 took 1 mins and 56 secs

Testing Model 604
[14, 14, 15, 22, 21, 22, 13, 19, 13, 22, 0, 20, 22, 9, 26, 22, 20, 30, 21, 29]
FLOPs = 2034.19M
Top-1 Accuracy = 54.87 | Top-5 Accuracy = 78.39 | Loss = 2.0387
Testing Model 604 took 1 mins and 55 secs

Testing Model 605
[20, 22, 20, 20, 20, 20, 21, 21, 16, 22, 23, 20, 22, 12, 16, 18, 15, 17, 20, 18]
FLOPs = 2002.96M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.69 | Loss = 2.0160
Testing Model 605 took 1 mins and 58 secs

Testing Model 606
[26, 22, 20, 17, 20, 20, 20, 21, 13, 12, 16, 23, 22, 12, 16, 22, 20, 21, 20, 27]
FLOPs = 2034.73M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.80 | Loss = 2.0103
Testing Model 606 took 1 mins and 56 secs

Testing Model 607
[14, 14, 16, 22, 21, 22, 20, 19, 16, 11, 16, 20, 22, 22, 26, 18, 15, 21, 21, 21]
FLOPs = 1960.04M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.62 | Loss = 2.0191
Testing Model 607 took 1 mins and 55 secs

Testing Model 608
[14, 14, 16, 22, 21, 22, 24, 19, 16, 22, 16, 20, 22, 19, 26, 18, 15, 21, 21, 21]
FLOPs = 2031.32M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.74 | Loss = 2.0170
Testing Model 608 took 1 mins and 55 secs

Testing Model 609
[20, 22, 20, 17, 22, 20, 21, 22, 16, 22, 23, 20, 22, 12, 13, 18, 15, 17, 20, 18]
FLOPs = 1956.36M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.64 | Loss = 2.0190
Testing Model 609 took 1 mins and 55 secs

Testing Model 610
[20, 22, 20, 17, 20, 20, 15, 21, 13, 12, 27, 23, 22, 12, 16, 22, 20, 21, 20, 21]
FLOPs = 1999.41M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.77 | Loss = 2.0118
Testing Model 610 took 1 mins and 54 secs

Testing Model 611
[20, 22, 20, 17, 20, 20, 20, 21, 13, 12, 16, 23, 22, 10, 20, 22, 20, 21, 20, 21]
FLOPs = 1966.54M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.74 | Loss = 2.0122
Testing Model 611 took 1 mins and 56 secs

Testing Model 612
[14, 14, 16, 22, 21, 22, 20, 28, 13, 22, 16, 23, 22, 8, 26, 15, 20, 21, 21, 21]
FLOPs = 2034.35M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.65 | Loss = 2.0186
Testing Model 612 took 1 mins and 54 secs

Testing Model 613
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 30, 12, 16, 18, 15, 17, 20, 18]
FLOPs = 2015.13M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.67 | Loss = 2.0174
Testing Model 613 took 1 mins and 57 secs

Testing Model 614
[20, 21, 21, 22, 20, 10, 13, 21, 16, 12, 19, 20, 22, 22, 14, 22, 11, 17, 21, 25]
FLOPs = 1961.39M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.69 | Loss = 2.0162
Testing Model 614 took 1 mins and 55 secs

Testing Model 615
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 19, 20, 24, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1978.54M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.74 | Loss = 2.0125
Testing Model 615 took 1 mins and 58 secs

Testing Model 616
[8, 19, 16, 22, 21, 23, 20, 19, 16, 22, 16, 18, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 1979.57M
Top-1 Accuracy = 54.72 | Top-5 Accuracy = 78.46 | Loss = 2.0367
Testing Model 616 took 2 mins and 0 secs

Testing Model 617
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 24, 15, 21, 20, 21]
FLOPs = 1995.33M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.70 | Loss = 2.0181
Testing Model 617 took 1 mins and 56 secs

Testing Model 618
[20, 25, 20, 17, 10, 20, 25, 21, 16, 22, 23, 20, 22, 12, 16, 18, 15, 17, 20, 18]
FLOPs = 1964.48M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.58 | Loss = 2.0202
Testing Model 618 took 1 mins and 56 secs

Testing Model 619
[14, 14, 17, 22, 21, 22, 13, 19, 13, 22, 16, 20, 22, 17, 26, 22, 20, 21, 21, 21]
FLOPs = 2010.23M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.69 | Loss = 2.0164
Testing Model 619 took 1 mins and 54 secs

Testing Model 620
[20, 22, 21, 22, 20, 15, 13, 21, 14, 12, 19, 20, 22, 22, 14, 26, 15, 17, 21, 20]
FLOPs = 2000.28M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.73 | Loss = 2.0152
Testing Model 620 took 1 mins and 56 secs

Testing Model 621
[22, 14, 16, 22, 20, 22, 20, 19, 13, 22, 16, 23, 18, 8, 26, 15, 20, 21, 21, 21]
FLOPs = 1962.37M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.65 | Loss = 2.0169
Testing Model 621 took 1 mins and 53 secs

Testing Model 622
[14, 14, 9, 22, 21, 22, 20, 19, 16, 26, 16, 20, 22, 12, 26, 18, 15, 21, 21, 28]
FLOPs = 1956.43M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.69 | Loss = 2.0212
Testing Model 622 took 1 mins and 54 secs

Testing Model 623
[14, 14, 16, 22, 29, 22, 20, 19, 13, 22, 16, 23, 22, 8, 26, 15, 20, 21, 21, 21]
FLOPs = 2018.03M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.58 | Loss = 2.0193
Testing Model 623 took 1 mins and 55 secs

Testing Model 624
[14, 14, 16, 22, 21, 22, 24, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 21, 21]
FLOPs = 1987.38M
Top-1 Accuracy = 55.26 | Top-5 Accuracy = 78.71 | Loss = 2.0176
Testing Model 624 took 1 mins and 58 secs

Testing Model 625
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 18, 20, 7, 26, 18, 15, 28, 22, 21]
FLOPs = 1980.50M
Top-1 Accuracy = 55.03 | Top-5 Accuracy = 78.66 | Loss = 2.0190
Testing Model 625 took 1 mins and 55 secs

Testing Model 626
[20, 14, 16, 22, 21, 22, 20, 19, 16, 22, 19, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 1995.60M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.72 | Loss = 2.0148
Testing Model 626 took 1 mins and 55 secs

Testing Model 627
[20, 14, 16, 22, 21, 10, 13, 21, 16, 22, 19, 20, 22, 22, 26, 22, 15, 17, 21, 21]
FLOPs = 1974.27M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.72 | Loss = 2.0138
Testing Model 627 took 1 mins and 58 secs

Testing Model 628
[20, 22, 21, 17, 20, 20, 21, 21, 16, 12, 23, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 2010.64M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.80 | Loss = 2.0122
Testing Model 628 took 1 mins and 55 secs

Testing Model 629
[20, 22, 20, 22, 20, 10, 20, 21, 16, 12, 19, 20, 22, 12, 16, 22, 20, 17, 20, 20]
FLOPs = 1954.04M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.72 | Loss = 2.0122
Testing Model 629 took 1 mins and 58 secs

Testing Model 630
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 12, 26, 18, 20, 21, 21, 21]
FLOPs = 2017.15M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.70 | Loss = 2.0184
Testing Model 630 took 1 mins and 58 secs

Testing Model 631
[20, 22, 16, 22, 21, 22, 13, 19, 16, 12, 19, 20, 22, 22, 26, 22, 15, 17, 21, 21]
FLOPs = 2044.15M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.75 | Loss = 2.0146
Testing Model 631 took 1 mins and 59 secs

Testing Model 632
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 8, 26, 22, 20, 21, 21, 21]
FLOPs = 1984.71M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.68 | Loss = 2.0178
Testing Model 632 took 1 mins and 53 secs

Testing Model 633
[20, 22, 21, 17, 20, 10, 21, 21, 16, 22, 19, 20, 22, 22, 16, 22, 15, 17, 21, 18]
FLOPs = 1969.87M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.63 | Loss = 2.0155
Testing Model 633 took 1 mins and 56 secs

Testing Model 634
[20, 14, 16, 22, 21, 22, 20, 19, 16, 22, 19, 20, 22, 12, 26, 22, 15, 17, 20, 21]
FLOPs = 1990.72M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.77 | Loss = 2.0167
Testing Model 634 took 1 mins and 55 secs

Testing Model 635
[14, 22, 16, 22, 20, 20, 20, 21, 13, 22, 16, 23, 22, 12, 26, 18, 15, 17, 20, 18]
FLOPs = 1978.05M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.62 | Loss = 2.0198
Testing Model 635 took 1 mins and 56 secs

Testing Model 636
[20, 22, 21, 17, 20, 20, 20, 21, 13, 12, 16, 23, 22, 12, 16, 22, 20, 21, 21, 20]
FLOPs = 1962.78M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.82 | Loss = 2.0112
Testing Model 636 took 1 mins and 56 secs

Testing Model 637
[14, 14, 20, 22, 20, 22, 20, 21, 13, 22, 16, 18, 22, 12, 26, 22, 15, 21, 22, 21]
FLOPs = 2024.17M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.71 | Loss = 2.0145
Testing Model 637 took 1 mins and 58 secs

Testing Model 638
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 16, 18, 22, 12, 26, 22, 15, 21, 21, 20]
FLOPs = 1969.98M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.77 | Loss = 2.0105
Testing Model 638 took 2 mins and 0 secs

Testing Model 639
[20, 14, 20, 22, 20, 22, 20, 21, 13, 22, 16, 23, 22, 12, 16, 22, 20, 21, 20, 21]
FLOPs = 2036.45M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.75 | Loss = 2.0138
Testing Model 639 took 1 mins and 56 secs

Testing Model 640
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 16, 20, 22, 12, 16, 22, 15, 21, 20, 18]
FLOPs = 1961.29M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.68 | Loss = 2.0168
Testing Model 640 took 1 mins and 58 secs

Testing Model 641
[20, 14, 16, 22, 21, 22, 20, 19, 16, 22, 19, 20, 22, 12, 26, 22, 15, 17, 21, 21]
FLOPs = 1998.57M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.79 | Loss = 2.0153
Testing Model 641 took 1 mins and 57 secs

Testing Model 642
[14, 22, 21, 22, 21, 22, 13, 21, 16, 12, 16, 20, 22, 12, 26, 22, 15, 21, 21, 21]
FLOPs = 2047.74M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.77 | Loss = 2.0128
Testing Model 642 took 2 mins and 0 secs

Testing Model 643
[20, 22, 20, 17, 20, 20, 20, 21, 16, 12, 23, 23, 22, 12, 16, 18, 20, 21, 20, 18]
FLOPs = 1966.82M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.70 | Loss = 2.0159
Testing Model 643 took 1 mins and 55 secs

Testing Model 644
[20, 14, 21, 22, 21, 22, 13, 21, 13, 12, 19, 20, 22, 22, 16, 22, 20, 21, 21, 21]
FLOPs = 2018.17M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.80 | Loss = 2.0105
Testing Model 644 took 1 mins and 57 secs

Testing Model 645
[20, 22, 16, 22, 20, 10, 20, 21, 16, 22, 19, 20, 22, 12, 26, 18, 15, 21, 21, 21]
FLOPs = 2022.20M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.80 | Loss = 2.0110
Testing Model 645 took 1 mins and 56 secs

Testing Model 646
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 19, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 1968.56M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.70 | Loss = 2.0173
Testing Model 646 took 1 mins and 55 secs

Testing Model 647
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 19, 20, 22, 12, 26, 22, 15, 17, 21, 21]
FLOPs = 1971.53M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.63 | Loss = 2.0182
Testing Model 647 took 1 mins and 55 secs

Testing Model 648
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 12, 26, 18, 15, 21, 21, 21]
FLOPs = 1983.27M
Top-1 Accuracy = 55.24 | Top-5 Accuracy = 78.69 | Loss = 2.0175
Testing Model 648 took 1 mins and 55 secs

Testing Model 649
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 18, 22, 12, 26, 18, 20, 21, 21, 21]
FLOPs = 1959.84M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.69 | Loss = 2.0185
Testing Model 649 took 2 mins and 0 secs

Testing Model 650
[20, 22, 16, 22, 21, 20, 21, 19, 16, 22, 19, 20, 22, 12, 26, 18, 15, 17, 20, 21]
FLOPs = 2038.13M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.78 | Loss = 2.0141
Testing Model 650 took 1 mins and 58 secs

> Select
Iteration 12 : Showing Top 50 results
1. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.640439987182617
2. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.595078468322754
3. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.574835777282715
4. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 17. 25. 20. 21.
 21. 21.] 
Reward = 15.56768798828125
5. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 21. 20.] 
Reward = 15.564767837524414
6. [20. 22. 20. 17. 20. 20. 20. 21. 13. 12. 16. 23. 22. 12. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.564648628234863
7. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 18. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.556252479553223
8. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.54874038696289
9. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.539837837219238
10. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.536077499389648
11. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.534582138061523
12. [20. 23. 20. 17. 20. 20. 20. 19. 13. 12. 16. 23. 18. 18. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.531522750854492
13. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22.  9. 26. 22. 15. 21.
 21. 21.] 
Reward = 15.5304536819458
14. [20. 22. 20. 22. 20. 10. 20. 21. 16. 12. 19. 20. 22. 12. 16. 22. 20. 17.
 20. 20.] 
Reward = 15.51479721069336
15. [14. 14. 16. 22. 21. 22. 20. 19. 16. 11. 16. 20. 22. 22. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.506855010986328
16. [20. 14. 16. 22. 21. 22. 13. 19. 13. 22. 19. 20. 22.  9. 26. 22. 20. 17.
 20. 21.] 
Reward = 15.494070053100586
17. [20. 14. 16. 22. 21. 22. 14. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.489802360534668
18. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.487140655517578
19. [20. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  9. 16. 22. 20. 21.
 21. 21.] 
Reward = 15.483205795288086
20. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
21. [20. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.471687316894531
22. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 21. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.470913887023926
23. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 19. 15. 17.
 20. 18.] 
Reward = 15.46304988861084
24. [20. 22. 20. 17. 22. 20. 21. 22. 16. 22. 23. 20. 22. 12. 13. 18. 15. 17.
 20. 18.] 
Reward = 15.457979202270508
25. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 26. 18. 20. 21.
 20. 21.] 
Reward = 15.45567512512207
26. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 21.] 
Reward = 15.448393821716309
27. [20. 14. 20. 22. 21. 22. 13. 19. 13. 12. 23. 20. 22. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.44775390625
28. [20. 22. 21. 22. 21. 10. 13. 19. 16. 12. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 20.] 
Reward = 15.444304466247559
29. [14. 14. 16. 22. 21. 22. 21. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.442277908325195
30. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.433782577514648
31. [20. 22. 20. 22. 20. 10. 20. 19. 16. 12. 19. 23. 18. 18. 16. 22. 15. 21.
 20. 20.] 
Reward = 15.431556701660156
32. [20. 22. 21. 22. 20. 10. 13. 19. 16. 12. 19. 23. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.430253028869629
33. [14. 14. 16. 22. 20. 22. 20. 21. 13. 22. 16. 23. 22. 12. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.428466796875
34. [18. 25. 17. 17. 13. 11. 21. 22. 16. 26. 18. 20. 23. 17. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.428112983703613
35. [20. 14. 16. 22. 21. 20. 20. 19. 16. 22. 19. 23. 22.  9. 16. 22. 15. 21.
 21. 21.] 
Reward = 15.423428535461426
36. [14. 22. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22.  9. 16. 22. 20. 17.
 21. 21.] 
Reward = 15.421411514282227
37. [19. 23. 20. 17. 20. 20. 21. 15. 16. 22. 23. 20. 18. 18. 13. 18. 23. 17.
 20. 18.] 
Reward = 15.420969009399414
38. [20. 22. 21. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 22. 15. 21.
 21. 20.] 
Reward = 15.418389320373535
39. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.417957305908203
40. [20. 23. 20. 22. 20. 10. 21. 21. 16. 12. 19. 20. 18. 18. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.416579246520996
41. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.416141510009766
42. [20. 23. 20. 17. 20. 20. 20. 19. 16. 12. 23. 20. 18. 18. 16. 22. 20. 17.
 20. 20.] 
Reward = 15.415833473205566
43. [20. 14. 21. 22. 20. 22. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.409370422363281
44. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 22.
 21. 21.] 
Reward = 15.401910781860352
45. [14. 14.  9. 22. 21. 22. 20. 19. 16. 26. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 28.] 
Reward = 15.40127182006836
46. [18. 20. 17. 17. 13. 22. 21. 22. 16. 22. 18. 20. 23. 18. 19. 20. 15. 23.
 18. 20.] 
Reward = 15.400196075439453
47. [14. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 20. 17.
 21. 21.] 
Reward = 15.397753715515137
48. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 19. 20. 22. 12. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.395768165588379
49. [20. 22. 20. 18. 20. 12. 21. 22. 16. 12. 18. 20. 22. 18. 16. 23. 15. 21.
 23. 18.] 
Reward = 15.392885208129883
50. [20. 23. 20. 22. 20. 20. 13. 19. 16. 12. 16. 20. 18. 18. 16. 22. 20. 17.
 20. 21.] 
Reward = 15.389420509338379
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 12 took 1 hour 37 mins 30 secs



Testing Model 651
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 18, 22, 12, 26, 18, 15, 21, 22, 24]
FLOPs = 1976.99M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.76 | Loss = 2.0157
Testing Model 651 took 1 mins and 55 secs

Testing Model 652
[20, 22, 21, 22, 20, 10, 19, 21, 16, 12, 19, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1999.47M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.78 | Loss = 2.0116
Testing Model 652 took 1 mins and 55 secs

Testing Model 653
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 28, 21]
FLOPs = 2021.30M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.72 | Loss = 2.0161
Testing Model 653 took 1 mins and 57 secs

Testing Model 654
[20, 22, 21, 22, 20, 9, 13, 21, 16, 21, 19, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 2015.99M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.73 | Loss = 2.0143
Testing Model 654 took 1 mins and 56 secs

Testing Model 655
[14, 14, 16, 22, 21, 22, 13, 19, 13, 22, 16, 20, 22, 9, 29, 22, 20, 21, 21, 21]
FLOPs = 1976.78M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.66 | Loss = 2.0165
Testing Model 655 took 1 mins and 53 secs

Testing Model 656
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 18, 29, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 2010.30M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.67 | Loss = 2.0146
Testing Model 656 took 1 mins and 52 secs

Testing Model 657
[14, 19, 16, 22, 21, 22, 20, 19, 16, 22, 29, 20, 22, 12, 22, 1, 15, 21, 20, 21]
FLOPs = 1978.33M
Top-1 Accuracy = 54.57 | Top-5 Accuracy = 78.12 | Loss = 2.0500
Testing Model 657 took 1 mins and 53 secs

Testing Model 658
[12, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 8, 25, 27, 21, 21, 21]
FLOPs = 1959.41M
Top-1 Accuracy = 55.01 | Top-5 Accuracy = 78.57 | Loss = 2.0247
Testing Model 658 took 1 mins and 57 secs

Testing Model 659
[14, 14, 16, 22, 21, 22, 20, 29, 16, 22, 16, 20, 22, 12, 18, 18, 15, 21, 20, 21]
FLOPs = 1972.82M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.65 | Loss = 2.0169
Testing Model 659 took 1 mins and 55 secs

Testing Model 660
[20, 22, 21, 22, 20, 10, 13, 25, 16, 12, 19, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1998.19M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.78 | Loss = 2.0121
Testing Model 660 took 1 mins and 59 secs

Testing Model 661
[20, 22, 20, 17, 20, 20, 25, 21, 13, 12, 16, 25, 22, 2, 16, 22, 20, 21, 20, 23]
FLOPs = 1984.27M
Top-1 Accuracy = 54.94 | Top-5 Accuracy = 78.63 | Loss = 2.0185
Testing Model 661 took 1 mins and 57 secs

Testing Model 662
[20, 22, 20, 17, 20, 20, 28, 21, 13, 12, 16, 23, 22, 12, 16, 22, 20, 21, 20, 21]
FLOPs = 2017.16M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.79 | Loss = 2.0109
Testing Model 662 took 1 mins and 57 secs

Testing Model 663
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 18, 22, 12, 26, 25, 15, 21, 22, 21]
FLOPs = 2004.39M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.65 | Loss = 2.0179
Testing Model 663 took 1 mins and 55 secs

Testing Model 664
[20, 22, 28, 17, 20, 20, 21, 21, 16, 13, 23, 20, 22, 12, 10, 25, 15, 17, 20, 18]
FLOPs = 2016.11M
Top-1 Accuracy = 54.97 | Top-5 Accuracy = 78.64 | Loss = 2.0210
Testing Model 664 took 1 mins and 58 secs

Testing Model 665
[5, 14, 16, 22, 21, 22, 13, 19, 13, 22, 16, 20, 22, 6, 26, 22, 20, 21, 30, 21]
FLOPs = 1977.21M
Top-1 Accuracy = 54.58 | Top-5 Accuracy = 78.19 | Loss = 2.0443
Testing Model 665 took 1 mins and 55 secs

Testing Model 666
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 23, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1993.69M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.71 | Loss = 2.0149
Testing Model 666 took 2 mins and 0 secs

Testing Model 667
[20, 22, 21, 22, 20, 10, 13, 21, 20, 12, 19, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1989.36M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.77 | Loss = 2.0125
Testing Model 667 took 1 mins and 58 secs

Testing Model 668
[20, 22, 20, 17, 20, 20, 20, 21, 13, 12, 16, 23, 22, 12, 16, 22, 20, 21, 25, 21]
FLOPs = 1992.92M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.75 | Loss = 2.0112
Testing Model 668 took 1 mins and 57 secs

Testing Model 669
[28, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 17, 25, 20, 21, 21, 21]
FLOPs = 2031.67M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.76 | Loss = 2.0133
Testing Model 669 took 1 mins and 55 secs

Testing Model 670
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 26, 18, 20, 21, 21, 21]
FLOPs = 1980.05M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.66 | Loss = 2.0172
Testing Model 670 took 1 mins and 54 secs

Testing Model 671
[20, 22, 20, 17, 27, 20, 20, 21, 13, 12, 16, 23, 22, 12, 16, 22, 20, 21, 20, 21]
FLOPs = 2001.45M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.84 | Loss = 2.0110
Testing Model 671 took 1 mins and 58 secs

Testing Model 672
[20, 22, 21, 22, 20, 10, 23, 21, 16, 2, 19, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1986.82M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.56 | Loss = 2.0189
Testing Model 672 took 1 mins and 57 secs

Testing Model 673
[20, 22, 21, 22, 20, 10, 26, 21, 16, 12, 19, 20, 22, 22, 14, 22, 15, 17, 21, 20]
FLOPs = 2043.38M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.75 | Loss = 2.0137
Testing Model 673 took 1 mins and 57 secs

Testing Model 674
[14, 14, 18, 22, 21, 22, 20, 19, 16, 22, 16, 15, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 1956.05M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.66 | Loss = 2.0167
Testing Model 674 took 1 mins and 56 secs

Testing Model 675
[4, 14, 16, 22, 29, 22, 20, 19, 13, 22, 16, 23, 22, 8, 17, 25, 22, 21, 21, 21]
FLOPs = 1989.38M
Top-1 Accuracy = 54.39 | Top-5 Accuracy = 78.17 | Loss = 2.0518
Testing Model 675 took 1 mins and 55 secs

Testing Model 676
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 18, 22, 12, 26, 22, 20, 21, 21, 21]
FLOPs = 2005.96M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.65 | Loss = 2.0178
Testing Model 676 took 1 mins and 54 secs

Testing Model 677
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 8, 17, 25, 20, 21, 21, 21]
FLOPs = 1982.41M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.66 | Loss = 2.0165
Testing Model 677 took 1 mins and 56 secs

Testing Model 678
[20, 22, 16, 22, 21, 10, 20, 19, 16, 22, 19, 20, 22, 22, 16, 22, 15, 21, 20, 21]
FLOPs = 2024.69M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.75 | Loss = 2.0123
Testing Model 678 took 1 mins and 58 secs

Testing Model 679
[14, 22, 21, 22, 21, 22, 20, 21, 16, 12, 16, 20, 22, 22, 16, 22, 15, 17, 21, 21]
FLOPs = 2048.94M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.73 | Loss = 2.0154
Testing Model 679 took 1 mins and 59 secs

Testing Model 680
[14, 14, 16, 22, 21, 22, 13, 19, 16, 22, 16, 20, 22, 9, 26, 22, 20, 21, 21, 21]
FLOPs = 1967.68M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.73 | Loss = 2.0166
Testing Model 680 took 1 mins and 57 secs

Testing Model 681
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 8, 26, 15, 15, 21, 22, 21]
FLOPs = 1952.57M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.63 | Loss = 2.0191
Testing Model 681 took 1 mins and 56 secs

Testing Model 682
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 20, 21, 21, 21]
FLOPs = 1992.80M
Top-1 Accuracy = 55.26 | Top-5 Accuracy = 78.71 | Loss = 2.0168
Testing Model 682 took 1 mins and 55 secs

Testing Model 683
[14, 22, 16, 22, 20, 20, 20, 21, 16, 12, 16, 20, 22, 12, 26, 22, 20, 21, 20, 21]
FLOPs = 2030.14M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.68 | Loss = 2.0143
Testing Model 683 took 1 mins and 54 secs

Testing Model 684
[14, 14, 16, 22, 21, 22, 13, 19, 13, 22, 16, 20, 22, 12, 26, 22, 20, 21, 20, 21]
FLOPs = 1958.30M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.68 | Loss = 2.0172
Testing Model 684 took 1 mins and 56 secs

Testing Model 685
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 12, 26, 25, 15, 21, 21, 21]
FLOPs = 2035.98M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.68 | Loss = 2.0167
Testing Model 685 took 1 mins and 55 secs

Testing Model 686
[20, 14, 20, 22, 20, 20, 20, 19, 16, 22, 16, 18, 22, 12, 26, 18, 15, 17, 20, 21]
FLOPs = 1960.65M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.79 | Loss = 2.0149
Testing Model 686 took 1 mins and 55 secs

Testing Model 687
[14, 22, 16, 17, 20, 22, 20, 19, 13, 22, 16, 23, 22, 12, 26, 22, 20, 21, 20, 21]
FLOPs = 1999.70M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.71 | Loss = 2.0165
Testing Model 687 took 1 mins and 57 secs

Testing Model 688
[20, 14, 20, 22, 20, 22, 13, 19, 13, 12, 16, 20, 22, 9, 26, 22, 20, 21, 21, 21]
FLOPs = 1958.56M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.76 | Loss = 2.0126
Testing Model 688 took 1 mins and 57 secs

Testing Model 689
[14, 22, 16, 22, 20, 20, 20, 21, 16, 22, 23, 23, 22, 12, 16, 18, 15, 21, 20, 18]
FLOPs = 2000.80M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.63 | Loss = 2.0188
Testing Model 689 took 1 mins and 56 secs

Testing Model 690
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 18, 22, 12, 26, 25, 20, 21, 21, 21]
FLOPs = 2012.55M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.68 | Loss = 2.0182
Testing Model 690 took 1 mins and 53 secs

Testing Model 691
[20, 22, 16, 22, 21, 22, 13, 21, 16, 22, 16, 20, 22, 12, 14, 18, 15, 21, 21, 21]
FLOPs = 1957.25M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.70 | Loss = 2.0148
Testing Model 691 took 1 mins and 56 secs

Testing Model 692
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 12, 26, 18, 20, 21, 22, 21]
FLOPs = 2025.74M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.71 | Loss = 2.0169
Testing Model 692 took 1 mins and 58 secs

Testing Model 693
[14, 22, 20, 17, 21, 22, 21, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 17, 21, 18]
FLOPs = 1955.06M
Top-1 Accuracy = 55.02 | Top-5 Accuracy = 78.65 | Loss = 2.0199
Testing Model 693 took 1 mins and 54 secs

Testing Model 694
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 26, 22, 15, 21, 21, 21]
FLOPs = 1970.81M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.69 | Loss = 2.0194
Testing Model 694 took 1 mins and 54 secs

Testing Model 695
[14, 22, 16, 17, 21, 22, 21, 21, 16, 22, 23, 20, 22, 12, 26, 18, 15, 17, 22, 18]
FLOPs = 1972.34M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.63 | Loss = 2.0199
Testing Model 695 took 1 mins and 58 secs

Testing Model 696
[20, 22, 20, 17, 20, 20, 20, 21, 13, 22, 16, 20, 22, 12, 16, 22, 15, 21, 20, 21]
FLOPs = 1958.90M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.76 | Loss = 2.0128
Testing Model 696 took 1 mins and 57 secs

Testing Model 697
[14, 14, 21, 22, 20, 10, 20, 19, 16, 22, 19, 20, 22, 22, 16, 22, 15, 21, 21, 21]
FLOPs = 1991.14M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.70 | Loss = 2.0168
Testing Model 697 took 1 mins and 56 secs

Testing Model 698
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 26, 25, 20, 21, 21, 21]
FLOPs = 2032.76M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.67 | Loss = 2.0182
Testing Model 698 took 1 mins and 55 secs

Testing Model 699
[14, 14, 20, 22, 21, 20, 21, 19, 16, 22, 16, 20, 22, 12, 26, 18, 20, 17, 20, 18]
FLOPs = 1973.63M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.60 | Loss = 2.0224
Testing Model 699 took 1 mins and 55 secs

Testing Model 700
[20, 22, 16, 22, 21, 22, 13, 21, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 21, 20]
FLOPs = 2035.63M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.70 | Loss = 2.0127
Testing Model 700 took 1 mins and 55 secs

> Select
Iteration 13 : Showing Top 50 results
1. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.640439987182617
2. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.595078468322754
3. [14. 14. 18. 22. 21. 22. 20. 19. 16. 22. 16. 15. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.582011222839355
4. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.574835777282715
5. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 17. 25. 20. 21.
 21. 21.] 
Reward = 15.56768798828125
6. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 21. 20.] 
Reward = 15.564767837524414
7. [20. 22. 20. 17. 20. 20. 20. 21. 13. 12. 16. 23. 22. 12. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.564648628234863
8. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 18. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.556252479553223
9. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.54874038696289
10. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.539837837219238
11. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.536077499389648
12. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.534582138061523
13. [20. 23. 20. 17. 20. 20. 20. 19. 13. 12. 16. 23. 18. 18. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.531522750854492
14. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22.  9. 26. 22. 15. 21.
 21. 21.] 
Reward = 15.5304536819458
15. [20. 22. 20. 22. 20. 10. 20. 21. 16. 12. 19. 20. 22. 12. 16. 22. 20. 17.
 20. 20.] 
Reward = 15.51479721069336
16. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22.  8. 26. 15. 15. 21.
 22. 21.] 
Reward = 15.514487266540527
17. [14. 14. 16. 22. 21. 22. 20. 19. 16. 11. 16. 20. 22. 22. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.506855010986328
18. [20. 14. 16. 22. 21. 22. 13. 19. 13. 22. 19. 20. 22.  9. 26. 22. 20. 17.
 20. 21.] 
Reward = 15.494070053100586
19. [20. 14. 16. 22. 21. 22. 14. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.489802360534668
20. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.487140655517578
21. [20. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  9. 16. 22. 20. 21.
 21. 21.] 
Reward = 15.483205795288086
22. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22. 12. 26. 22. 20. 21.
 20. 21.] 
Reward = 15.481279373168945
23. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
24. [20. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.471687316894531
25. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 21. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.470913887023926
26. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 19. 15. 17.
 20. 18.] 
Reward = 15.46304988861084
27. [20. 22. 20. 17. 22. 20. 21. 22. 16. 22. 23. 20. 22. 12. 13. 18. 15. 17.
 20. 18.] 
Reward = 15.457979202270508
28. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 26. 18. 20. 21.
 20. 21.] 
Reward = 15.45567512512207
29. [14. 14. 16. 22. 21. 22. 13. 19. 16. 22. 16. 20. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.453227043151855
30. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 21.] 
Reward = 15.448393821716309
31. [20. 14. 20. 22. 21. 22. 13. 19. 13. 12. 23. 20. 22. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.44775390625
32. [20. 22. 21. 22. 21. 10. 13. 19. 16. 12. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 20.] 
Reward = 15.444304466247559
33. [14. 14. 16. 22. 21. 22. 21. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.442277908325195
34. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.433782577514648
35. [20. 22. 20. 22. 20. 10. 20. 19. 16. 12. 19. 23. 18. 18. 16. 22. 15. 21.
 20. 20.] 
Reward = 15.431556701660156
36. [20. 22. 21. 22. 20. 10. 13. 19. 16. 12. 19. 23. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.430253028869629
37. [14. 14. 16. 22. 20. 22. 20. 21. 13. 22. 16. 23. 22. 12. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.428466796875
38. [20. 14. 20. 22. 20. 20. 20. 19. 16. 22. 16. 18. 22. 12. 26. 18. 15. 17.
 20. 21.] 
Reward = 15.428179740905762
39. [18. 25. 17. 17. 13. 11. 21. 22. 16. 26. 18. 20. 23. 17. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.428112983703613
40. [20. 14. 16. 22. 21. 20. 20. 19. 16. 22. 19. 23. 22.  9. 16. 22. 15. 21.
 21. 21.] 
Reward = 15.423428535461426
41. [14. 22. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22.  9. 16. 22. 20. 17.
 21. 21.] 
Reward = 15.421411514282227
42. [19. 23. 20. 17. 20. 20. 21. 15. 16. 22. 23. 20. 18. 18. 13. 18. 23. 17.
 20. 18.] 
Reward = 15.420969009399414
43. [20. 22. 21. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 22. 15. 21.
 21. 20.] 
Reward = 15.418389320373535
44. [14. 14. 16. 22. 21. 22. 20. 29. 16. 22. 16. 20. 22. 12. 18. 18. 15. 21.
 20. 21.] 
Reward = 15.418320655822754
45. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.417957305908203
46. [20. 23. 20. 22. 20. 10. 21. 21. 16. 12. 19. 20. 18. 18. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.416579246520996
47. [20. 22. 21. 17. 20. 20. 21. 22. 16. 22. 18. 20. 22. 12. 16. 18. 15. 17.
 20. 20.] 
Reward = 15.416141510009766
48. [20. 23. 20. 17. 20. 20. 20. 19. 16. 12. 23. 20. 18. 18. 16. 22. 20. 17.
 20. 20.] 
Reward = 15.415833473205566
49. [20. 22. 20. 17. 20. 20. 20. 21. 13. 22. 16. 20. 22. 12. 16. 22. 15. 21.
 20. 21.] 
Reward = 15.414799690246582
50. [20. 14. 21. 22. 20. 22. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.409370422363281
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 13 took 1 hour 37 mins 15 secs



Testing Model 701
[22, 14, 18, 22, 21, 22, 20, 19, 16, 22, 16, 15, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 1992.93M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.79 | Loss = 2.0145
Testing Model 701 took 1 mins and 54 secs

Testing Model 702
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 20, 10, 18, 15, 17, 20, 18]
FLOPs = 1966.72M
Top-1 Accuracy = 54.97 | Top-5 Accuracy = 78.61 | Loss = 2.0196
Testing Model 702 took 1 mins and 58 secs

Testing Model 703
[14, 14, 16, 22, 21, 4, 20, 26, 16, 22, 16, 25, 11, 23, 26, 18, 15, 21, 20, 21]
FLOPs = 1962.39M
Top-1 Accuracy = 55.04 | Top-5 Accuracy = 78.65 | Loss = 2.0202
Testing Model 703 took 1 mins and 54 secs

Testing Model 704
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 19, 20, 22, 22, 16, 22, 15, 17, 28, 20]
FLOPs = 2025.66M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.74 | Loss = 2.0130
Testing Model 704 took 1 mins and 58 secs

Testing Model 705
[20, 23, 21, 22, 20, 10, 13, 21, 16, 12, 19, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1973.15M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.73 | Loss = 2.0120
Testing Model 705 took 1 mins and 57 secs

Testing Model 706
[17, 22, 21, 22, 20, 10, 13, 21, 16, 12, 19, 20, 22, 22, 14, 22, 15, 17, 24, 20]
FLOPs = 1963.35M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.72 | Loss = 2.0135
Testing Model 706 took 1 mins and 57 secs

Testing Model 707
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 4, 20, 22, 30, 16, 18, 15, 17, 20, 18]
FLOPs = 1968.62M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.51 | Loss = 2.0266
Testing Model 707 took 1 mins and 58 secs

Testing Model 708
[14, 22, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 17, 19, 20, 21, 21, 21]
FLOPs = 2001.81M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.69 | Loss = 2.0157
Testing Model 708 took 1 mins and 57 secs

Testing Model 709
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 9, 28, 15, 20, 21, 21, 17]
FLOPs = 1951.31M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.51 | Loss = 2.0215
Testing Model 709 took 1 mins and 54 secs

Testing Model 710
[14, 14, 22, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 17, 25, 20, 13, 21, 25]
FLOPs = 2014.32M
Top-1 Accuracy = 54.99 | Top-5 Accuracy = 78.50 | Loss = 2.0207
Testing Model 710 took 1 mins and 56 secs

Testing Model 711
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 8, 30, 21, 20, 21]
FLOPs = 2010.82M
Top-1 Accuracy = 54.94 | Top-5 Accuracy = 78.54 | Loss = 2.0265
Testing Model 711 took 1 mins and 54 secs

Testing Model 712
[20, 22, 20, 17, 18, 20, 21, 16, 2, 25, 23, 20, 22, 12, 20, 28, 15, 17, 20, 18]
FLOPs = 1953.70M
Top-1 Accuracy = 55.01 | Top-5 Accuracy = 78.62 | Loss = 2.0223
Testing Model 712 took 1 mins and 56 secs

Testing Model 713
[5, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 17, 25, 28, 21, 21, 21]
FLOPs = 1987.23M
Top-1 Accuracy = 54.57 | Top-5 Accuracy = 78.23 | Loss = 2.0450
Testing Model 713 took 1 mins and 55 secs

Testing Model 714
[20, 22, 21, 22, 20, 10, 13, 21, 16, 11, 19, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1959.13M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.75 | Loss = 2.0134
Testing Model 714 took 1 mins and 56 secs

Testing Model 715
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 10, 8, 30, 25, 20, 21, 21, 21]
FLOPs = 1992.38M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.60 | Loss = 2.0201
Testing Model 715 took 1 mins and 54 secs

Testing Model 716
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 17, 16, 18, 15, 17, 20, 18]
FLOPs = 1979.05M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.69 | Loss = 2.0169
Testing Model 716 took 1 mins and 54 secs

Testing Model 717
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 19, 12, 22, 22, 16, 22, 15, 30, 21, 13]
FLOPs = 1975.89M
Top-1 Accuracy = 54.77 | Top-5 Accuracy = 78.43 | Loss = 2.0311
Testing Model 717 took 1 mins and 56 secs

Testing Model 718
[14, 14, 16, 22, 21, 26, 20, 19, 13, 22, 16, 23, 22, 8, 17, 25, 20, 21, 21, 21]
FLOPs = 1995.55M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.64 | Loss = 2.0185
Testing Model 718 took 1 mins and 56 secs

Testing Model 719
[20, 22, 21, 22, 20, 10, 13, 21, 16, 29, 19, 20, 7, 22, 14, 29, 15, 17, 21, 20]
FLOPs = 2042.90M
Top-1 Accuracy = 54.88 | Top-5 Accuracy = 78.67 | Loss = 2.0202
Testing Model 719 took 1 mins and 54 secs

Testing Model 720
[20, 22, 21, 22, 20, 10, 13, 21, 15, 12, 19, 27, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 2018.98M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.74 | Loss = 2.0127
Testing Model 720 took 1 mins and 57 secs

Testing Model 721
[5, 26, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 26, 15, 20, 21, 19, 20]
FLOPs = 2014.45M
Top-1 Accuracy = 54.64 | Top-5 Accuracy = 78.33 | Loss = 2.0458
Testing Model 721 took 1 mins and 57 secs

Testing Model 722
[14, 14, 22, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 26, 15, 20, 21, 21, 21]
FLOPs = 2040.17M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.63 | Loss = 2.0175
Testing Model 722 took 1 mins and 58 secs

Testing Model 723
[20, 22, 21, 22, 20, 10, 13, 21, 16, 15, 19, 20, 22, 22, 16, 22, 15, 17, 21, 20]
FLOPs = 1981.18M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.73 | Loss = 2.0135
Testing Model 723 took 2 mins and 0 secs

Testing Model 724
[20, 22, 21, 19, 20, 10, 13, 21, 16, 12, 19, 20, 22, 22, 27, 22, 15, 17, 21, 20]
FLOPs = 1985.83M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.72 | Loss = 2.0150
Testing Model 724 took 1 mins and 59 secs

Testing Model 725
[14, 14, 16, 30, 21, 9, 20, 5, 16, 22, 16, 20, 22, 12, 26, 18, 23, 21, 20, 21]
FLOPs = 2010.68M
Top-1 Accuracy = 55.04 | Top-5 Accuracy = 78.63 | Loss = 2.0242
Testing Model 725 took 1 mins and 51 secs

Testing Model 726
[20, 22, 20, 17, 20, 20, 21, 21, 16, 12, 16, 23, 22, 12, 16, 22, 20, 21, 20, 18]
FLOPs = 1952.91M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.71 | Loss = 2.0141
Testing Model 726 took 1 mins and 57 secs

Testing Model 727
[14, 22, 16, 22, 20, 22, 20, 19, 13, 12, 19, 20, 22, 22, 17, 25, 15, 17, 21, 20]
FLOPs = 1983.24M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.68 | Loss = 2.0158
Testing Model 727 took 1 mins and 55 secs

Testing Model 728
[20, 22, 16, 22, 21, 20, 20, 19, 13, 12, 16, 23, 22, 12, 16, 22, 20, 21, 20, 21]
FLOPs = 1982.00M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.74 | Loss = 2.0117
Testing Model 728 took 1 mins and 54 secs

Testing Model 729
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 12, 17, 25, 15, 21, 22, 21]
FLOPs = 1977.10M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.75 | Loss = 2.0160
Testing Model 729 took 1 mins and 56 secs

Testing Model 730
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 26, 15, 15, 21, 22, 21]
FLOPs = 1955.42M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.71 | Loss = 2.0183
Testing Model 730 took 1 mins and 56 secs

Testing Model 731
[20, 14, 16, 22, 21, 22, 13, 21, 16, 12, 19, 23, 22, 22, 17, 22, 15, 21, 21, 20]
FLOPs = 1963.17M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.76 | Loss = 2.0166
Testing Model 731 took 1 mins and 53 secs

Testing Model 732
[20, 22, 20, 17, 20, 20, 20, 21, 16, 22, 23, 20, 22, 12, 16, 18, 15, 21, 20, 18]
FLOPs = 1975.20M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.64 | Loss = 2.0162
Testing Model 732 took 1 mins and 52 secs

Testing Model 733
[14, 14, 18, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 26, 18, 15, 21, 21, 21]
FLOPs = 1992.63M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.68 | Loss = 2.0167
Testing Model 733 took 1 mins and 56 secs

Testing Model 734
[20, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 17, 25, 20, 21, 21, 21]
FLOPs = 2012.30M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.78 | Loss = 2.0119
Testing Model 734 took 1 mins and 54 secs

Testing Model 735
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 17, 25, 20, 21, 22, 21]
FLOPs = 1973.88M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.66 | Loss = 2.0159
Testing Model 735 took 1 mins and 54 secs

Testing Model 736
[14, 14, 16, 22, 20, 22, 13, 19, 16, 22, 16, 20, 22, 22, 26, 22, 15, 21, 21, 21]
FLOPs = 2009.04M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.70 | Loss = 2.0158
Testing Model 736 took 1 mins and 53 secs

Testing Model 737
[20, 22, 21, 22, 20, 22, 20, 19, 16, 12, 19, 20, 22, 12, 14, 22, 15, 21, 21, 21]
FLOPs = 2029.05M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.72 | Loss = 2.0128
Testing Model 737 took 1 mins and 58 secs

Testing Model 738
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 26, 18, 20, 21, 21, 21]
FLOPs = 2000.02M
Top-1 Accuracy = 55.25 | Top-5 Accuracy = 78.70 | Loss = 2.0148
Testing Model 738 took 1 mins and 54 secs

Testing Model 739
[20, 22, 21, 17, 20, 10, 13, 21, 16, 22, 23, 20, 22, 22, 16, 22, 15, 17, 20, 20]
FLOPs = 1956.98M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.68 | Loss = 2.0125
Testing Model 739 took 1 mins and 57 secs

Testing Model 740
[14, 14, 21, 22, 20, 22, 20, 21, 13, 12, 19, 23, 22, 8, 17, 25, 20, 21, 21, 21]
FLOPs = 1993.93M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.73 | Loss = 2.0152
Testing Model 740 took 1 mins and 58 secs

Testing Model 741
[20, 22, 18, 22, 21, 22, 13, 19, 16, 22, 16, 15, 22, 22, 16, 18, 15, 17, 22, 20]
FLOPs = 1975.10M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.71 | Loss = 2.0139
Testing Model 741 took 1 mins and 58 secs

Testing Model 742
[20, 14, 20, 22, 21, 20, 20, 21, 13, 22, 16, 23, 22, 12, 17, 22, 20, 21, 21, 21]
FLOPs = 2043.47M
Top-1 Accuracy = 55.24 | Top-5 Accuracy = 78.90 | Loss = 2.0107
Testing Model 742 took 1 mins and 56 secs

Testing Model 743
[14, 22, 21, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 16, 22, 15, 17, 21, 21]
FLOPs = 2031.42M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.66 | Loss = 2.0168
Testing Model 743 took 1 mins and 58 secs

Testing Model 744
[20, 22, 16, 22, 20, 22, 13, 19, 16, 22, 16, 23, 22, 8, 16, 25, 20, 17, 21, 21]
FLOPs = 2002.91M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.73 | Loss = 2.0161
Testing Model 744 took 1 mins and 56 secs

Testing Model 745
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 8, 26, 18, 15, 21, 20, 21]
FLOPs = 1955.46M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.69 | Loss = 2.0180
Testing Model 745 took 1 mins and 59 secs

Testing Model 746
[14, 22, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 22, 14, 18, 15, 21, 21, 21]
FLOPs = 2020.55M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.70 | Loss = 2.0170
Testing Model 746 took 1 mins and 57 secs

Testing Model 747
[20, 22, 18, 22, 21, 22, 13, 19, 16, 22, 16, 20, 22, 22, 14, 22, 15, 17, 21, 21]
FLOPs = 2029.31M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.73 | Loss = 2.0131
Testing Model 747 took 1 mins and 56 secs

Testing Model 748
[14, 22, 16, 22, 20, 10, 20, 21, 16, 12, 16, 20, 22, 22, 26, 22, 15, 17, 21, 21]
FLOPs = 1975.67M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.72 | Loss = 2.0179
Testing Model 748 took 1 mins and 55 secs

Testing Model 749
[14, 22, 21, 22, 20, 10, 20, 21, 16, 22, 16, 20, 22, 8, 26, 22, 15, 17, 21, 21]
FLOPs = 2020.78M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.68 | Loss = 2.0162
Testing Model 749 took 1 mins and 54 secs

Testing Model 750
[20, 14, 21, 22, 21, 10, 20, 19, 16, 12, 16, 20, 22, 22, 26, 18, 15, 17, 22, 21]
FLOPs = 1959.85M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.80 | Loss = 2.0128
Testing Model 750 took 1 mins and 52 secs

> Select
Iteration 14 : Showing Top 50 results
1. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.640439987182617
2. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.595078468322754
3. [14. 14. 18. 22. 21. 22. 20. 19. 16. 22. 16. 15. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.582011222839355
4. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.574835777282715
5. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 17. 25. 20. 21.
 21. 21.] 
Reward = 15.56768798828125
6. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 21. 20.] 
Reward = 15.564767837524414
7. [20. 22. 20. 17. 20. 20. 20. 21. 13. 12. 16. 23. 22. 12. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.564648628234863
8. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 18. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.556252479553223
9. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.54874038696289
10. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22.  8. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.547995567321777
11. [20. 14. 21. 22. 21. 10. 20. 19. 16. 12. 16. 20. 22. 22. 26. 18. 15. 17.
 22. 21.] 
Reward = 15.545217514038086
12. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.539837837219238
13. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.536077499389648
14. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.534582138061523
15. [20. 22. 21. 17. 20. 10. 13. 21. 16. 22. 23. 20. 22. 22. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.531606674194336
16. [20. 23. 20. 17. 20. 20. 20. 19. 13. 12. 16. 23. 18. 18. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.531522750854492
17. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22.  9. 26. 22. 15. 21.
 21. 21.] 
Reward = 15.5304536819458
18. [20. 22. 20. 22. 20. 10. 20. 21. 16. 12. 19. 20. 22. 12. 16. 22. 20. 17.
 20. 20.] 
Reward = 15.51479721069336
19. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22.  8. 26. 15. 15. 21.
 22. 21.] 
Reward = 15.514487266540527
20. [14. 14. 16. 22. 21. 22. 20. 19. 16. 11. 16. 20. 22. 22. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.506855010986328
21. [20. 22. 21. 22. 20. 10. 13. 21. 16. 11. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.504549980163574
22. [20. 14. 16. 22. 21. 22. 13. 19. 13. 22. 19. 20. 22.  9. 26. 22. 20. 17.
 20. 21.] 
Reward = 15.494070053100586
23. [20. 14. 16. 22. 21. 22. 14. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.489802360534668
24. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.487140655517578
25. [20. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  9. 16. 22. 20. 21.
 21. 21.] 
Reward = 15.483205795288086
26. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22. 12. 26. 22. 20. 21.
 20. 21.] 
Reward = 15.481279373168945
27. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
28. [20. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.471687316894531
29. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 21. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.470913887023926
30. [20. 14. 16. 22. 21. 22. 13. 21. 16. 12. 19. 23. 22. 22. 17. 22. 15. 21.
 21. 20.] 
Reward = 15.465348243713379
31. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 19. 15. 17.
 20. 18.] 
Reward = 15.46304988861084
32. [20. 22. 20. 17. 22. 20. 21. 22. 16. 22. 23. 20. 22. 12. 13. 18. 15. 17.
 20. 18.] 
Reward = 15.457979202270508
33. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 26. 18. 20. 21.
 20. 21.] 
Reward = 15.45567512512207
34. [14. 14. 16. 22. 21. 22. 13. 19. 16. 22. 16. 20. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.453227043151855
35. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 21.] 
Reward = 15.448393821716309
36. [20. 14. 20. 22. 21. 22. 13. 19. 13. 12. 23. 20. 22. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.44775390625
37. [17. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 24. 20.] 
Reward = 15.44729995727539
38. [20. 22. 21. 22. 21. 10. 13. 19. 16. 12. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 20.] 
Reward = 15.444304466247559
39. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 28. 15. 20. 21.
 21. 17.] 
Reward = 15.443835258483887
40. [14. 14. 16. 22. 21. 22. 21. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.442277908325195
41. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.433782577514648
42. [20. 22. 20. 22. 20. 10. 20. 19. 16. 12. 19. 23. 18. 18. 16. 22. 15. 21.
 20. 20.] 
Reward = 15.431556701660156
43. [20. 22. 21. 22. 20. 10. 13. 19. 16. 12. 19. 23. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.430253028869629
44. [14. 14. 16. 22. 20. 22. 20. 21. 13. 22. 16. 23. 22. 12. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.428466796875
45. [20. 14. 20. 22. 20. 20. 20. 19. 16. 22. 16. 18. 22. 12. 26. 18. 15. 17.
 20. 21.] 
Reward = 15.428179740905762
46. [18. 25. 17. 17. 13. 11. 21. 22. 16. 26. 18. 20. 23. 17. 16. 18. 15. 23.
 23. 20.] 
Reward = 15.428112983703613
47. [20. 14. 16. 22. 21. 20. 20. 19. 16. 22. 19. 23. 22.  9. 16. 22. 15. 21.
 21. 21.] 
Reward = 15.423428535461426
48. [14. 22. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22.  9. 16. 22. 20. 17.
 21. 21.] 
Reward = 15.421411514282227
49. [19. 23. 20. 17. 20. 20. 21. 15. 16. 22. 23. 20. 18. 18. 13. 18. 23. 17.
 20. 18.] 
Reward = 15.420969009399414
50. [20. 22. 21. 18. 20. 12. 23. 21. 16. 12. 19. 20. 22. 18. 16. 22. 15. 21.
 21. 20.] 
Reward = 15.418389320373535
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 14 took 1 hour 37 mins 10 secs



Testing Model 751
[14, 14, 16, 22, 21, 22, 18, 19, 27, 22, 16, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 2014.14M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.68 | Loss = 2.0188
Testing Model 751 took 1 mins and 55 secs

Testing Model 752
[20, 22, 20, 17, 20, 20, 20, 21, 13, 12, 16, 23, 22, 26, 16, 22, 20, 21, 20, 21]
FLOPs = 2042.18M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.79 | Loss = 2.0109
Testing Model 752 took 1 mins and 56 secs

Testing Model 753
[20, 14, 15, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 17, 25, 20, 21, 21, 21]
FLOPs = 1979.52M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.76 | Loss = 2.0156
Testing Model 753 took 1 mins and 56 secs

Testing Model 754
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 24, 26, 18, 15, 21, 20, 21]
FLOPs = 2032.11M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.72 | Loss = 2.0167
Testing Model 754 took 1 mins and 58 secs

Testing Model 755
[14, 14, 16, 28, 21, 22, 1, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 1977.79M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.69 | Loss = 2.0197
Testing Model 755 took 1 mins and 57 secs

Testing Model 756
[14, 14, 23, 22, 21, 22, 20, 19, 13, 22, 16, 23, 8, 8, 17, 25, 20, 21, 21, 21]
FLOPs = 1971.79M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.68 | Loss = 2.0242
Testing Model 756 took 1 mins and 57 secs

Testing Model 757
[14, 14, 18, 22, 21, 22, 20, 16, 16, 28, 16, 15, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 1983.30M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.67 | Loss = 2.0148
Testing Model 757 took 1 mins and 55 secs

Testing Model 758
[20, 22, 20, 17, 20, 20, 30, 21, 13, 12, 16, 23, 22, 12, 10, 26, 20, 21, 20, 21]
FLOPs = 2035.02M
Top-1 Accuracy = 55.04 | Top-5 Accuracy = 78.82 | Loss = 2.0137
Testing Model 758 took 1 mins and 55 secs

Testing Model 759
[14, 14, 18, 22, 30, 22, 20, 19, 16, 22, 16, 15, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 2021.53M
Top-1 Accuracy = 55.26 | Top-5 Accuracy = 78.71 | Loss = 2.0168
Testing Model 759 took 1 mins and 56 secs

Testing Model 760
[14, 20, 18, 22, 21, 22, 20, 19, 16, 27, 16, 22, 22, 12, 2, 18, 26, 21, 22, 21]
FLOPs = 2049.09M
Top-1 Accuracy = 54.93 | Top-5 Accuracy = 78.46 | Loss = 2.0359
Testing Model 760 took 1 mins and 56 secs

Testing Model 761
[14, 14, 18, 22, 21, 22, 20, 19, 16, 22, 16, 15, 22, 12, 26, 23, 15, 21, 22, 21]
FLOPs = 1993.09M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.66 | Loss = 2.0165
Testing Model 761 took 1 mins and 55 secs

Testing Model 762
[20, 22, 20, 17, 20, 28, 20, 21, 13, 12, 16, 23, 30, 14, 17, 22, 20, 3, 20, 21]
FLOPs = 1980.03M
Top-1 Accuracy = 54.33 | Top-5 Accuracy = 78.17 | Loss = 2.0565
Testing Model 762 took 1 mins and 54 secs

Testing Model 763
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 19, 20, 22, 21, 16, 22, 15, 17, 21, 20]
FLOPs = 1955.48M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.79 | Loss = 2.0136
Testing Model 763 took 1 mins and 56 secs

Testing Model 764
[14, 14, 16, 22, 21, 22, 20, 19, 19, 22, 16, 23, 22, 8, 17, 25, 20, 21, 21, 20]
FLOPs = 1992.05M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.62 | Loss = 2.0179
Testing Model 764 took 1 mins and 52 secs

Testing Model 765
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 24, 21]
FLOPs = 1984.23M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.64 | Loss = 2.0172
Testing Model 765 took 1 mins and 51 secs

Testing Model 766
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 20, 27]
FLOPs = 2003.56M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.78 | Loss = 2.0167
Testing Model 766 took 1 mins and 55 secs

Testing Model 767
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 6, 23, 27, 8, 17, 25, 20, 21, 21, 21]
FLOPs = 1957.25M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.63 | Loss = 2.0216
Testing Model 767 took 1 mins and 55 secs

Testing Model 768
[14, 14, 18, 22, 21, 22, 20, 19, 16, 22, 16, 15, 22, 13, 26, 18, 15, 26, 22, 21]
FLOPs = 2009.37M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.71 | Loss = 2.0168
Testing Model 768 took 1 mins and 55 secs

Testing Model 769
[20, 22, 21, 22, 20, 10, 13, 30, 16, 12, 19, 20, 22, 22, 14, 22, 15, 17, 21, 20]
FLOPs = 2037.65M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.69 | Loss = 2.0108
Testing Model 769 took 1 mins and 54 secs

Testing Model 770
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 12, 16, 18, 15, 17, 21, 18]
FLOPs = 1958.55M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.66 | Loss = 2.0173
Testing Model 770 took 1 mins and 54 secs

Testing Model 771
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 12, 16, 28, 15, 17, 20, 18]
FLOPs = 2024.34M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.63 | Loss = 2.0188
Testing Model 771 took 1 mins and 55 secs

Testing Model 772
[14, 14, 18, 22, 8, 22, 20, 19, 13, 22, 16, 23, 22, 8, 17, 25, 20, 21, 21, 30]
FLOPs = 2013.34M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.63 | Loss = 2.0190
Testing Model 772 took 1 mins and 54 secs

Testing Model 773
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 26, 15, 21, 21, 21]
FLOPs = 2020.32M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.69 | Loss = 2.0168
Testing Model 773 took 1 mins and 53 secs

Testing Model 774
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 27, 16, 18, 15, 17, 20, 18]
FLOPs = 2049.72M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.65 | Loss = 2.0176
Testing Model 774 took 1 mins and 57 secs

Testing Model 775
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 21, 18, 22, 4, 26, 18, 15, 30, 22, 21]
FLOPs = 2035.14M
Top-1 Accuracy = 55.03 | Top-5 Accuracy = 78.60 | Loss = 2.0229
Testing Model 775 took 1 mins and 57 secs

Testing Model 776
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 17, 25, 15, 21, 22, 21]
FLOPs = 1959.98M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.69 | Loss = 2.0160
Testing Model 776 took 1 mins and 55 secs

Testing Model 777
[20, 22, 16, 22, 20, 20, 20, 21, 16, 22, 23, 20, 22, 12, 16, 18, 15, 17, 21, 18]
FLOPs = 1979.50M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.68 | Loss = 2.0181
Testing Model 777 took 1 mins and 55 secs

Testing Model 778
[20, 22, 21, 22, 20, 22, 20, 21, 16, 12, 16, 15, 22, 12, 26, 18, 15, 17, 21, 20]
FLOPs = 2003.69M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.72 | Loss = 2.0161
Testing Model 778 took 1 mins and 57 secs

Testing Model 779
[14, 22, 18, 17, 21, 22, 21, 21, 16, 22, 23, 15, 22, 12, 16, 18, 15, 21, 22, 21]
FLOPs = 1950.03M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.69 | Loss = 2.0146
Testing Model 779 took 1 mins and 57 secs

Testing Model 780
[14, 14, 18, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 8, 26, 18, 15, 21, 20, 21]
FLOPs = 1982.52M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.67 | Loss = 2.0191
Testing Model 780 took 1 mins and 56 secs

Testing Model 781
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 8, 26, 25, 15, 21, 21, 21]
FLOPs = 1974.54M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.68 | Loss = 2.0177
Testing Model 781 took 1 mins and 55 secs

Testing Model 782
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 1991.87M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.74 | Loss = 2.0154
Testing Model 782 took 1 mins and 56 secs

Testing Model 783
[14, 22, 16, 22, 20, 20, 20, 19, 16, 22, 23, 20, 22, 12, 16, 18, 15, 21, 20, 18]
FLOPs = 1959.62M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.64 | Loss = 2.0188
Testing Model 783 took 1 mins and 56 secs

Testing Model 784
[14, 14, 20, 22, 21, 20, 20, 21, 13, 12, 16, 23, 22, 12, 26, 18, 20, 21, 22, 21]
FLOPs = 1998.82M
Top-1 Accuracy = 55.26 | Top-5 Accuracy = 78.76 | Loss = 2.0141
Testing Model 784 took 1 mins and 54 secs

Testing Model 785
[14, 22, 16, 22, 20, 20, 20, 19, 13, 22, 16, 23, 22, 12, 16, 22, 15, 21, 20, 21]
FLOPs = 1973.33M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.80 | Loss = 2.0148
Testing Model 785 took 1 mins and 56 secs

Testing Model 786
[14, 22, 20, 22, 20, 20, 20, 19, 13, 22, 16, 23, 22, 12, 16, 22, 15, 21, 22, 21]
FLOPs = 2045.69M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.79 | Loss = 2.0114
Testing Model 786 took 1 mins and 57 secs

Testing Model 787
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 12, 17, 25, 15, 21, 20, 21]
FLOPs = 1960.66M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.73 | Loss = 2.0168
Testing Model 787 took 1 mins and 53 secs

Testing Model 788
[20, 22, 21, 22, 20, 20, 21, 21, 16, 22, 19, 20, 22, 12, 14, 22, 15, 17, 20, 18]
FLOPs = 2039.02M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.66 | Loss = 2.0172
Testing Model 788 took 2 mins and 0 secs

Testing Model 789
[14, 22, 20, 17, 20, 20, 20, 19, 16, 22, 16, 23, 22, 12, 26, 18, 20, 21, 20, 21]
FLOPs = 2029.61M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.75 | Loss = 2.0148
Testing Model 789 took 1 mins and 58 secs

Testing Model 790
[14, 22, 16, 22, 21, 22, 20, 21, 13, 12, 16, 20, 22, 12, 26, 18, 20, 21, 20, 21]
FLOPs = 2005.85M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.75 | Loss = 2.0126
Testing Model 790 took 1 mins and 57 secs

Testing Model 791
[14, 14, 16, 22, 20, 22, 20, 19, 16, 22, 23, 20, 22, 12, 26, 18, 15, 21, 21, 18]
FLOPs = 1975.29M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.60 | Loss = 2.0211
Testing Model 791 took 1 mins and 56 secs

Testing Model 792
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 17, 25, 15, 21, 21, 21]
FLOPs = 1951.39M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.75 | Loss = 2.0164
Testing Model 792 took 1 mins and 54 secs

Testing Model 793
[20, 22, 16, 22, 21, 22, 20, 19, 16, 22, 19, 20, 22, 12, 26, 18, 15, 17, 21, 20]
FLOPs = 2045.89M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.74 | Loss = 2.0145
Testing Model 793 took 1 mins and 59 secs

Testing Model 794
[14, 14, 20, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 26, 18, 15, 21, 20, 21]
FLOPs = 1991.29M
Top-1 Accuracy = 55.24 | Top-5 Accuracy = 78.71 | Loss = 2.0154
Testing Model 794 took 1 mins and 53 secs

Testing Model 795
[20, 22, 16, 22, 20, 22, 20, 21, 13, 12, 16, 20, 22, 12, 26, 18, 20, 21, 20, 21]
FLOPs = 2028.40M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.77 | Loss = 2.0133
Testing Model 795 took 1 mins and 57 secs

Testing Model 796
[14, 22, 16, 22, 21, 22, 20, 21, 16, 12, 16, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 1989.10M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.73 | Loss = 2.0138
Testing Model 796 took 1 mins and 56 secs

Testing Model 797
[20, 22, 20, 17, 21, 20, 21, 21, 16, 22, 16, 23, 22, 8, 17, 18, 15, 21, 21, 18]
FLOPs = 1961.48M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.68 | Loss = 2.0178
Testing Model 797 took 1 mins and 57 secs

Testing Model 798
[20, 22, 16, 17, 21, 20, 20, 21, 16, 22, 23, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 2017.69M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.83 | Loss = 2.0150
Testing Model 798 took 1 mins and 55 secs

Testing Model 799
[14, 22, 18, 22, 21, 10, 20, 19, 16, 22, 16, 20, 22, 22, 16, 22, 15, 17, 21, 21]
FLOPs = 1980.02M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.68 | Loss = 2.0156
Testing Model 799 took 2 mins and 4 secs

Testing Model 800
[20, 14, 18, 22, 21, 20, 20, 21, 16, 22, 16, 23, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 2031.26M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.77 | Loss = 2.0151
Testing Model 800 took 1 mins and 56 secs

> Select
Iteration 15 : Showing Top 50 results
1. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.640439987182617
2. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 21. 21.] 
Reward = 15.616037368774414
3. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.595078468322754
4. [14. 14. 18. 22. 21. 22. 20. 19. 16. 22. 16. 15. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.582011222839355
5. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.574835777282715
6. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 21. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.567974090576172
7. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 17. 25. 20. 21.
 21. 21.] 
Reward = 15.56768798828125
8. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 21. 20.] 
Reward = 15.564767837524414
9. [20. 22. 20. 17. 20. 20. 20. 21. 13. 12. 16. 23. 22. 12. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.564648628234863
10. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 18. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.556252479553223
11. [14. 22. 18. 17. 21. 22. 21. 21. 16. 22. 23. 15. 22. 12. 16. 18. 15. 21.
 22. 21.] 
Reward = 15.553827285766602
12. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.54874038696289
13. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 20. 21.] 
Reward = 15.548630714416504
14. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22.  8. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.547995567321777
15. [20. 14. 21. 22. 21. 10. 20. 19. 16. 12. 16. 20. 22. 22. 26. 18. 15. 17.
 22. 21.] 
Reward = 15.545217514038086
16. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.539837837219238
17. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.536077499389648
18. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.534582138061523
19. [20. 22. 21. 17. 20. 10. 13. 21. 16. 22. 23. 20. 22. 22. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.531606674194336
20. [20. 23. 20. 17. 20. 20. 20. 19. 13. 12. 16. 23. 18. 18. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.531522750854492
21. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22.  9. 26. 22. 15. 21.
 21. 21.] 
Reward = 15.5304536819458
22. [20. 22. 20. 22. 20. 10. 20. 21. 16. 12. 19. 20. 22. 12. 16. 22. 20. 17.
 20. 20.] 
Reward = 15.51479721069336
23. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22.  8. 26. 15. 15. 21.
 22. 21.] 
Reward = 15.514487266540527
24. [14. 14. 16. 22. 21. 22. 20. 19. 16. 11. 16. 20. 22. 22. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.506855010986328
25. [20. 22. 21. 22. 20. 10. 13. 21. 16. 11. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.504549980163574
26. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 22. 21.] 
Reward = 15.503497123718262
27. [20. 14. 16. 22. 21. 22. 13. 19. 13. 22. 19. 20. 22.  9. 26. 22. 20. 17.
 20. 21.] 
Reward = 15.494070053100586
28. [20. 14. 16. 22. 21. 22. 14. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.489802360534668
29. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.487140655517578
30. [20. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  9. 16. 22. 20. 21.
 21. 21.] 
Reward = 15.483205795288086
31. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22. 12. 26. 22. 20. 21.
 20. 21.] 
Reward = 15.481279373168945
32. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
33. [20. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.471687316894531
34. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 21. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.470913887023926
35. [20. 14. 16. 22. 21. 22. 13. 21. 16. 12. 19. 23. 22. 22. 17. 22. 15. 21.
 21. 20.] 
Reward = 15.465348243713379
36. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 19. 15. 17.
 20. 18.] 
Reward = 15.46304988861084
37. [20. 22. 20. 17. 22. 20. 21. 22. 16. 22. 23. 20. 22. 12. 13. 18. 15. 17.
 20. 18.] 
Reward = 15.457979202270508
38. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 26. 18. 20. 21.
 20. 21.] 
Reward = 15.45567512512207
39. [14. 14. 16. 22. 21. 22. 13. 19. 16. 22. 16. 20. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.453227043151855
40. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 21.] 
Reward = 15.448393821716309
41. [20. 14. 20. 22. 21. 22. 13. 19. 13. 12. 23. 20. 22. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.44775390625
42. [17. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 24. 20.] 
Reward = 15.44729995727539
43. [20. 22. 21. 22. 21. 10. 13. 19. 16. 12. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 20.] 
Reward = 15.444304466247559
44. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 28. 15. 20. 21.
 21. 17.] 
Reward = 15.443835258483887
45. [14. 14. 16. 22. 21. 22. 21. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.442277908325195
46. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.433782577514648
47. [20. 22. 20. 22. 20. 10. 20. 19. 16. 12. 19. 23. 18. 18. 16. 22. 15. 21.
 20. 20.] 
Reward = 15.431556701660156
48. [20. 22. 21. 22. 20. 10. 13. 19. 16. 12. 19. 23. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.430253028869629
49. [14. 14. 16. 22. 20. 22. 20. 21. 13. 22. 16. 23. 22. 12. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.428466796875
50. [20. 14. 20. 22. 20. 20. 20. 19. 16. 22. 16. 18. 22. 12. 26. 18. 15. 17.
 20. 21.] 
Reward = 15.428179740905762
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 15 took 1 hour 37 mins 6 secs



Testing Model 801
[20, 22, 20, 17, 20, 20, 13, 22, 16, 28, 23, 20, 22, 12, 16, 18, 15, 17, 20, 18]
FLOPs = 1956.81M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.60 | Loss = 2.0192
Testing Model 801 took 1 mins and 55 secs

Testing Model 802
[14, 14, 21, 22, 17, 22, 20, 19, 13, 25, 16, 23, 22, 8, 17, 25, 20, 21, 21, 9]
FLOPs = 1950.35M
Top-1 Accuracy = 54.23 | Top-5 Accuracy = 78.01 | Loss = 2.0538
Testing Model 802 took 1 mins and 53 secs

Testing Model 803
[20, 22, 21, 22, 16, 10, 13, 28, 16, 12, 19, 20, 22, 22, 14, 22, 15, 17, 21, 20]
FLOPs = 1995.06M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.76 | Loss = 2.0139
Testing Model 803 took 1 mins and 55 secs

Testing Model 804
[14, 14, 16, 21, 21, 22, 20, 19, 24, 22, 16, 23, 22, 12, 16, 25, 15, 21, 21, 21]
FLOPs = 1995.07M
Top-1 Accuracy = 55.25 | Top-5 Accuracy = 78.68 | Loss = 2.0175
Testing Model 804 took 1 mins and 54 secs

Testing Model 805
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 20, 27, 22, 12, 17, 25, 15, 21, 21, 21]
FLOPs = 2010.21M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.68 | Loss = 2.0165
Testing Model 805 took 1 mins and 52 secs

Testing Model 806
[14, 30, 16, 22, 21, 22, 23, 19, 13, 22, 16, 23, 8, 12, 17, 25, 11, 21, 14, 21]
FLOPs = 1982.69M
Top-1 Accuracy = 54.86 | Top-5 Accuracy = 78.55 | Loss = 2.0319
Testing Model 806 took 1 mins and 58 secs

Testing Model 807
[14, 14, 16, 22, 26, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 21, 21]
FLOPs = 1993.05M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.71 | Loss = 2.0188
Testing Model 807 took 1 mins and 54 secs

Testing Model 808
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 17, 25, 20, 21, 24, 21]
FLOPs = 1990.60M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.61 | Loss = 2.0182
Testing Model 808 took 1 mins and 56 secs

Testing Model 809
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 17, 25, 15, 21, 26, 21]
FLOPs = 1994.81M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.68 | Loss = 2.0191
Testing Model 809 took 1 mins and 56 secs

Testing Model 810
[14, 14, 16, 22, 25, 22, 20, 19, 16, 22, 16, 23, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 2002.27M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.67 | Loss = 2.0188
Testing Model 810 took 1 mins and 55 secs

Testing Model 811
[14, 14, 16, 22, 21, 13, 20, 19, 13, 22, 16, 23, 22, 12, 17, 25, 25, 21, 21, 21]
FLOPs = 1971.12M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.72 | Loss = 2.0168
Testing Model 811 took 1 mins and 53 secs

Testing Model 812
[14, 14, 18, 22, 21, 22, 20, 19, 16, 22, 16, 8, 29, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 1971.67M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.57 | Loss = 2.0235
Testing Model 812 took 1 mins and 55 secs

Testing Model 813
[14, 14, 16, 22, 26, 22, 20, 19, 16, 22, 16, 18, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 1985.80M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.69 | Loss = 2.0171
Testing Model 813 took 1 mins and 54 secs

Testing Model 814
[29, 14, 23, 22, 21, 22, 20, 13, 16, 22, 16, 20, 22, 12, 18, 18, 15, 21, 21, 21]
FLOPs = 2020.26M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.83 | Loss = 2.0133
Testing Model 814 took 1 mins and 56 secs

Testing Model 815
[14, 14, 16, 22, 1, 22, 20, 19, 13, 22, 16, 23, 22, 8, 17, 25, 20, 28, 21, 21]
FLOPs = 1955.15M
Top-1 Accuracy = 54.87 | Top-5 Accuracy = 78.45 | Loss = 2.0299
Testing Model 815 took 1 mins and 56 secs

Testing Model 816
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 27, 22, 12, 17, 25, 15, 21, 21, 21]
FLOPs = 1985.95M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.75 | Loss = 2.0152
Testing Model 816 took 1 mins and 56 secs

Testing Model 817
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 10, 21, 21, 26]
FLOPs = 1974.50M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.66 | Loss = 2.0209
Testing Model 817 took 1 mins and 57 secs

Testing Model 818
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 8, 30, 22, 20, 30, 21, 3]
FLOPs = 2021.64M
Top-1 Accuracy = 52.39 | Top-5 Accuracy = 76.94 | Loss = 2.1407
Testing Model 818 took 1 mins and 56 secs

Testing Model 819
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 12, 16, 18, 15, 17, 30, 18]
FLOPs = 2040.73M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.63 | Loss = 2.0182
Testing Model 819 took 1 mins and 56 secs

Testing Model 820
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 18, 22, 12, 26, 18, 28, 21, 22, 21]
FLOPs = 2049.29M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.68 | Loss = 2.0173
Testing Model 820 took 1 mins and 57 secs

Testing Model 821
[20, 22, 21, 22, 20, 12, 13, 21, 20, 12, 19, 20, 22, 21, 16, 22, 15, 17, 21, 20]
FLOPs = 1992.56M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.74 | Loss = 2.0124
Testing Model 821 took 2 mins and 0 secs

Testing Model 822
[14, 14, 16, 22, 21, 22, 20, 19, 13, 29, 16, 23, 22, 12, 17, 25, 15, 21, 21, 21]
FLOPs = 2006.11M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.69 | Loss = 2.0163
Testing Model 822 took 1 mins and 55 secs

Testing Model 823
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 24, 20, 22, 12, 16, 18, 15, 17, 20, 18]
FLOPs = 1956.74M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.65 | Loss = 2.0179
Testing Model 823 took 1 mins and 54 secs

Testing Model 824
[14, 13, 16, 22, 27, 22, 20, 19, 16, 22, 16, 18, 22, 12, 26, 18, 15, 21, 22, 24]
FLOPs = 2007.55M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.75 | Loss = 2.0173
Testing Model 824 took 1 mins and 52 secs

Testing Model 825
[14, 14, 16, 22, 21, 20, 20, 19, 13, 22, 16, 23, 22, 8, 17, 25, 20, 21, 21, 21]
FLOPs = 1951.52M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.66 | Loss = 2.0180
Testing Model 825 took 1 mins and 57 secs

Testing Model 826
[14, 22, 20, 17, 20, 22, 20, 19, 13, 22, 16, 23, 22, 8, 16, 22, 20, 21, 20, 21]
FLOPs = 1966.04M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.71 | Loss = 2.0178
Testing Model 826 took 1 mins and 59 secs

Testing Model 827
[20, 22, 16, 22, 20, 20, 21, 21, 13, 22, 23, 23, 22, 12, 17, 18, 15, 17, 20, 21]
FLOPs = 2016.59M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.77 | Loss = 2.0132
Testing Model 827 took 1 mins and 57 secs

Testing Model 828
[14, 14, 20, 22, 21, 22, 20, 21, 13, 12, 16, 23, 22, 12, 17, 25, 20, 21, 21, 21]
FLOPs = 1989.24M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.70 | Loss = 2.0141
Testing Model 828 took 1 mins and 55 secs

Testing Model 829
[20, 14, 16, 22, 20, 10, 20, 21, 16, 22, 16, 18, 22, 22, 26, 22, 15, 17, 21, 20]
FLOPs = 1965.42M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.72 | Loss = 2.0158
Testing Model 829 took 1 mins and 54 secs

Testing Model 830
[14, 14, 20, 22, 20, 22, 20, 21, 13, 22, 16, 23, 22, 12, 16, 22, 20, 21, 21, 21]
FLOPs = 2017.32M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.78 | Loss = 2.0156
Testing Model 830 took 1 mins and 55 secs

Testing Model 831
[14, 14, 18, 22, 21, 22, 20, 19, 13, 22, 16, 15, 22, 12, 26, 25, 20, 21, 22, 21]
FLOPs = 2024.93M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.74 | Loss = 2.0143
Testing Model 831 took 2 mins and 0 secs

Testing Model 832
[20, 22, 20, 17, 20, 20, 21, 21, 13, 22, 23, 20, 22, 12, 16, 22, 20, 21, 20, 21]
FLOPs = 2046.54M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.80 | Loss = 2.0118
Testing Model 832 took 2 mins and 0 secs

Testing Model 833
[14, 14, 18, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 1994.02M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.69 | Loss = 2.0172
Testing Model 833 took 1 mins and 54 secs

Testing Model 834
[20, 22, 20, 17, 21, 22, 20, 21, 16, 22, 23, 20, 22, 12, 16, 18, 15, 21, 22, 21]
FLOPs = 2036.99M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.80 | Loss = 2.0120
Testing Model 834 took 1 mins and 55 secs

Testing Model 835
[20, 22, 20, 17, 20, 20, 20, 21, 16, 12, 23, 20, 22, 12, 16, 22, 20, 21, 20, 18]
FLOPs = 1969.18M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.67 | Loss = 2.0138
Testing Model 835 took 1 mins and 54 secs

Testing Model 836
[20, 22, 16, 22, 20, 22, 13, 19, 13, 22, 19, 23, 22, 12, 16, 22, 15, 17, 21, 21]
FLOPs = 1965.66M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.73 | Loss = 2.0142
Testing Model 836 took 1 mins and 53 secs

Testing Model 837
[14, 14, 20, 22, 21, 20, 21, 21, 13, 22, 23, 20, 22, 12, 17, 25, 15, 21, 21, 18]
FLOPs = 2012.71M
Top-1 Accuracy = 55.07 | Top-5 Accuracy = 78.65 | Loss = 2.0214
Testing Model 837 took 1 mins and 55 secs

Testing Model 838
[20, 14, 20, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 16, 18, 20, 21, 20, 21]
FLOPs = 1972.50M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.77 | Loss = 2.0137
Testing Model 838 took 1 mins and 55 secs

Testing Model 839
[20, 22, 16, 17, 20, 20, 20, 19, 16, 22, 23, 23, 22, 12, 16, 25, 15, 17, 20, 21]
FLOPs = 1965.76M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.71 | Loss = 2.0147
Testing Model 839 took 1 mins and 54 secs

Testing Model 840
[14, 22, 20, 17, 20, 22, 21, 21, 16, 22, 23, 15, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 2040.67M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.68 | Loss = 2.0141
Testing Model 840 took 1 mins and 56 secs

Testing Model 841
[20, 22, 16, 22, 21, 10, 20, 19, 13, 12, 16, 23, 22, 21, 16, 25, 15, 21, 21, 20]
FLOPs = 1969.46M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.72 | Loss = 2.0151
Testing Model 841 took 1 mins and 56 secs

Testing Model 842
[20, 14, 21, 22, 20, 10, 13, 21, 13, 22, 19, 23, 22, 22, 17, 22, 20, 21, 21, 20]
FLOPs = 2035.30M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.73 | Loss = 2.0125
Testing Model 842 took 2 mins and 0 secs

Testing Model 843
[20, 22, 21, 22, 20, 10, 20, 21, 16, 12, 16, 20, 22, 12, 16, 22, 20, 21, 21, 20]
FLOPs = 1989.94M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.73 | Loss = 2.0131
Testing Model 843 took 1 mins and 56 secs

Testing Model 844
[20, 22, 16, 22, 21, 10, 20, 19, 16, 12, 16, 20, 22, 22, 26, 22, 15, 21, 22, 20]
FLOPs = 2029.13M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.82 | Loss = 2.0116
Testing Model 844 took 1 mins and 58 secs

Testing Model 845
[20, 22, 21, 22, 20, 10, 13, 19, 16, 22, 19, 18, 22, 12, 26, 18, 15, 21, 21, 20]
FLOPs = 2008.05M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.77 | Loss = 2.0112
Testing Model 845 took 1 mins and 56 secs

Testing Model 846
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 12, 26, 25, 15, 21, 22, 21]
FLOPs = 2044.57M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.73 | Loss = 2.0171
Testing Model 846 took 1 mins and 54 secs

Testing Model 847
[20, 22, 16, 22, 21, 22, 20, 19, 16, 12, 16, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 2001.42M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.74 | Loss = 2.0132
Testing Model 847 took 1 mins and 55 secs

Testing Model 848
[14, 22, 16, 22, 20, 22, 13, 21, 16, 22, 16, 18, 22, 22, 14, 18, 15, 21, 21, 21]
FLOPs = 1971.52M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.69 | Loss = 2.0187
Testing Model 848 took 1 mins and 58 secs

Testing Model 849
[14, 22, 20, 22, 20, 20, 20, 19, 13, 12, 16, 18, 22, 12, 26, 18, 20, 21, 22, 21]
FLOPs = 2018.02M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.72 | Loss = 2.0142
Testing Model 849 took 1 mins and 58 secs

Testing Model 850
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 17, 25, 20, 21, 20, 21]
FLOPs = 1953.06M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.66 | Loss = 2.0175
Testing Model 850 took 1 mins and 54 secs

> Select
Iteration 16 : Showing Top 50 results
1. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.640439987182617
2. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 17. 25. 20. 21.
 20. 21.] 
Reward = 15.62641716003418
3. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 21. 21.] 
Reward = 15.616037368774414
4. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.595078468322754
5. [14. 14. 18. 22. 21. 22. 20. 19. 16. 22. 16. 15. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.582011222839355
6. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.574835777282715
7. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 21. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.567974090576172
8. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 17. 25. 20. 21.
 21. 21.] 
Reward = 15.56768798828125
9. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 21. 20.] 
Reward = 15.564767837524414
10. [20. 22. 20. 17. 20. 20. 20. 21. 13. 12. 16. 23. 22. 12. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.564648628234863
11. [14. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  8. 17. 25. 20. 21.
 21. 21.] 
Reward = 15.562047958374023
12. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 18. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.556252479553223
13. [14. 22. 18. 17. 21. 22. 21. 21. 16. 22. 23. 15. 22. 12. 16. 18. 15. 21.
 22. 21.] 
Reward = 15.553827285766602
14. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.54874038696289
15. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 20. 21.] 
Reward = 15.548630714416504
16. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22.  8. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.547995567321777
17. [20. 14. 21. 22. 21. 10. 20. 19. 16. 12. 16. 20. 22. 22. 26. 18. 15. 17.
 22. 21.] 
Reward = 15.545217514038086
18. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.539837837219238
19. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.536077499389648
20. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.534582138061523
21. [20. 22. 21. 17. 20. 10. 13. 21. 16. 22. 23. 20. 22. 22. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.531606674194336
22. [20. 23. 20. 17. 20. 20. 20. 19. 13. 12. 16. 23. 18. 18. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.531522750854492
23. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22.  9. 26. 22. 15. 21.
 21. 21.] 
Reward = 15.5304536819458
24. [20. 22. 20. 22. 20. 10. 20. 21. 16. 12. 19. 20. 22. 12. 16. 22. 20. 17.
 20. 20.] 
Reward = 15.51479721069336
25. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22.  8. 26. 15. 15. 21.
 22. 21.] 
Reward = 15.514487266540527
26. [14. 14. 16. 22. 21. 22. 20. 19. 16. 11. 16. 20. 22. 22. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.506855010986328
27. [20. 22. 21. 22. 20. 10. 13. 21. 16. 11. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.504549980163574
28. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 22. 21.] 
Reward = 15.503497123718262
29. [20. 14. 16. 22. 21. 22. 13. 19. 13. 22. 19. 20. 22.  9. 26. 22. 20. 17.
 20. 21.] 
Reward = 15.494070053100586
30. [20. 14. 16. 22. 21. 22. 14. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.489802360534668
31. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.487140655517578
32. [20. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  9. 16. 22. 20. 21.
 21. 21.] 
Reward = 15.483205795288086
33. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22. 12. 26. 22. 20. 21.
 20. 21.] 
Reward = 15.481279373168945
34. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
35. [20. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.471687316894531
36. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 21. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.470913887023926
37. [20. 14. 16. 22. 21. 22. 13. 21. 16. 12. 19. 23. 22. 22. 17. 22. 15. 21.
 21. 20.] 
Reward = 15.465348243713379
38. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 19. 15. 17.
 20. 18.] 
Reward = 15.46304988861084
39. [20. 22. 20. 17. 22. 20. 21. 22. 16. 22. 23. 20. 22. 12. 13. 18. 15. 17.
 20. 18.] 
Reward = 15.457979202270508
40. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 26. 18. 20. 21.
 20. 21.] 
Reward = 15.45567512512207
41. [20. 22. 16. 17. 20. 20. 20. 19. 16. 22. 23. 23. 22. 12. 16. 25. 15. 17.
 20. 21.] 
Reward = 15.453691482543945
42. [14. 14. 16. 22. 21. 22. 13. 19. 16. 22. 16. 20. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.453227043151855
43. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 21.] 
Reward = 15.448393821716309
44. [20. 14. 20. 22. 21. 22. 13. 19. 13. 12. 23. 20. 22. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.44775390625
45. [17. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 24. 20.] 
Reward = 15.44729995727539
46. [20. 22. 21. 22. 21. 10. 13. 19. 16. 12. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 20.] 
Reward = 15.444304466247559
47. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 28. 15. 20. 21.
 21. 17.] 
Reward = 15.443835258483887
48. [14. 14. 16. 22. 21. 22. 21. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.442277908325195
49. [20. 22. 21. 22. 20. 20. 13. 21. 16. 12. 19. 20. 22. 12. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.433782577514648
50. [20. 22. 20. 22. 20. 10. 20. 19. 16. 12. 19. 23. 18. 18. 16. 22. 15. 21.
 20. 20.] 
Reward = 15.431556701660156
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 16 took 1 hour 37 mins 6 secs



Testing Model 851
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 25, 18, 15, 21, 21, 21]
FLOPs = 1950.24M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.69 | Loss = 2.0174
Testing Model 851 took 1 mins and 54 secs

Testing Model 852
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 10, 23, 22, 18, 17, 25, 15, 21, 21, 21]
FLOPs = 1957.14M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.65 | Loss = 2.0202
Testing Model 852 took 1 mins and 54 secs

Testing Model 853
[20, 22, 20, 17, 20, 20, 28, 21, 12, 12, 16, 23, 22, 12, 16, 22, 20, 21, 20, 21]
FLOPs = 2011.51M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.76 | Loss = 2.0126
Testing Model 853 took 1 mins and 55 secs

Testing Model 854
[30, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 21, 21]
FLOPs = 2035.14M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.78 | Loss = 2.0150
Testing Model 854 took 1 mins and 56 secs

Testing Model 855
[20, 22, 20, 17, 20, 20, 20, 21, 13, 12, 25, 23, 20, 12, 16, 28, 20, 21, 20, 21]
FLOPs = 2046.33M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.80 | Loss = 2.0113
Testing Model 855 took 1 mins and 53 secs

Testing Model 856
[6, 22, 21, 22, 20, 24, 13, 21, 16, 12, 19, 20, 22, 21, 16, 22, 15, 17, 21, 20]
FLOPs = 1975.97M
Top-1 Accuracy = 54.65 | Top-5 Accuracy = 78.28 | Loss = 2.0431
Testing Model 856 took 1 mins and 56 secs

Testing Model 857
[14, 14, 16, 22, 21, 22, 20, 20, 13, 22, 16, 20, 22, 12, 17, 25, 20, 21, 20, 21]
FLOPs = 1960.60M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.73 | Loss = 2.0162
Testing Model 857 took 1 mins and 56 secs

Testing Model 858
[20, 22, 21, 22, 20, 10, 13, 21, 6, 15, 19, 20, 22, 21, 16, 30, 15, 17, 21, 20]
FLOPs = 1988.62M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.74 | Loss = 2.0132
Testing Model 858 took 1 mins and 55 secs

Testing Model 859
[14, 14, 21, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 17, 25, 15, 21, 21, 21]
FLOPs = 2017.16M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.71 | Loss = 2.0168
Testing Model 859 took 1 mins and 54 secs

Testing Model 860
[20, 29, 21, 22, 20, 10, 13, 21, 16, 12, 19, 20, 22, 21, 16, 22, 15, 17, 21, 20]
FLOPs = 2022.07M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.75 | Loss = 2.0111
Testing Model 860 took 1 mins and 59 secs

Testing Model 861
[20, 23, 21, 22, 20, 10, 13, 21, 16, 12, 19, 20, 22, 22, 14, 22, 15, 17, 21, 20]
FLOPs = 1961.13M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.75 | Loss = 2.0140
Testing Model 861 took 1 mins and 55 secs

Testing Model 862
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 24, 22, 12, 26, 18, 15, 21, 21, 21]
FLOPs = 1991.06M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.72 | Loss = 2.0160
Testing Model 862 took 1 mins and 56 secs

Testing Model 863
[20, 22, 20, 17, 20, 29, 21, 21, 16, 22, 23, 20, 22, 4, 16, 18, 15, 17, 20, 18]
FLOPs = 1993.10M
Top-1 Accuracy = 55.05 | Top-5 Accuracy = 78.58 | Loss = 2.0222
Testing Model 863 took 1 mins and 57 secs

Testing Model 864
[29, 22, 21, 22, 20, 10, 13, 21, 8, 12, 19, 20, 22, 21, 16, 22, 15, 17, 21, 20]
FLOPs = 1959.24M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.71 | Loss = 2.0119
Testing Model 864 took 2 mins and 2 secs

Testing Model 865
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 19, 22, 22, 21, 16, 22, 13, 17, 21, 20]
FLOPs = 1960.45M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.69 | Loss = 2.0137
Testing Model 865 took 1 mins and 57 secs

Testing Model 866
[14, 14, 16, 22, 29, 22, 20, 19, 6, 22, 16, 20, 22, 12, 17, 25, 30, 21, 11, 21]
FLOPs = 1999.00M
Top-1 Accuracy = 54.80 | Top-5 Accuracy = 78.36 | Loss = 2.0391
Testing Model 866 took 1 mins and 56 secs

Testing Model 867
[20, 22, 21, 22, 20, 10, 13, 21, 20, 12, 19, 20, 22, 21, 16, 22, 15, 17, 21, 20]
FLOPs = 1981.55M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.78 | Loss = 2.0126
Testing Model 867 took 1 mins and 56 secs

Testing Model 868
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 21, 25]
FLOPs = 1993.48M
Top-1 Accuracy = 55.27 | Top-5 Accuracy = 78.76 | Loss = 2.0151
Testing Model 868 took 1 mins and 55 secs

Testing Model 869
[20, 22, 20, 17, 20, 20, 20, 21, 13, 12, 16, 23, 22, 12, 16, 22, 27, 21, 20, 21]
FLOPs = 2001.95M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.75 | Loss = 2.0132
Testing Model 869 took 1 mins and 56 secs

Testing Model 870
[14, 14, 22, 22, 21, 22, 20, 19, 6, 22, 16, 23, 22, 12, 17, 25, 15, 21, 21, 21]
FLOPs = 1995.79M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.72 | Loss = 2.0163
Testing Model 870 took 1 mins and 55 secs

Testing Model 871
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 19, 20, 30, 22, 14, 22, 15, 17, 21, 20]
FLOPs = 2019.44M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.72 | Loss = 2.0130
Testing Model 871 took 1 mins and 57 secs

Testing Model 872
[20, 22, 21, 22, 26, 10, 13, 21, 16, 12, 19, 20, 22, 22, 14, 22, 15, 17, 21, 20]
FLOPs = 1994.24M
Top-1 Accuracy = 55.24 | Top-5 Accuracy = 78.78 | Loss = 2.0126
Testing Model 872 took 2 mins and 0 secs

Testing Model 873
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 19, 20, 22, 21, 25, 22, 15, 17, 21, 20]
FLOPs = 2021.00M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.79 | Loss = 2.0116
Testing Model 873 took 1 mins and 59 secs

Testing Model 874
[14, 14, 16, 22, 16, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 20, 24]
FLOPs = 1950.50M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.74 | Loss = 2.0186
Testing Model 874 took 1 mins and 55 secs

Testing Model 875
[14, 14, 16, 22, 21, 22, 20, 16, 13, 22, 16, 20, 22, 12, 17, 25, 20, 21, 30, 18]
FLOPs = 2000.08M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.63 | Loss = 2.0197
Testing Model 875 took 2 mins and 0 secs

Testing Model 876
[14, 22, 16, 22, 20, 20, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 2011.31M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.73 | Loss = 2.0157
Testing Model 876 took 1 mins and 57 secs

Testing Model 877
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 8, 17, 25, 20, 21, 22, 21]
FLOPs = 1991.00M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.59 | Loss = 2.0193
Testing Model 877 took 1 mins and 55 secs

Testing Model 878
[14, 14, 18, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 1977.58M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.73 | Loss = 2.0170
Testing Model 878 took 1 mins and 53 secs

Testing Model 879
[14, 14, 16, 22, 21, 22, 21, 21, 16, 22, 23, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 2019.11M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.76 | Loss = 2.0168
Testing Model 879 took 1 mins and 58 secs

Testing Model 880
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 17, 25, 20, 21, 20, 21]
FLOPs = 1977.41M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.72 | Loss = 2.0171
Testing Model 880 took 1 mins and 54 secs

Testing Model 881
[20, 14, 21, 22, 21, 22, 13, 19, 16, 22, 16, 20, 22, 22, 17, 25, 15, 17, 20, 21]
FLOPs = 2022.57M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.78 | Loss = 2.0126
Testing Model 881 took 1 mins and 53 secs

Testing Model 882
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 17, 25, 20, 21, 20, 21]
FLOPs = 1970.19M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.69 | Loss = 2.0160
Testing Model 882 took 1 mins and 57 secs

Testing Model 883
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 8, 17, 25, 20, 21, 20, 21]
FLOPs = 1974.56M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.61 | Loss = 2.0198
Testing Model 883 took 1 mins and 54 secs

Testing Model 884
[20, 22, 20, 22, 20, 10, 13, 21, 16, 12, 19, 23, 22, 12, 16, 22, 20, 21, 21, 20]
FLOPs = 1977.74M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.75 | Loss = 2.0119
Testing Model 884 took 1 mins and 55 secs

Testing Model 885
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 26, 25, 20, 21, 21, 21]
FLOPs = 2028.38M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.73 | Loss = 2.0170
Testing Model 885 took 1 mins and 55 secs

Testing Model 886
[20, 22, 21, 22, 20, 22, 13, 21, 16, 12, 16, 20, 22, 12, 14, 22, 15, 21, 21, 20]
FLOPs = 1976.21M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.74 | Loss = 2.0137
Testing Model 886 took 2 mins and 0 secs

Testing Model 887
[20, 22, 20, 22, 20, 20, 13, 21, 16, 22, 23, 20, 22, 12, 16, 18, 15, 17, 20, 18]
FLOPs = 1987.14M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.66 | Loss = 2.0168
Testing Model 887 took 1 mins and 56 secs

Testing Model 888
[14, 14, 21, 22, 21, 10, 20, 19, 16, 22, 16, 20, 22, 22, 17, 25, 15, 17, 21, 21]
FLOPs = 1975.04M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.64 | Loss = 2.0169
Testing Model 888 took 1 mins and 53 secs

Testing Model 889
[20, 22, 16, 22, 21, 20, 20, 21, 16, 22, 23, 20, 22, 12, 17, 18, 20, 17, 20, 21]
FLOPs = 2042.30M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.75 | Loss = 2.0139
Testing Model 889 took 1 mins and 57 secs

Testing Model 890
[14, 22, 16, 22, 21, 22, 20, 21, 13, 12, 16, 20, 22, 22, 17, 25, 15, 21, 21, 20]
FLOPs = 2023.00M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.72 | Loss = 2.0146
Testing Model 890 took 1 mins and 55 secs

Testing Model 891
[14, 22, 21, 22, 20, 22, 20, 21, 16, 12, 16, 20, 22, 12, 26, 22, 15, 17, 21, 20]
FLOPs = 2042.98M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.66 | Loss = 2.0178
Testing Model 891 took 1 mins and 56 secs

Testing Model 892
[14, 22, 20, 17, 20, 22, 20, 21, 16, 22, 23, 20, 22, 12, 17, 18, 15, 21, 20, 21]
FLOPs = 1991.12M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.73 | Loss = 2.0162
Testing Model 892 took 1 mins and 57 secs

Testing Model 893
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 12, 16, 25, 15, 21, 20, 18]
FLOPs = 2032.19M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.71 | Loss = 2.0139
Testing Model 893 took 1 mins and 56 secs

Testing Model 894
[14, 14, 18, 22, 21, 22, 20, 19, 16, 22, 16, 15, 22, 12, 26, 25, 15, 21, 22, 21]
FLOPs = 2008.76M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.68 | Loss = 2.0170
Testing Model 894 took 1 mins and 58 secs

Testing Model 895
[14, 14, 21, 22, 20, 22, 20, 19, 13, 22, 19, 23, 22, 8, 17, 25, 15, 21, 21, 20]
FLOPs = 2002.00M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.67 | Loss = 2.0155
Testing Model 895 took 1 mins and 54 secs

Testing Model 896
[14, 14, 16, 22, 21, 22, 20, 21, 16, 22, 16, 23, 22, 12, 26, 22, 15, 21, 21, 21]
FLOPs = 2027.58M
Top-1 Accuracy = 55.27 | Top-5 Accuracy = 78.72 | Loss = 2.0153
Testing Model 896 took 1 mins and 58 secs

Testing Model 897
[14, 22, 21, 22, 20, 22, 20, 21, 16, 22, 16, 20, 22, 12, 16, 22, 15, 17, 20, 20]
FLOPs = 2026.51M
Top-1 Accuracy = 55.11 | Top-5 Accuracy = 78.63 | Loss = 2.0171
Testing Model 897 took 2 mins and 0 secs

Testing Model 898
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 17, 25, 20, 21, 21, 21]
FLOPs = 1960.91M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.67 | Loss = 2.0170
Testing Model 898 took 1 mins and 59 secs

Testing Model 899
[20, 14, 18, 22, 20, 20, 21, 21, 16, 22, 23, 20, 22, 12, 26, 18, 15, 21, 22, 18]
FLOPs = 2047.18M
Top-1 Accuracy = 55.24 | Top-5 Accuracy = 78.77 | Loss = 2.0156
Testing Model 899 took 1 mins and 54 secs

Testing Model 900
[14, 22, 18, 17, 20, 20, 20, 21, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 22, 18]
FLOPs = 1956.30M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.63 | Loss = 2.0193
Testing Model 900 took 1 mins and 55 secs

> Select
Iteration 17 : Showing Top 50 results
1. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 25. 18. 15. 21.
 21. 21.] 
Reward = 15.652791976928711
2. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.640439987182617
3. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 17. 25. 20. 21.
 20. 21.] 
Reward = 15.62641716003418
4. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 21. 21.] 
Reward = 15.616037368774414
5. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.595078468322754
6. [14. 14. 16. 22. 16. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 20. 24.] 
Reward = 15.585054397583008
7. [14. 14. 18. 22. 21. 22. 20. 19. 16. 22. 16. 15. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.582011222839355
8. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.574835777282715
9. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 21. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.567974090576172
10. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 17. 25. 20. 21.
 21. 21.] 
Reward = 15.56768798828125
11. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 21. 20.] 
Reward = 15.564767837524414
12. [20. 22. 20. 17. 20. 20. 20. 21. 13. 12. 16. 23. 22. 12. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.564648628234863
13. [14. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  8. 17. 25. 20. 21.
 21. 21.] 
Reward = 15.562047958374023
14. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 18. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.556252479553223
15. [14. 22. 18. 17. 21. 22. 21. 21. 16. 22. 23. 15. 22. 12. 16. 18. 15. 21.
 22. 21.] 
Reward = 15.553827285766602
16. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.54874038696289
17. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 20. 21.] 
Reward = 15.548630714416504
18. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22.  8. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.547995567321777
19. [20. 14. 21. 22. 21. 10. 20. 19. 16. 12. 16. 20. 22. 22. 26. 18. 15. 17.
 22. 21.] 
Reward = 15.545217514038086
20. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.539837837219238
21. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.536077499389648
22. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.534582138061523
23. [20. 22. 21. 17. 20. 10. 13. 21. 16. 22. 23. 20. 22. 22. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.531606674194336
24. [20. 23. 20. 17. 20. 20. 20. 19. 13. 12. 16. 23. 18. 18. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.531522750854492
25. [20. 23. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 21. 20.] 
Reward = 15.531478881835938
26. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22.  9. 26. 22. 15. 21.
 21. 21.] 
Reward = 15.5304536819458
27. [20. 22. 20. 22. 20. 10. 20. 21. 16. 12. 19. 20. 22. 12. 16. 22. 20. 17.
 20. 20.] 
Reward = 15.51479721069336
28. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22.  8. 26. 15. 15. 21.
 22. 21.] 
Reward = 15.514487266540527
29. [14. 14. 16. 22. 21. 22. 20. 19. 16. 11. 16. 20. 22. 22. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.506855010986328
30. [20. 22. 21. 22. 20. 10. 13. 21. 16. 11. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.504549980163574
31. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 22. 21.] 
Reward = 15.503497123718262
32. [20. 14. 16. 22. 21. 22. 13. 19. 13. 22. 19. 20. 22.  9. 26. 22. 20. 17.
 20. 21.] 
Reward = 15.494070053100586
33. [20. 14. 16. 22. 21. 22. 14. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.489802360534668
34. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.487140655517578
35. [20. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  9. 16. 22. 20. 21.
 21. 21.] 
Reward = 15.483205795288086
36. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22. 12. 26. 22. 20. 21.
 20. 21.] 
Reward = 15.481279373168945
37. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
38. [20. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.471687316894531
39. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 21. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.470913887023926
40. [20. 14. 16. 22. 21. 22. 13. 21. 16. 12. 19. 23. 22. 22. 17. 22. 15. 21.
 21. 20.] 
Reward = 15.465348243713379
41. [14. 14. 16. 22. 21. 22. 20. 20. 13. 22. 16. 20. 22. 12. 17. 25. 20. 21.
 20. 21.] 
Reward = 15.46469783782959
42. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 19. 15. 17.
 20. 18.] 
Reward = 15.46304988861084
43. [20. 22. 20. 17. 22. 20. 21. 22. 16. 22. 23. 20. 22. 12. 13. 18. 15. 17.
 20. 18.] 
Reward = 15.457979202270508
44. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 26. 18. 20. 21.
 20. 21.] 
Reward = 15.45567512512207
45. [20. 22. 16. 17. 20. 20. 20. 19. 16. 22. 23. 23. 22. 12. 16. 25. 15. 17.
 20. 21.] 
Reward = 15.453691482543945
46. [14. 14. 16. 22. 21. 22. 13. 19. 16. 22. 16. 20. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.453227043151855
47. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 21.] 
Reward = 15.448393821716309
48. [20. 14. 20. 22. 21. 22. 13. 19. 13. 12. 23. 20. 22. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.44775390625
49. [17. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 24. 20.] 
Reward = 15.44729995727539
50. [20. 22. 21. 22. 21. 10. 13. 19. 16. 12. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 20.] 
Reward = 15.444304466247559
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 17 took 1 hour 37 mins 29 secs



Testing Model 901
[14, 26, 16, 22, 21, 22, 20, 19, 1, 14, 16, 23, 22, 8, 13, 25, 20, 21, 21, 21]
FLOPs = 1967.27M
Top-1 Accuracy = 54.98 | Top-5 Accuracy = 78.61 | Loss = 2.0223
Testing Model 901 took 1 mins and 58 secs

Testing Model 902
[14, 14, 16, 22, 21, 30, 20, 19, 13, 22, 16, 20, 22, 12, 17, 25, 20, 21, 20, 21]
FLOPs = 2017.19M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.69 | Loss = 2.0163
Testing Model 902 took 1 mins and 55 secs

Testing Model 903
[14, 14, 16, 22, 21, 22, 20, 24, 16, 22, 16, 20, 22, 12, 25, 18, 15, 21, 21, 21]
FLOPs = 1988.06M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.71 | Loss = 2.0166
Testing Model 903 took 1 mins and 53 secs

Testing Model 904
[16, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 29, 12, 17, 25, 20, 21, 20, 21]
FLOPs = 2021.51M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.77 | Loss = 2.0140
Testing Model 904 took 1 mins and 54 secs

Testing Model 905
[14, 14, 16, 22, 21, 26, 23, 19, 13, 22, 16, 20, 22, 12, 17, 25, 20, 21, 20, 21]
FLOPs = 2004.32M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.69 | Loss = 2.0161
Testing Model 905 took 1 mins and 56 secs

Testing Model 906
[14, 14, 16, 22, 23, 22, 20, 19, 13, 22, 16, 20, 22, 12, 17, 25, 25, 21, 20, 18]
FLOPs = 1980.76M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.64 | Loss = 2.0208
Testing Model 906 took 1 mins and 55 secs

Testing Model 907
[14, 14, 16, 22, 16, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 20, 21, 20, 24]
FLOPs = 1984.37M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.72 | Loss = 2.0188
Testing Model 907 took 1 mins and 55 secs

Testing Model 908
[20, 27, 21, 22, 16, 10, 13, 21, 16, 12, 19, 20, 22, 21, 16, 22, 15, 17, 21, 20]
FLOPs = 1980.19M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.75 | Loss = 2.0146
Testing Model 908 took 2 mins and 2 secs

Testing Model 909
[14, 14, 16, 22, 24, 22, 20, 19, 16, 22, 16, 20, 22, 12, 25, 18, 15, 21, 21, 21]
FLOPs = 1970.04M
Top-1 Accuracy = 55.26 | Top-5 Accuracy = 78.71 | Loss = 2.0172
Testing Model 909 took 1 mins and 55 secs

Testing Model 910
[20, 22, 21, 22, 20, 10, 13, 21, 16, 12, 19, 20, 22, 25, 16, 22, 29, 17, 9, 20]
FLOPs = 2011.37M
Top-1 Accuracy = 54.56 | Top-5 Accuracy = 78.37 | Loss = 2.0404
Testing Model 910 took 1 mins and 57 secs

Testing Model 911
[14, 14, 16, 22, 21, 22, 24, 19, 16, 22, 16, 20, 22, 20, 25, 18, 15, 21, 21, 21]
FLOPs = 2030.02M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.71 | Loss = 2.0203
Testing Model 911 took 1 mins and 53 secs

Testing Model 912
[22, 14, 16, 22, 21, 30, 20, 12, 16, 22, 16, 24, 22, 12, 26, 18, 15, 21, 21, 21]
FLOPs = 2047.08M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.76 | Loss = 2.0146
Testing Model 912 took 1 mins and 53 secs

Testing Model 913
[15, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 17, 25, 20, 21, 20, 21]
FLOPs = 1957.98M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.74 | Loss = 2.0148
Testing Model 913 took 1 mins and 55 secs

Testing Model 914
[30, 22, 21, 22, 20, 10, 16, 21, 21, 12, 19, 20, 22, 21, 16, 22, 9, 17, 21, 20]
FLOPs = 2027.75M
Top-1 Accuracy = 55.01 | Top-5 Accuracy = 78.67 | Loss = 2.0160
Testing Model 914 took 1 mins and 57 secs

Testing Model 915
[14, 14, 16, 22, 21, 25, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 28, 21]
FLOPs = 2043.65M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.72 | Loss = 2.0165
Testing Model 915 took 1 mins and 58 secs

Testing Model 916
[14, 14, 16, 22, 21, 22, 20, 9, 16, 22, 16, 20, 22, 12, 25, 18, 15, 28, 21, 21]
FLOPs = 1957.92M
Top-1 Accuracy = 55.03 | Top-5 Accuracy = 78.64 | Loss = 2.0229
Testing Model 916 took 1 mins and 55 secs

Testing Model 917
[14, 14, 16, 22, 4, 22, 20, 19, 13, 22, 16, 23, 22, 12, 30, 25, 15, 21, 21, 21]
FLOPs = 1983.39M
Top-1 Accuracy = 54.94 | Top-5 Accuracy = 78.53 | Loss = 2.0256
Testing Model 917 took 1 mins and 55 secs

Testing Model 918
[14, 14, 16, 22, 21, 22, 20, 28, 13, 22, 16, 16, 22, 8, 17, 25, 20, 21, 21, 21]
FLOPs = 1984.70M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.60 | Loss = 2.0176
Testing Model 918 took 1 mins and 54 secs

Testing Model 919
[20, 22, 20, 25, 7, 20, 21, 21, 16, 22, 23, 20, 22, 12, 9, 18, 15, 17, 20, 18]
FLOPs = 1985.50M
Top-1 Accuracy = 54.99 | Top-5 Accuracy = 78.68 | Loss = 2.0232
Testing Model 919 took 2 mins and 5 secs

Testing Model 920
[14, 28, 18, 22, 21, 22, 20, 19, 16, 22, 12, 19, 22, 12, 0, 18, 15, 21, 22, 21]
FLOPs = 1959.84M
Top-1 Accuracy = 54.49 | Top-5 Accuracy = 78.33 | Loss = 2.0528
Testing Model 920 took 1 mins and 57 secs

Testing Model 921
[14, 22, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 8, 15, 21, 20, 21]
FLOPs = 1976.39M
Top-1 Accuracy = 54.90 | Top-5 Accuracy = 78.64 | Loss = 2.0251
Testing Model 921 took 1 mins and 56 secs

Testing Model 922
[14, 14, 18, 22, 21, 22, 20, 19, 16, 22, 16, 15, 29, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 2014.67M
Top-1 Accuracy = 55.26 | Top-5 Accuracy = 78.68 | Loss = 2.0157
Testing Model 922 took 1 mins and 57 secs

Testing Model 923
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 22, 20, 22, 14, 25, 18, 15, 21, 21, 21]
FLOPs = 2000.69M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.67 | Loss = 2.0161
Testing Model 923 took 1 mins and 54 secs

Testing Model 924
[14, 22, 18, 29, 21, 22, 20, 7, 4, 22, 16, 15, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 2030.61M
Top-1 Accuracy = 55.00 | Top-5 Accuracy = 78.61 | Loss = 2.0212
Testing Model 924 took 1 mins and 59 secs

Testing Model 925
[14, 14, 18, 22, 21, 22, 20, 19, 16, 27, 16, 15, 22, 12, 26, 18, 15, 21, 22, 18]
FLOPs = 1970.97M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.62 | Loss = 2.0208
Testing Model 925 took 1 mins and 53 secs

Testing Model 926
[14, 22, 16, 22, 21, 22, 21, 21, 13, 22, 16, 23, 22, 8, 16, 18, 20, 21, 21, 21]
FLOPs = 2012.29M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.67 | Loss = 2.0186
Testing Model 926 took 2 mins and 1 secs

Testing Model 927
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 25, 25, 15, 21, 20, 21]
FLOPs = 1995.10M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.67 | Loss = 2.0189
Testing Model 927 took 1 mins and 56 secs

Testing Model 928
[14, 14, 16, 22, 16, 22, 20, 19, 16, 22, 16, 23, 22, 12, 26, 25, 15, 21, 20, 21]
FLOPs = 2002.25M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.68 | Loss = 2.0176
Testing Model 928 took 1 mins and 57 secs

Testing Model 929
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 12, 17, 25, 15, 21, 21, 24]
FLOPs = 1993.82M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.76 | Loss = 2.0158
Testing Model 929 took 1 mins and 54 secs

Testing Model 930
[14, 14, 16, 22, 16, 22, 20, 19, 16, 22, 16, 23, 22, 12, 26, 18, 15, 21, 21, 21]
FLOPs = 1957.39M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.70 | Loss = 2.0207
Testing Model 930 took 1 mins and 57 secs

Testing Model 931
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 20, 21, 20, 21]
FLOPs = 1984.95M
Top-1 Accuracy = 55.24 | Top-5 Accuracy = 78.67 | Loss = 2.0166
Testing Model 931 took 1 mins and 56 secs

Testing Model 932
[14, 14, 21, 22, 21, 22, 13, 21, 16, 22, 19, 20, 22, 21, 16, 25, 20, 17, 21, 20]
FLOPs = 2049.45M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.65 | Loss = 2.0188
Testing Model 932 took 1 mins and 57 secs

Testing Model 933
[20, 22, 20, 22, 21, 22, 21, 19, 16, 22, 16, 20, 22, 12, 16, 25, 15, 17, 20, 18]
FLOPs = 2046.98M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.69 | Loss = 2.0162
Testing Model 933 took 2 mins and 0 secs

Testing Model 934
[14, 22, 16, 22, 20, 20, 20, 19, 16, 22, 23, 20, 22, 12, 16, 18, 15, 17, 20, 24]
FLOPs = 1974.49M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.74 | Loss = 2.0161
Testing Model 934 took 1 mins and 56 secs

Testing Model 935
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 26, 25, 15, 21, 20, 21]
FLOPs = 1986.66M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.69 | Loss = 2.0171
Testing Model 935 took 1 mins and 57 secs

Testing Model 936
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 8, 17, 25, 20, 21, 21, 24]
FLOPs = 1983.37M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.62 | Loss = 2.0185
Testing Model 936 took 1 mins and 59 secs

Testing Model 937
[14, 22, 21, 22, 20, 10, 20, 19, 16, 22, 16, 20, 22, 12, 17, 22, 20, 21, 21, 20]
FLOPs = 2015.87M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.72 | Loss = 2.0144
Testing Model 937 took 1 mins and 57 secs

Testing Model 938
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 26, 25, 15, 21, 20, 24]
FLOPs = 2036.32M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.74 | Loss = 2.0161
Testing Model 938 took 1 mins and 55 secs

Testing Model 939
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 26, 25, 20, 21, 20, 24]
FLOPs = 2045.84M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.74 | Loss = 2.0161
Testing Model 939 took 1 mins and 55 secs

Testing Model 940
[14, 22, 21, 22, 20, 22, 13, 21, 16, 22, 19, 20, 22, 12, 16, 18, 15, 21, 21, 20]
FLOPs = 2014.55M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.70 | Loss = 2.0143
Testing Model 940 took 2 mins and 5 secs

Testing Model 941
[14, 22, 21, 22, 21, 10, 13, 19, 16, 22, 19, 20, 22, 21, 16, 22, 15, 21, 21, 20]
FLOPs = 2015.08M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.74 | Loss = 2.0144
Testing Model 941 took 1 mins and 56 secs

Testing Model 942
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 21, 24]
FLOPs = 1984.23M
Top-1 Accuracy = 55.25 | Top-5 Accuracy = 78.77 | Loss = 2.0156
Testing Model 942 took 1 mins and 54 secs

Testing Model 943
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 25, 25, 15, 21, 21, 21]
FLOPs = 2002.95M
Top-1 Accuracy = 55.25 | Top-5 Accuracy = 78.69 | Loss = 2.0181
Testing Model 943 took 1 mins and 55 secs

Testing Model 944
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 12, 17, 25, 15, 21, 20, 24]
FLOPs = 1985.97M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.72 | Loss = 2.0168
Testing Model 944 took 1 mins and 56 secs

Testing Model 945
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 25, 20, 21, 20, 21]
FLOPs = 2037.66M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.66 | Loss = 2.0165
Testing Model 945 took 1 mins and 53 secs

Testing Model 946
[14, 14, 16, 22, 16, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 21, 24]
FLOPs = 1958.35M
Top-1 Accuracy = 55.27 | Top-5 Accuracy = 78.78 | Loss = 2.0162
Testing Model 946 took 1 mins and 55 secs

Testing Model 947
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 20, 24]
FLOPs = 1976.39M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.71 | Loss = 2.0179
Testing Model 947 took 1 mins and 51 secs

Testing Model 948
[14, 14, 18, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 17, 25, 15, 21, 21, 21]
FLOPs = 1977.87M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.71 | Loss = 2.0146
Testing Model 948 took 1 mins and 57 secs

Testing Model 949
[14, 14, 18, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 21, 21]
FLOPs = 1985.43M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.70 | Loss = 2.0168
Testing Model 949 took 1 mins and 57 secs

Testing Model 950
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 25, 18, 20, 21, 20, 21]
FLOPs = 1976.26M
Top-1 Accuracy = 55.24 | Top-5 Accuracy = 78.67 | Loss = 2.0154
Testing Model 950 took 1 mins and 52 secs

> Select
Iteration 18 : Showing Top 50 results
1. [14. 14. 16. 22. 16. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 24.] 
Reward = 15.66705322265625
2. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 25. 18. 15. 21.
 21. 21.] 
Reward = 15.652791976928711
3. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.640439987182617
4. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 17. 25. 20. 21.
 20. 21.] 
Reward = 15.62641716003418
5. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 21. 21.] 
Reward = 15.616037368774414
6. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.595078468322754
7. [14. 14. 16. 22. 16. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 20. 24.] 
Reward = 15.585054397583008
8. [14. 14. 18. 22. 21. 22. 20. 19. 16. 22. 16. 15. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.582011222839355
9. [15. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 17. 25. 20. 21.
 20. 21.] 
Reward = 15.577486038208008
10. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.574835777282715
11. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 21. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.567974090576172
12. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 17. 25. 20. 21.
 21. 21.] 
Reward = 15.56768798828125
13. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 21. 20.] 
Reward = 15.564767837524414
14. [20. 22. 20. 17. 20. 20. 20. 21. 13. 12. 16. 23. 22. 12. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.564648628234863
15. [14. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  8. 17. 25. 20. 21.
 21. 21.] 
Reward = 15.562047958374023
16. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 18. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.556252479553223
17. [14. 22. 18. 17. 21. 22. 21. 21. 16. 22. 23. 15. 22. 12. 16. 18. 15. 21.
 22. 21.] 
Reward = 15.553827285766602
18. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.54874038696289
19. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 20. 21.] 
Reward = 15.548630714416504
20. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22.  8. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.547995567321777
21. [20. 14. 21. 22. 21. 10. 20. 19. 16. 12. 16. 20. 22. 22. 26. 18. 15. 17.
 22. 21.] 
Reward = 15.545217514038086
22. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.539837837219238
23. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.536077499389648
24. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.534582138061523
25. [20. 22. 21. 17. 20. 10. 13. 21. 16. 22. 23. 20. 22. 22. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.531606674194336
26. [20. 23. 20. 17. 20. 20. 20. 19. 13. 12. 16. 23. 18. 18. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.531522750854492
27. [20. 23. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 21. 20.] 
Reward = 15.531478881835938
28. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22.  9. 26. 22. 15. 21.
 21. 21.] 
Reward = 15.5304536819458
29. [14. 14. 16. 22. 24. 22. 20. 19. 16. 22. 16. 20. 22. 12. 25. 18. 15. 21.
 21. 21.] 
Reward = 15.516618728637695
30. [20. 22. 20. 22. 20. 10. 20. 21. 16. 12. 19. 20. 22. 12. 16. 22. 20. 17.
 20. 20.] 
Reward = 15.51479721069336
31. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22.  8. 26. 15. 15. 21.
 22. 21.] 
Reward = 15.514487266540527
32. [14. 14. 16. 22. 21. 22. 20. 19. 16. 11. 16. 20. 22. 22. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.506855010986328
33. [20. 22. 21. 22. 20. 10. 13. 21. 16. 11. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.504549980163574
34. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 22. 21.] 
Reward = 15.503497123718262
35. [20. 14. 16. 22. 21. 22. 13. 19. 13. 22. 19. 20. 22.  9. 26. 22. 20. 17.
 20. 21.] 
Reward = 15.494070053100586
36. [20. 14. 16. 22. 21. 22. 14. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.489802360534668
37. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.487140655517578
38. [20. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  9. 16. 22. 20. 21.
 21. 21.] 
Reward = 15.483205795288086
39. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22. 12. 26. 22. 20. 21.
 20. 21.] 
Reward = 15.481279373168945
40. [14. 14. 16. 22. 16. 22. 20. 19. 16. 22. 16. 23. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.478944778442383
41. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
42. [20. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.471687316894531
43. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 21. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.470913887023926
44. [20. 14. 16. 22. 21. 22. 13. 21. 16. 12. 19. 23. 22. 22. 17. 22. 15. 21.
 21. 20.] 
Reward = 15.465348243713379
45. [14. 14. 16. 22. 21. 22. 20. 20. 13. 22. 16. 20. 22. 12. 17. 25. 20. 21.
 20. 21.] 
Reward = 15.46469783782959
46. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 19. 15. 17.
 20. 18.] 
Reward = 15.46304988861084
47. [20. 22. 20. 17. 22. 20. 21. 22. 16. 22. 23. 20. 22. 12. 13. 18. 15. 17.
 20. 18.] 
Reward = 15.457979202270508
48. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 26. 18. 20. 21.
 20. 21.] 
Reward = 15.45567512512207
49. [20. 22. 16. 17. 20. 20. 20. 19. 16. 22. 23. 23. 22. 12. 16. 25. 15. 17.
 20. 21.] 
Reward = 15.453691482543945
50. [14. 14. 16. 22. 21. 22. 13. 19. 16. 22. 16. 20. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.453227043151855
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 18 took 1 hour 37 mins 30 secs



Testing Model 951
[23, 14, 18, 22, 15, 22, 20, 19, 16, 22, 16, 15, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 1966.25M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.75 | Loss = 2.0122
Testing Model 951 took 1 mins and 55 secs

Testing Model 952
[10, 24, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 2031.75M
Top-1 Accuracy = 54.71 | Top-5 Accuracy = 78.52 | Loss = 2.0375
Testing Model 952 took 1 mins and 58 secs

Testing Model 953
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 17, 25, 28, 21, 21, 21]
FLOPs = 2049.00M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.70 | Loss = 2.0145
Testing Model 953 took 1 mins and 54 secs

Testing Model 954
[14, 14, 16, 22, 21, 22, 20, 22, 16, 22, 16, 20, 22, 12, 26, 18, 15, 18, 21, 21]
FLOPs = 1956.37M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.65 | Loss = 2.0197
Testing Model 954 took 1 mins and 53 secs

Testing Model 955
[20, 22, 20, 17, 20, 20, 21, 21, 19, 22, 23, 20, 22, 12, 16, 18, 15, 17, 20, 18]
FLOPs = 1969.25M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.68 | Loss = 2.0164
Testing Model 955 took 1 mins and 54 secs

Testing Model 956
[14, 14, 27, 22, 21, 22, 20, 21, 16, 22, 16, 20, 11, 12, 25, 18, 15, 21, 21, 21]
FLOPs = 2040.36M
Top-1 Accuracy = 55.24 | Top-5 Accuracy = 78.70 | Loss = 2.0163
Testing Model 956 took 1 mins and 59 secs

Testing Model 957
[27, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 17, 25, 20, 21, 20, 21]
FLOPs = 2014.53M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.74 | Loss = 2.0140
Testing Model 957 took 1 mins and 55 secs

Testing Model 958
[9, 14, 16, 22, 21, 22, 20, 19, 13, 22, 28, 20, 22, 12, 17, 25, 20, 21, 20, 21]
FLOPs = 2012.94M
Top-1 Accuracy = 54.64 | Top-5 Accuracy = 78.42 | Loss = 2.0364
Testing Model 958 took 1 mins and 58 secs

Testing Model 959
[14, 14, 16, 22, 21, 22, 20, 30, 13, 22, 16, 19, 22, 12, 17, 25, 15, 21, 13, 21]
FLOPs = 1953.38M
Top-1 Accuracy = 54.88 | Top-5 Accuracy = 78.54 | Loss = 2.0261
Testing Model 959 took 1 mins and 57 secs

Testing Model 960
[1, 23, 16, 22, 16, 22, 20, 19, 16, 22, 16, 14, 22, 12, 26, 18, 15, 21, 20, 30]
FLOPs = 1988.99M
Top-1 Accuracy = 52.25 | Top-5 Accuracy = 76.32 | Loss = 2.1887
Testing Model 960 took 1 mins and 55 secs

Testing Model 961
[15, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 18, 25, 20, 21, 20, 21]
FLOPs = 1964.06M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.78 | Loss = 2.0135
Testing Model 961 took 1 mins and 54 secs

Testing Model 962
[14, 13, 16, 22, 21, 22, 20, 19, 24, 22, 16, 20, 22, 12, 17, 25, 20, 21, 20, 21]
FLOPs = 2011.12M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.67 | Loss = 2.0155
Testing Model 962 took 1 mins and 53 secs

Testing Model 963
[14, 14, 16, 22, 21, 22, 20, 28, 17, 22, 16, 23, 22, 12, 17, 25, 15, 21, 21, 21]
FLOPs = 2048.29M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.68 | Loss = 2.0159
Testing Model 963 took 1 mins and 55 secs

Testing Model 964
[21, 22, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 15, 16, 18, 15, 17, 20, 18]
FLOPs = 1972.06M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.65 | Loss = 2.0153
Testing Model 964 took 1 mins and 56 secs

Testing Model 965
[15, 14, 16, 22, 21, 30, 20, 19, 13, 22, 16, 20, 22, 12, 17, 25, 20, 21, 20, 21]
FLOPs = 2022.11M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.75 | Loss = 2.0160
Testing Model 965 took 1 mins and 53 secs

Testing Model 966
[20, 22, 20, 17, 20, 20, 21, 21, 16, 22, 23, 20, 22, 12, 16, 18, 15, 17, 23, 18]
FLOPs = 1975.40M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.66 | Loss = 2.0170
Testing Model 966 took 1 mins and 55 secs

Testing Model 967
[14, 14, 16, 22, 21, 22, 20, 23, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 21, 21]
FLOPs = 1990.44M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.72 | Loss = 2.0163
Testing Model 967 took 1 mins and 57 secs

Testing Model 968
[15, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 15, 25, 20, 27, 20, 21]
FLOPs = 2002.04M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.78 | Loss = 2.0157
Testing Model 968 took 1 mins and 57 secs

Testing Model 969
[14, 14, 16, 22, 16, 22, 20, 19, 16, 22, 26, 20, 22, 12, 26, 18, 15, 21, 21, 24]
FLOPs = 2025.98M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.70 | Loss = 2.0180
Testing Model 969 took 1 mins and 56 secs

Testing Model 970
[14, 14, 16, 27, 21, 22, 20, 19, 16, 22, 16, 20, 13, 12, 25, 18, 15, 28, 21, 21]
FLOPs = 2048.47M
Top-1 Accuracy = 55.14 | Top-5 Accuracy = 78.70 | Loss = 2.0197
Testing Model 970 took 1 mins and 58 secs

Testing Model 971
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 17, 25, 21, 21, 21, 21]
FLOPs = 1991.91M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.71 | Loss = 2.0155
Testing Model 971 took 1 mins and 57 secs

Testing Model 972
[20, 22, 20, 17, 20, 20, 21, 21, 26, 22, 23, 20, 22, 12, 16, 18, 15, 17, 20, 18]
FLOPs = 2022.03M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.68 | Loss = 2.0160
Testing Model 972 took 2 mins and 1 secs

Testing Model 973
[15, 14, 16, 22, 21, 22, 20, 19, 20, 22, 16, 20, 22, 12, 17, 25, 20, 21, 20, 21]
FLOPs = 1999.36M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.76 | Loss = 2.0143
Testing Model 973 took 1 mins and 55 secs

Testing Model 974
[14, 14, 16, 22, 16, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 29, 24]
FLOPs = 2030.20M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.73 | Loss = 2.0174
Testing Model 974 took 1 mins and 55 secs

Testing Model 975
[14, 14, 16, 22, 21, 22, 19, 19, 13, 22, 16, 23, 22, 12, 17, 25, 15, 23, 21, 21]
FLOPs = 1963.32M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.73 | Loss = 2.0162
Testing Model 975 took 1 mins and 53 secs

Testing Model 976
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 25, 18, 15, 21, 21, 21]
FLOPs = 1957.47M
Top-1 Accuracy = 55.24 | Top-5 Accuracy = 78.70 | Loss = 2.0158
Testing Model 976 took 1 mins and 55 secs

Testing Model 977
[20, 22, 20, 22, 21, 20, 21, 19, 13, 22, 16, 23, 22, 12, 16, 18, 15, 21, 20, 18]
FLOPs = 2020.03M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.73 | Loss = 2.0148
Testing Model 977 took 2 mins and 0 secs

Testing Model 978
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 17, 25, 20, 21, 21, 21]
FLOPs = 1978.03M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.66 | Loss = 2.0166
Testing Model 978 took 1 mins and 56 secs

Testing Model 979
[20, 14, 20, 22, 16, 20, 21, 21, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 20, 18]
FLOPs = 1990.19M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.71 | Loss = 2.0178
Testing Model 979 took 1 mins and 56 secs

Testing Model 980
[14, 14, 18, 22, 21, 22, 20, 19, 16, 22, 16, 15, 22, 12, 26, 18, 15, 21, 21, 24]
FLOPs = 1972.77M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.74 | Loss = 2.0147
Testing Model 980 took 1 mins and 54 secs

Testing Model 981
[20, 22, 20, 22, 20, 20, 20, 19, 16, 22, 16, 20, 22, 12, 16, 18, 20, 17, 20, 21]
FLOPs = 2022.15M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.78 | Loss = 2.0126
Testing Model 981 took 1 mins and 58 secs

Testing Model 982
[15, 14, 20, 22, 21, 20, 21, 21, 13, 22, 23, 20, 22, 12, 17, 25, 15, 17, 20, 21]
FLOPs = 1999.34M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.75 | Loss = 2.0139
Testing Model 982 took 1 mins and 57 secs

Testing Model 983
[20, 14, 20, 17, 21, 22, 21, 19, 13, 22, 23, 23, 22, 12, 16, 25, 15, 21, 20, 18]
FLOPs = 1955.45M
Top-1 Accuracy = 55.09 | Top-5 Accuracy = 78.74 | Loss = 2.0176
Testing Model 983 took 2 mins and 1 secs

Testing Model 984
[20, 22, 16, 17, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 1970.20M
Top-1 Accuracy = 55.12 | Top-5 Accuracy = 78.80 | Loss = 2.0132
Testing Model 984 took 1 mins and 54 secs

Testing Model 985
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 17, 25, 15, 21, 21, 24]
FLOPs = 1952.35M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.71 | Loss = 2.0168
Testing Model 985 took 1 mins and 55 secs

Testing Model 986
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 25, 15, 21, 21, 24]
FLOPs = 2036.94M
Top-1 Accuracy = 55.27 | Top-5 Accuracy = 78.75 | Loss = 2.0170
Testing Model 986 took 1 mins and 56 secs

Testing Model 987
[20, 14, 20, 22, 20, 22, 20, 19, 16, 22, 23, 20, 22, 12, 16, 18, 15, 17, 21, 24]
FLOPs = 1998.56M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.79 | Loss = 2.0150
Testing Model 987 took 1 mins and 56 secs

Testing Model 988
[14, 14, 16, 22, 16, 22, 20, 19, 13, 22, 16, 20, 22, 12, 26, 25, 20, 21, 20, 21]
FLOPs = 1994.65M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.66 | Loss = 2.0187
Testing Model 988 took 1 mins and 55 secs

Testing Model 989
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 26, 18, 15, 21, 20, 24]
FLOPs = 1959.26M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.74 | Loss = 2.0163
Testing Model 989 took 1 mins and 53 secs

Testing Model 990
[14, 22, 16, 22, 20, 20, 21, 19, 16, 22, 16, 20, 22, 12, 25, 18, 15, 17, 21, 18]
FLOPs = 1960.69M
Top-1 Accuracy = 55.08 | Top-5 Accuracy = 78.63 | Loss = 2.0222
Testing Model 990 took 1 mins and 57 secs

Testing Model 991
[15, 22, 20, 22, 20, 22, 21, 21, 13, 22, 23, 20, 22, 12, 17, 18, 15, 17, 20, 18]
FLOPs = 2018.13M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.59 | Loss = 2.0189
Testing Model 991 took 2 mins and 2 secs

Testing Model 992
[20, 22, 16, 22, 16, 20, 21, 21, 16, 22, 23, 20, 22, 12, 16, 18, 15, 21, 20, 24]
FLOPs = 2040.51M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.79 | Loss = 2.0115
Testing Model 992 took 1 mins and 59 secs

Testing Model 993
[14, 22, 16, 22, 21, 20, 21, 21, 16, 22, 23, 20, 22, 12, 26, 18, 15, 17, 20, 18]
FLOPs = 2030.85M
Top-1 Accuracy = 55.06 | Top-5 Accuracy = 78.59 | Loss = 2.0214
Testing Model 993 took 1 mins and 58 secs

Testing Model 994
[20, 22, 20, 17, 20, 22, 21, 21, 13, 22, 16, 20, 22, 12, 16, 25, 15, 17, 20, 21]
FLOPs = 1972.03M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.77 | Loss = 2.0139
Testing Model 994 took 1 mins and 55 secs

Testing Model 995
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 25, 18, 15, 21, 21, 24]
FLOPs = 1975.55M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.73 | Loss = 2.0180
Testing Model 995 took 1 mins and 55 secs

Testing Model 996
[20, 14, 16, 22, 21, 20, 20, 21, 16, 22, 23, 20, 22, 12, 16, 25, 15, 21, 20, 21]
FLOPs = 2004.11M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.81 | Loss = 2.0137
Testing Model 996 took 1 mins and 54 secs

Testing Model 997
[15, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 17, 25, 20, 21, 21, 21]
FLOPs = 1965.83M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.78 | Loss = 2.0170
Testing Model 997 took 1 mins and 55 secs

Testing Model 998
[14, 14, 16, 22, 16, 22, 20, 19, 16, 22, 16, 23, 22, 12, 17, 25, 15, 21, 21, 24]
FLOPs = 1967.94M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.73 | Loss = 2.0176
Testing Model 998 took 1 mins and 56 secs

Testing Model 999
[14, 14, 16, 22, 16, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 25, 15, 21, 21, 24]
FLOPs = 2011.06M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.72 | Loss = 2.0172
Testing Model 999 took 1 mins and 54 secs

Testing Model 1000
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 17, 25, 20, 21, 21, 21]
FLOPs = 1985.26M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.71 | Loss = 2.0154
Testing Model 1000 took 1 mins and 56 secs

> Select
Iteration 19 : Showing Top 50 results
1. [14. 14. 16. 22. 16. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 24.] 
Reward = 15.66705322265625
2. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 25. 18. 15. 21.
 21. 21.] 
Reward = 15.652791976928711
3. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 17. 25. 15. 21.
 21. 24.] 
Reward = 15.650390625
4. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.640439987182617
5. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 17. 25. 20. 21.
 20. 21.] 
Reward = 15.62641716003418
6. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 21. 21.] 
Reward = 15.616037368774414
7. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22. 12. 25. 18. 15. 21.
 21. 21.] 
Reward = 15.611405372619629
8. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.595078468322754
9. [14. 14. 16. 22. 16. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 20. 24.] 
Reward = 15.585054397583008
10. [14. 14. 18. 22. 21. 22. 20. 19. 16. 22. 16. 15. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.582011222839355
11. [15. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 17. 25. 20. 21.
 20. 21.] 
Reward = 15.577486038208008
12. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.574835777282715
13. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 21. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.567974090576172
14. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 17. 25. 20. 21.
 21. 21.] 
Reward = 15.56768798828125
15. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 21. 20.] 
Reward = 15.564767837524414
16. [20. 22. 20. 17. 20. 20. 20. 21. 13. 12. 16. 23. 22. 12. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.564648628234863
17. [14. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  8. 17. 25. 20. 21.
 21. 21.] 
Reward = 15.562047958374023
18. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 18. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.556252479553223
19. [14. 22. 18. 17. 21. 22. 21. 21. 16. 22. 23. 15. 22. 12. 16. 18. 15. 21.
 22. 21.] 
Reward = 15.553827285766602
20. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.54874038696289
21. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 20. 21.] 
Reward = 15.548630714416504
22. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22.  8. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.547995567321777
23. [20. 14. 21. 22. 21. 10. 20. 19. 16. 12. 16. 20. 22. 22. 26. 18. 15. 17.
 22. 21.] 
Reward = 15.545217514038086
24. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.539837837219238
25. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.536077499389648
26. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.534582138061523
27. [20. 22. 21. 17. 20. 10. 13. 21. 16. 22. 23. 20. 22. 22. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.531606674194336
28. [20. 23. 20. 17. 20. 20. 20. 19. 13. 12. 16. 23. 18. 18. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.531522750854492
29. [20. 23. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 21. 20.] 
Reward = 15.531478881835938
30. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22.  9. 26. 22. 15. 21.
 21. 21.] 
Reward = 15.5304536819458
31. [14. 14. 16. 22. 24. 22. 20. 19. 16. 22. 16. 20. 22. 12. 25. 18. 15. 21.
 21. 21.] 
Reward = 15.516618728637695
32. [15. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 18. 25. 20. 21.
 20. 21.] 
Reward = 15.516180038452148
33. [20. 22. 20. 22. 20. 10. 20. 21. 16. 12. 19. 20. 22. 12. 16. 22. 20. 17.
 20. 20.] 
Reward = 15.51479721069336
34. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22.  8. 26. 15. 15. 21.
 22. 21.] 
Reward = 15.514487266540527
35. [14. 14. 16. 22. 21. 22. 20. 19. 16. 11. 16. 20. 22. 22. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.506855010986328
36. [20. 22. 21. 22. 20. 10. 13. 21. 16. 11. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.504549980163574
37. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 22. 21.] 
Reward = 15.503497123718262
38. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 20. 24.] 
Reward = 15.50312614440918
39. [14. 14. 16. 22. 21. 22. 19. 19. 13. 22. 16. 23. 22. 12. 17. 25. 15. 23.
 21. 21.] 
Reward = 15.499947547912598
40. [20. 14. 16. 22. 21. 22. 13. 19. 13. 22. 19. 20. 22.  9. 26. 22. 20. 17.
 20. 21.] 
Reward = 15.494070053100586
41. [15. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 17. 25. 20. 21.
 21. 21.] 
Reward = 15.493162155151367
42. [20. 14. 16. 22. 21. 22. 14. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.489802360534668
43. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.487140655517578
44. [20. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  9. 16. 22. 20. 21.
 21. 21.] 
Reward = 15.483205795288086
45. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22. 12. 26. 22. 20. 21.
 20. 21.] 
Reward = 15.481279373168945
46. [14. 14. 16. 22. 16. 22. 20. 19. 16. 22. 16. 23. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.478944778442383
47. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  9. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.476776123046875
48. [20. 23. 20. 17. 20. 20. 21. 15. 16. 12. 23. 20. 18. 18. 16. 22. 23. 17.
 20. 20.] 
Reward = 15.471687316894531
49. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 21. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.470913887023926
50. [20. 14. 16. 22. 21. 22. 13. 21. 16. 12. 19. 23. 22. 22. 17. 22. 15. 21.
 21. 20.] 
Reward = 15.465348243713379
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 19 took 1 hour 37 mins 26 secs



Testing Model 1001
[10, 14, 24, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 17, 21]
FLOPs = 2013.73M
Top-1 Accuracy = 54.65 | Top-5 Accuracy = 78.44 | Loss = 2.0393
Testing Model 1001 took 1 mins and 57 secs

Testing Model 1002
[14, 14, 16, 22, 16, 22, 22, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 21, 24]
FLOPs = 1972.13M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.75 | Loss = 2.0185
Testing Model 1002 took 1 mins and 55 secs

Testing Model 1003
[14, 14, 12, 22, 21, 28, 16, 19, 16, 22, 16, 15, 22, 12, 26, 18, 21, 21, 27, 21]
FLOPs = 1989.43M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.72 | Loss = 2.0186
Testing Model 1003 took 1 mins and 54 secs

Testing Model 1004
[14, 14, 16, 22, 23, 22, 24, 19, 13, 22, 16, 15, 22, 12, 17, 25, 15, 21, 21, 24]
FLOPs = 1956.75M
Top-1 Accuracy = 55.29 | Top-5 Accuracy = 78.67 | Loss = 2.0141
Testing Model 1004 took 1 mins and 55 secs

Testing Model 1005
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 17, 25, 20, 22, 20, 21]
FLOPs = 1962.49M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.70 | Loss = 2.0171
Testing Model 1005 took 2 mins and 0 secs

Testing Model 1006
[14, 14, 16, 25, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 17, 25, 20, 21, 20, 21]
FLOPs = 2008.94M
Top-1 Accuracy = 55.13 | Top-5 Accuracy = 78.64 | Loss = 2.0163
Testing Model 1006 took 1 mins and 56 secs

Testing Model 1007
[14, 14, 16, 22, 21, 22, 20, 19, 13, 21, 16, 23, 25, 12, 25, 18, 15, 21, 21, 21]
FLOPs = 1973.94M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.73 | Loss = 2.0177
Testing Model 1007 took 1 mins and 54 secs

Testing Model 1008
[14, 14, 16, 22, 16, 22, 15, 19, 4, 22, 16, 20, 22, 12, 26, 30, 15, 21, 20, 24]
FLOPs = 1965.39M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.70 | Loss = 2.0199
Testing Model 1008 took 1 mins and 55 secs

Testing Model 1009
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 6, 25, 18, 23, 21, 21, 21]
FLOPs = 1977.28M
Top-1 Accuracy = 55.02 | Top-5 Accuracy = 78.73 | Loss = 2.0191
Testing Model 1009 took 1 mins and 54 secs

Testing Model 1010
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 17, 25, 15, 21, 21, 27]
FLOPs = 1979.52M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.76 | Loss = 2.0164
Testing Model 1010 took 1 mins and 55 secs

Testing Model 1011
[11, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 23, 15, 21, 21, 21]
FLOPs = 1981.21M
Top-1 Accuracy = 54.89 | Top-5 Accuracy = 78.59 | Loss = 2.0252
Testing Model 1011 took 1 mins and 54 secs

Testing Model 1012
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 12, 20, 22, 26, 26, 18, 15, 15, 20, 21]
FLOPs = 1977.04M
Top-1 Accuracy = 55.03 | Top-5 Accuracy = 78.66 | Loss = 2.0215
Testing Model 1012 took 1 mins and 55 secs

Testing Model 1013
[14, 14, 16, 22, 16, 22, 20, 19, 16, 22, 16, 20, 22, 1, 26, 18, 15, 30, 20, 24]
FLOPs = 1992.06M
Top-1 Accuracy = 54.83 | Top-5 Accuracy = 78.63 | Loss = 2.0322
Testing Model 1013 took 1 mins and 57 secs

Testing Model 1014
[14, 14, 16, 22, 21, 22, 28, 19, 13, 22, 16, 18, 25, 12, 17, 25, 15, 21, 21, 21]
FLOPs = 1995.42M
Top-1 Accuracy = 55.16 | Top-5 Accuracy = 78.70 | Loss = 2.0154
Testing Model 1014 took 1 mins and 55 secs

Testing Model 1015
[14, 14, 18, 22, 21, 22, 20, 19, 16, 22, 16, 15, 22, 11, 26, 18, 15, 21, 22, 21]
FLOPs = 1951.11M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.68 | Loss = 2.0163
Testing Model 1015 took 1 mins and 56 secs

Testing Model 1016
[2, 14, 16, 22, 21, 22, 20, 19, 16, 21, 16, 20, 22, 12, 26, 18, 15, 21, 28, 21]
FLOPs = 1957.52M
Top-1 Accuracy = 53.62 | Top-5 Accuracy = 77.45 | Loss = 2.1032
Testing Model 1016 took 1 mins and 51 secs

Testing Model 1017
[14, 14, 16, 22, 21, 22, 30, 19, 13, 22, 16, 23, 22, 12, 25, 18, 15, 21, 21, 21]
FLOPs = 2035.37M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.70 | Loss = 2.0170
Testing Model 1017 took 1 mins and 56 secs

Testing Model 1018
[14, 14, 26, 22, 21, 22, 20, 19, 16, 22, 16, 20, 0, 12, 26, 18, 15, 21, 20, 21]
FLOPs = 1965.78M
Top-1 Accuracy = 54.53 | Top-5 Accuracy = 78.34 | Loss = 2.0406
Testing Model 1018 took 1 mins and 57 secs

Testing Model 1019
[14, 14, 16, 22, 21, 29, 20, 19, 13, 22, 16, 23, 22, 12, 17, 25, 15, 21, 21, 21]
FLOPs = 2006.71M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.74 | Loss = 2.0149
Testing Model 1019 took 1 mins and 53 secs

Testing Model 1020
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 24, 20, 22, 12, 26, 13, 15, 21, 21, 21]
FLOPs = 1979.70M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.68 | Loss = 2.0208
Testing Model 1020 took 1 mins and 54 secs

Testing Model 1021
[14, 22, 16, 22, 21, 22, 20, 19, 13, 23, 14, 20, 22, 12, 17, 25, 15, 23, 21, 24]
FLOPs = 2048.71M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.80 | Loss = 2.0132
Testing Model 1021 took 1 mins and 57 secs

Testing Model 1022
[14, 14, 16, 22, 16, 22, 20, 24, 16, 22, 16, 20, 22, 12, 26, 18, 15, 23, 20, 24]
FLOPs = 2006.80M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.77 | Loss = 2.0177
Testing Model 1022 took 1 mins and 57 secs

Testing Model 1023
[14, 22, 18, 22, 21, 22, 20, 19, 16, 22, 16, 15, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 2039.60M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.69 | Loss = 2.0131
Testing Model 1023 took 1 mins and 57 secs

Testing Model 1024
[14, 14, 16, 22, 16, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 24, 21, 21, 24]
FLOPs = 2021.93M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.76 | Loss = 2.0173
Testing Model 1024 took 1 mins and 54 secs

Testing Model 1025
[14, 14, 22, 22, 2, 22, 20, 19, 16, 22, 16, 20, 22, 12, 25, 18, 15, 21, 21, 21]
FLOPs = 1953.66M
Top-1 Accuracy = 55.00 | Top-5 Accuracy = 78.53 | Loss = 2.0263
Testing Model 1025 took 1 mins and 54 secs

Testing Model 1026
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 1974.74M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.74 | Loss = 2.0144
Testing Model 1026 took 2 mins and 1 secs

Testing Model 1027
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 26, 18, 20, 21, 21, 21]
FLOPs = 1975.67M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.71 | Loss = 2.0164
Testing Model 1027 took 1 mins and 52 secs

Testing Model 1028
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 17, 25, 20, 21, 20, 24]
FLOPs = 1978.37M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.76 | Loss = 2.0154
Testing Model 1028 took 1 mins and 55 secs

Testing Model 1029
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 25, 25, 15, 21, 21, 24]
FLOPs = 2011.14M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.75 | Loss = 2.0165
Testing Model 1029 took 1 mins and 53 secs

Testing Model 1030
[14, 14, 16, 22, 16, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 25, 15, 21, 20, 24]
FLOPs = 2003.21M
Top-1 Accuracy = 55.10 | Top-5 Accuracy = 78.67 | Loss = 2.0175
Testing Model 1030 took 1 mins and 51 secs

Testing Model 1031
[14, 14, 18, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 26, 18, 15, 21, 22, 21]
FLOPs = 2001.22M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.76 | Loss = 2.0154
Testing Model 1031 took 1 mins and 53 secs

Testing Model 1032
[14, 14, 18, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 20, 21, 22, 21]
FLOPs = 2027.89M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.70 | Loss = 2.0143
Testing Model 1032 took 1 mins and 53 secs

Testing Model 1033
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 17, 25, 15, 21, 21, 24]
FLOPs = 1976.70M
Top-1 Accuracy = 55.27 | Top-5 Accuracy = 78.75 | Loss = 2.0147
Testing Model 1033 took 1 mins and 57 secs

Testing Model 1034
[14, 14, 16, 22, 16, 22, 20, 19, 16, 22, 16, 20, 22, 12, 17, 25, 20, 21, 21, 21]
FLOPs = 1952.15M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.61 | Loss = 2.0188
Testing Model 1034 took 1 mins and 55 secs

Testing Model 1035
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 12, 25, 18, 15, 21, 21, 21]
FLOPs = 1974.59M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.70 | Loss = 2.0168
Testing Model 1035 took 1 mins and 56 secs

Testing Model 1036
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 26, 18, 15, 21, 21, 24]
FLOPs = 1991.46M
Top-1 Accuracy = 55.25 | Top-5 Accuracy = 78.77 | Loss = 2.0177
Testing Model 1036 took 1 mins and 57 secs

Testing Model 1037
[14, 14, 18, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 25, 18, 15, 21, 22, 21]
FLOPs = 1992.54M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.77 | Loss = 2.0140
Testing Model 1037 took 1 mins and 58 secs

Testing Model 1038
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 12, 17, 25, 15, 21, 21, 21]
FLOPs = 1968.51M
Top-1 Accuracy = 55.22 | Top-5 Accuracy = 78.74 | Loss = 2.0163
Testing Model 1038 took 1 mins and 54 secs

Testing Model 1039
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 17, 25, 20, 21, 21, 24]
FLOPs = 1986.22M
Top-1 Accuracy = 55.17 | Top-5 Accuracy = 78.73 | Loss = 2.0162
Testing Model 1039 took 1 mins and 54 secs

Testing Model 1040
[14, 14, 16, 22, 16, 22, 20, 19, 13, 22, 16, 23, 22, 12, 26, 25, 15, 21, 21, 21]
FLOPs = 1992.98M
Top-1 Accuracy = 55.24 | Top-5 Accuracy = 78.73 | Loss = 2.0175
Testing Model 1040 took 1 mins and 56 secs

Testing Model 1041
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 25, 25, 15, 21, 21, 24]
FLOPs = 2035.48M
Top-1 Accuracy = 55.24 | Top-5 Accuracy = 78.73 | Loss = 2.0175
Testing Model 1041 took 1 mins and 55 secs

Testing Model 1042
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 25, 25, 15, 21, 21, 21]
FLOPs = 1985.83M
Top-1 Accuracy = 55.19 | Top-5 Accuracy = 78.69 | Loss = 2.0173
Testing Model 1042 took 1 mins and 55 secs

Testing Model 1043
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 25, 25, 20, 21, 20, 21]
FLOPs = 2011.85M
Top-1 Accuracy = 55.23 | Top-5 Accuracy = 78.69 | Loss = 2.0164
Testing Model 1043 took 1 mins and 56 secs

Testing Model 1044
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 26, 25, 15, 21, 21, 24]
FLOPs = 2019.82M
Top-1 Accuracy = 55.24 | Top-5 Accuracy = 78.74 | Loss = 2.0141
Testing Model 1044 took 1 mins and 56 secs

Testing Model 1045
[14, 14, 18, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 22, 24]
FLOPs = 2019.33M
Top-1 Accuracy = 55.20 | Top-5 Accuracy = 78.79 | Loss = 2.0160
Testing Model 1045 took 1 mins and 55 secs

Testing Model 1046
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 26, 18, 15, 21, 21, 24]
FLOPs = 1967.11M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.76 | Loss = 2.0174
Testing Model 1046 took 1 mins and 59 secs

Testing Model 1047
[14, 14, 16, 22, 16, 22, 20, 19, 13, 22, 16, 23, 22, 12, 26, 18, 15, 21, 21, 24]
FLOPs = 1965.58M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.74 | Loss = 2.0175
Testing Model 1047 took 1 mins and 53 secs

Testing Model 1048
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 25, 25, 15, 21, 21, 21]
FLOPs = 2010.18M
Top-1 Accuracy = 55.15 | Top-5 Accuracy = 78.73 | Loss = 2.0163
Testing Model 1048 took 1 mins and 56 secs

Testing Model 1049
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 20, 21, 22, 21]
FLOPs = 2001.39M
Top-1 Accuracy = 55.21 | Top-5 Accuracy = 78.75 | Loss = 2.0168
Testing Model 1049 took 1 mins and 55 secs

Testing Model 1050
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 23, 22, 12, 26, 25, 15, 21, 20, 21]
FLOPs = 2028.13M
Top-1 Accuracy = 55.18 | Top-5 Accuracy = 78.74 | Loss = 2.0170
Testing Model 1050 took 1 mins and 54 secs

> Select
Iteration 20 : Showing Top 50 results
1. [14. 14. 16. 22. 23. 22. 24. 19. 13. 22. 16. 15. 22. 12. 17. 25. 15. 21.
 21. 24.] 
Reward = 15.73775863647461
2. [14. 14. 16. 22. 16. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 24.] 
Reward = 15.66705322265625
3. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 25. 18. 15. 21.
 21. 21.] 
Reward = 15.652791976928711
4. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 17. 25. 15. 21.
 21. 24.] 
Reward = 15.650390625
5. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.640439987182617
6. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 17. 25. 20. 21.
 20. 21.] 
Reward = 15.62641716003418
7. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 21. 21.] 
Reward = 15.616037368774414
8. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22. 12. 25. 18. 15. 21.
 21. 21.] 
Reward = 15.611405372619629
9. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.595078468322754
10. [14. 14. 18. 22. 21. 22. 20. 19. 16. 22. 16. 15. 22. 11. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.586628913879395
11. [14. 14. 16. 22. 16. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 20. 24.] 
Reward = 15.585054397583008
12. [14. 14. 18. 22. 21. 22. 20. 19. 16. 22. 16. 15. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.582011222839355
13. [15. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 17. 25. 20. 21.
 20. 21.] 
Reward = 15.577486038208008
14. [20. 22. 20. 17. 20. 20. 21. 21. 16. 22. 23. 20. 22. 12. 16. 18. 15. 17.
 20. 18.] 
Reward = 15.574835777282715
15. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 21. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.567974090576172
16. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 17. 25. 20. 21.
 21. 21.] 
Reward = 15.56768798828125
17. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 21. 20.] 
Reward = 15.564767837524414
18. [20. 22. 20. 17. 20. 20. 20. 21. 13. 12. 16. 23. 22. 12. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.564648628234863
19. [14. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  8. 17. 25. 20. 21.
 21. 21.] 
Reward = 15.562047958374023
20. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 18. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.556252479553223
21. [14. 22. 18. 17. 21. 22. 21. 21. 16. 22. 23. 15. 22. 12. 16. 18. 15. 21.
 22. 21.] 
Reward = 15.553827285766602
22. [20. 22. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.54874038696289
23. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 20. 21.] 
Reward = 15.548630714416504
24. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22.  8. 26. 18. 15. 21.
 20. 21.] 
Reward = 15.547995567321777
25. [20. 14. 21. 22. 21. 10. 20. 19. 16. 12. 16. 20. 22. 22. 26. 18. 15. 17.
 22. 21.] 
Reward = 15.545217514038086
26. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22.  8. 26. 15. 20. 21.
 21. 21.] 
Reward = 15.539837837219238
27. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22.  9. 26. 22. 20. 21.
 21. 21.] 
Reward = 15.536077499389648
28. [20. 14. 16. 22. 21. 22. 13. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.534582138061523
29. [20. 22. 21. 17. 20. 10. 13. 21. 16. 22. 23. 20. 22. 22. 16. 22. 15. 17.
 20. 20.] 
Reward = 15.531606674194336
30. [20. 23. 20. 17. 20. 20. 20. 19. 13. 12. 16. 23. 18. 18. 16. 22. 20. 21.
 20. 21.] 
Reward = 15.531522750854492
31. [20. 23. 21. 22. 20. 10. 13. 21. 16. 12. 19. 20. 22. 22. 14. 22. 15. 17.
 21. 20.] 
Reward = 15.531478881835938
32. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22.  9. 26. 22. 15. 21.
 21. 21.] 
Reward = 15.5304536819458
33. [14. 14. 16. 22. 24. 22. 20. 19. 16. 22. 16. 20. 22. 12. 25. 18. 15. 21.
 21. 21.] 
Reward = 15.516618728637695
34. [15. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 18. 25. 20. 21.
 20. 21.] 
Reward = 15.516180038452148
35. [20. 22. 20. 22. 20. 10. 20. 21. 16. 12. 19. 20. 22. 12. 16. 22. 20. 17.
 20. 20.] 
Reward = 15.51479721069336
36. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 23. 22.  8. 26. 15. 15. 21.
 22. 21.] 
Reward = 15.514487266540527
37. [14. 14. 16. 22. 21. 22. 20. 19. 16. 11. 16. 20. 22. 22. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.506855010986328
38. [20. 22. 21. 22. 20. 10. 13. 21. 16. 11. 19. 20. 22. 22. 16. 22. 15. 17.
 21. 20.] 
Reward = 15.504549980163574
39. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 23. 22. 12. 17. 25. 15. 21.
 22. 21.] 
Reward = 15.503497123718262
40. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 20. 24.] 
Reward = 15.50312614440918
41. [14. 14. 16. 22. 16. 22. 20. 19. 16. 22. 16. 20. 22. 12. 17. 25. 20. 21.
 21. 21.] 
Reward = 15.502900123596191
42. [14. 14. 16. 22. 21. 22. 19. 19. 13. 22. 16. 23. 22. 12. 17. 25. 15. 23.
 21. 21.] 
Reward = 15.499947547912598
43. [20. 14. 16. 22. 21. 22. 13. 19. 13. 22. 19. 20. 22.  9. 26. 22. 20. 17.
 20. 21.] 
Reward = 15.494070053100586
44. [15. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 17. 25. 20. 21.
 21. 21.] 
Reward = 15.493162155151367
45. [20. 14. 16. 22. 21. 22. 14. 19. 16. 22. 19. 20. 22. 12. 26. 22. 15. 17.
 20. 21.] 
Reward = 15.489802360534668
46. [14. 14. 16. 22. 21. 22. 20. 19. 16. 22. 16. 20. 22. 12. 26. 18. 15. 21.
 22. 21.] 
Reward = 15.487140655517578
47. [20. 14. 16. 22. 21. 20. 20. 19. 13. 22. 16. 23. 22.  9. 16. 22. 20. 21.
 21. 21.] 
Reward = 15.483205795288086
48. [14. 14. 16. 22. 21. 22. 13. 19. 13. 22. 16. 20. 22. 12. 26. 22. 20. 21.
 20. 21.] 
Reward = 15.481279373168945
49. [14. 14. 16. 22. 21. 22. 20. 19. 13. 22. 16. 20. 22. 12. 17. 25. 20. 22.
 20. 21.] 
Reward = 15.48060131072998
50. [14. 14. 16. 22. 16. 22. 20. 19. 16. 22. 16. 23. 22. 12. 26. 18. 15. 21.
 21. 21.] 
Reward = 15.478944778442383
> Mutation
mutation_num = 25
> Crossover
crossover_num = 25
> Random Select
Number of Candidates = 0
Saving tested_dict ........

Iteration 20 took 1 hour 36 mins 47 secs


[14, 14, 16, 22, 23, 22, 24, 19, 13, 22, 16, 15, 22, 12, 17, 25, 15, 21, 21, 24]
[14, 14, 16, 22, 16, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 21, 24]
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 25, 18, 15, 21, 21, 21]
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 17, 25, 15, 21, 21, 24]
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 21, 21]
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 20, 22, 12, 17, 25, 20, 21, 20, 21]
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 17, 25, 15, 21, 21, 21]
[14, 14, 16, 22, 21, 22, 20, 19, 13, 22, 16, 23, 22, 12, 25, 18, 15, 21, 21, 21]
[14, 14, 16, 22, 21, 22, 20, 19, 16, 22, 16, 20, 22, 12, 26, 18, 15, 21, 20, 21]
[14, 14, 18, 22, 21, 22, 20, 19, 16, 22, 16, 15, 22, 11, 26, 18, 15, 21, 22, 21]
Finished!
Total Searching time = 34.85 hours
